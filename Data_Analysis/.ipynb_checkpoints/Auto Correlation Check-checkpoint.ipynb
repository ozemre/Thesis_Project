{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murat.ozemre\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from random import randrange\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from matplotlib import pyplot\n",
    "from pandas import Series\n",
    "from random import seed\n",
    "from random import random\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "#os.chdir('C:/Users/murat.ozemre/Documents/MOZEMRE-OZEL/Doktora/2017 Tez/Veri Analizi/Ver 3 Tez Izleme Calısmaları/Auto Correlation')\n",
    "#os.chdir('C:/Users/murat.ozemre/Documents/MOZEMRE-OZEL/Doktora/2017 Tez/Veri Analizi/Ver 3 Tez Izleme Calısmaları')\n",
    "\n",
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Sources_and_Preparation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841850 MaxAbsScaler\n"
     ]
    }
   ],
   "source": [
    "Scaler_Type_Options = ['Normalizer', 'MinMaxScaler','MaxAbsScaler','RobustScaler','StandardScaler' ]\n",
    "#Scaler_Type_Options = ['Normalizer', 'MinMaxScaler' ]\n",
    "\n",
    "Product_Type_Options = [841810,841840,841850]\n",
    "Product=Product_Type_Options[2]\n",
    "ScalerType=Scaler_Type_Options[2]\n",
    "print(Product,ScalerType)\n",
    "\n",
    "MonthSeries=\"1\"\n",
    "MonthSeries_option=[\"1\",\"12\"]\n",
    "#MonthSeries_option=[\"12\",\"123\",\"1236\",\"1236_12\",\"__12\",\"__126\",\"__1263\",\"__12632\"]\n",
    "#MonthSeries_option=[\"12\",\"123\",\"1236\",\"1236_12\",\"__12\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setpartner(Product):\n",
    "    if Product==841810 :\n",
    "        IMP1=\"USA\"\n",
    "        IMP2=\"JPN\"\n",
    "        IMP3=\"FRA\"\n",
    "        IMP4=\"AUS\"\n",
    "        EXP1=\"POL\"\n",
    "        EXP2=\"KOR\"\n",
    "        EXP3=\"ITA\"\n",
    "    elif Product==841840 :\n",
    "        IMP1=\"USA\"\n",
    "        IMP2=\"JPN\"\n",
    "        IMP3=\"FRA\"\n",
    "        IMP4=\"DEU\"\n",
    "        EXP1=\"DEU\"\n",
    "        EXP2=\"NLD\"\n",
    "        EXP3=\"HUN\"\n",
    "    elif Product==841850 :\n",
    "        IMP1=\"USA\"\n",
    "        IMP2=\"AUS\"\n",
    "        IMP3=\"ITA\"\n",
    "        IMP4=\"IDN\"\n",
    "        EXP1=\"AUT\"\n",
    "        EXP2=\"CHZ\"\n",
    "        EXP3=\"ITA\"\n",
    "    \n",
    "    return IMP1,IMP2,IMP3,IMP4,EXP1,EXP2,EXP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readexcel(Product):\n",
    "    if Product==841810 :\n",
    "        Data_Core = pd.ExcelFile('Out_841810_CHN_UK_Data_Core_1236_12.xlsx')\n",
    "        Data_Core = Data_Core.parse('Sheet1', header=0,index_col=None, na_values=['NA'])\n",
    "    elif Product==841840:\n",
    "        Data_Core = pd.ExcelFile('Out_841840_CHN_UK_Data_Core_1236_12.xlsx')\n",
    "        Data_Core = Data_Core.parse('Sheet1', header=0,index_col=None, na_values=['NA'])\n",
    "    elif Product==841850:\n",
    "        Data_Core = pd.ExcelFile('Out_841850_CHN_UK_Data_Core_1236_12.xlsx')\n",
    "        Data_Core = Data_Core.parse('Sheet1', header=0,index_col=None, na_values=['NA'])\n",
    "    return Data_Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readexcel_hat(Product):\n",
    "    if Product==841810 :\n",
    "        Data_Core = pd.ExcelFile('Out_841810_CHN_UK_Data_Core_1236_12.xlsx')\n",
    "        Data_Core = Data_Core.parse('Sheet2', header=0,index_col=None, na_values=['NA'])\n",
    "    elif Product==841840:\n",
    "        Data_Core = pd.ExcelFile('Out_841840_CHN_UK_Data_Core_1236_12.xlsx')\n",
    "        Data_Core = Data_Core.parse('Sheet2', header=0,index_col=None, na_values=['NA'])\n",
    "    elif Product==841850:\n",
    "        Data_Core = pd.ExcelFile('Out_841850_CHN_UK_Data_Core_1236_12.xlsx')\n",
    "        Data_Core = Data_Core.parse('Sheet2', header=0,index_col=None, na_values=['NA'])\n",
    "    Data_Core=Data_Core.iloc[3:,:]\n",
    "    return Data_Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_y(Product,Data_Core):\n",
    "    if Product==841810 :\n",
    "        y=Data_Core['CHN_GBR_841810']        \n",
    "    elif Product==841840 :\n",
    "        y=Data_Core['CHN_GBR_841840']\n",
    "    elif Product==841850 :\n",
    "        y=Data_Core['CHN_GBR_841850']\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_X(Product,Data_Core,MonthSeries):\n",
    "    if MonthSeries==\"1\":\n",
    "        X=Data_Core[\n",
    "    \n",
    "            ['CHN_World_{}-1'.format(Product), 'CHN_{}_{}-1'.format(IMP1,Product), 'CHN_{}_{}-1'.format(IMP2,Product),\n",
    "               'CHN_{}_{}-1'.format(IMP3,Product), 'CHN_{}_{}-1'.format(IMP4,Product), 'CHN_GBR_{}-1'.format(Product),\n",
    "               '{}_GBR_{}-1'. format(EXP1,Product), '{}_GBR_{}-1'. format(EXP2,Product), '{}_GBR_{}-1'. format(EXP3,Product), \n",
    "               'EPU_CHN-1','EPU_UK-1', 'EPU_World-1', \n",
    "               'BCI_CHN-1', 'CCI_CHN-1', 'CLI_CHN-1','GDP_CHN-1', \n",
    "               'BCI_GBR-1', 'CCI_GBR-1', 'CLI_GBR-1', 'GDP_GBR-1',\n",
    "               'PPI_CHN-1', 'PPI_GBR-1', 'CPI_CHN-1', 'CPI_GBR-1', \n",
    "               'CNY-1', 'GBP-1','World-1','Date']\n",
    "        ]\n",
    "        \n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841810\n",
      "841840\n",
      "841850\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#y=set_y(Product,Data_Core)\n",
    "#X=set_X(Product,Data_Core,MonthSeries)\n",
    "\n",
    "for Product in Product_Type_Options:\n",
    "    partner=setpartner(Product)\n",
    "  \n",
    "    IMP1=partner[0]\n",
    "    IMP2=partner[1]\n",
    "    IMP3=partner[2]\n",
    "    IMP4=partner[3]\n",
    "    EXP1=partner[4]\n",
    "    EXP2=partner[5]\n",
    "    EXP3=partner[6]\n",
    "    \n",
    "    Data_Core=readexcel(Product)\n",
    "    Data_Core_hat=readexcel_hat(Product)\n",
    "    print(Product)\n",
    "    if Product==841810 :\n",
    "        y1=set_y(Product,Data_Core)\n",
    "        X1=set_X(Product,Data_Core,MonthSeries)\n",
    "        \n",
    "        y1hat=set_y(Product,Data_Core_hat)\n",
    "        X1hat=set_X(Product,Data_Core_hat,MonthSeries)\n",
    "        \n",
    "    elif Product==841840 :\n",
    "        y2=set_y(Product,Data_Core)\n",
    "        X2=set_X(Product,Data_Core,MonthSeries)\n",
    "        y2hat=set_y(Product,Data_Core_hat)\n",
    "        X2hat=set_X(Product,Data_Core_hat,MonthSeries)\n",
    "        \n",
    "    elif Product==841850 :\n",
    "        y3=set_y(Product,Data_Core)\n",
    "        X3=set_X(Product,Data_Core,MonthSeries)\n",
    "\n",
    "        y3hat=set_y(Product,Data_Core_hat)\n",
    "        X3hat=set_X(Product,Data_Core_hat,MonthSeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mean Staitionary testi için 2 ayrı setin Mean Farkı \n",
    "Z=y1\n",
    "split = int(len(Z)/ 2)\n",
    "Z1, Z2 = Z[0:split], Z[split:]\n",
    "mean1, mean2 = Z1.mean(), Z2.mean()\n",
    "var1, var2 = Z1.var(), Z2.var()\n",
    "print('mean1=%f, mean2=%f' % (mean1, mean2))\n",
    "print('variance1=%f, variance2=%f' % (var1, var2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate and plot a white noise series\n",
    "from random import gauss\n",
    "from random import seed\n",
    "from pandas import Series\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from random import randrange\n",
    "\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "# create white noise series\n",
    "series = [gauss(0.0, 1.0) for i in range(1000)]\n",
    "series = Series(series)\n",
    "# summary stats\n",
    "print(series.describe())\n",
    "# line plot\n",
    "series.plot()\n",
    "#pyplot.savefig(\"Deneme.png\", format='png', dpi=300)\n",
    "\n",
    "pyplot.show()\n",
    "\n",
    "# histogram plot\n",
    "series.hist()\n",
    "pyplot.show()\n",
    "# autocorrelation\n",
    "autocorrelation_plot(series)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Analiz(z):\n",
    "    a=''\n",
    "    pyplot.gcf().clear()\n",
    "    print(z.describe())\n",
    "    z.plot()\n",
    "    pyplot.title('{}{} Line Plot'.format(z.name, a))\n",
    "    pyplot.savefig(\"{}{} Line Plot.png\".format(z.name, a), format='png', dpi=300)\n",
    "    pyplot.show()\n",
    "    \n",
    "    z.hist()\n",
    "    pyplot.title('{}{} Histogram Plot'.format(z.name, a))\n",
    "    pyplot.savefig(\"{}{} Histogram Plot.png\".format(z.name, a), format='png', dpi=300)\n",
    "    pyplot.show()\n",
    "\n",
    "    autocorrelation_plot(z)\n",
    "    pyplot.title('{}{} Auto Correlation Plot'.format(z.name, a))\n",
    "    pyplot.savefig(\"{}{} Auto Correlation Plot.png\".format(z.name, a), format='png', dpi=300)\n",
    "    pyplot.show()\n",
    "    \n",
    "    plot_acf(z,lags=30)\n",
    "    pyplot.title('{}{} Auto Correlation with legs'.format(z.name, a))\n",
    "    pyplot.savefig(\"{}{} Auto Correlation with legs .png\".format(z.name, a), format='png', dpi=300)\n",
    "    pyplot.show()\n",
    "    \n",
    "    plot_pacf(z,lags=30)\n",
    "    pyplot.title('{}{} Partial Auto Correlation with legs'.format(z.name, a))\n",
    "    pyplot.savefig(\"{}{} Partial Auto Correlation with legs .png\".format(z.name, a), format='png', dpi=300)\n",
    "    pyplot.show()\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Stationary_Analiz(z):\n",
    "    a=''\n",
    "    print(z.name)\n",
    "    result = adfuller(z)\n",
    "    print('ADF Statistic: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "    series = [i+randrange(10) for i in range(1,100)]\n",
    "    modeltype='additive'\n",
    "    \n",
    "    result = seasonal_decompose(z.tolist(), model=modeltype, freq=12)\n",
    "    result.plot()\n",
    "   \n",
    "    pyplot.savefig(\"{}{} Decompose with {} moded .png\".format(z.name,a,modeltype), format='png', dpi=300)\n",
    "\n",
    "    pyplot.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Stationary_Analiz_Short(z):\n",
    "    #print(Product)\n",
    "    result = adfuller(z)\n",
    "    adf=int(100000*result[0])/100000\n",
    "    p_value=int(100000*result[1])/100000\n",
    "\n",
    "    #print('ADF Statistic: %f' % adf)\n",
    "    #print('p-value: %f' % p_value)\n",
    "    \n",
    "    return adf,p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z=y1.dropna()\n",
    "series = [i+randrange(10) for i in range(1,100)]\n",
    "result = seasonal_decompose(z.tolist(), model='multiplicative', freq=12)\n",
    "result.plot()\n",
    "pyplot.show()\n",
    "\n",
    "observed=pd.Series(data=result.observed, index=z.index)\n",
    "trend=pd.Series(data=result.trend, index=z.index)\n",
    "seasonal=pd.Series(data=result.seasonal, index=z.index)\n",
    "resid=pd.Series(data=result.resid, index=z.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resid=resid.dropna()\n",
    "resid.plot()\n",
    "pyplot.show()\n",
    "Stationary_Analiz_Short(resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z=y1.dropna()\n",
    "series = [i+randrange(10) for i in range(1,100)]\n",
    "result = seasonal_decompose(z.tolist(), model='additive', freq=12)\n",
    "result.plot()\n",
    "pyplot.show()\n",
    "\n",
    "observed=pd.Series(data=result.observed, index=z.index)\n",
    "trend=pd.Series(data=result.trend, index=z.index)\n",
    "seasonal=pd.Series(data=result.seasonal, index=z.index)\n",
    "resid=pd.Series(data=result.resid, index=z.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resid=resid.dropna()\n",
    "resid.plot()\n",
    "pyplot.show()\n",
    "Stationary_Analiz_Short(resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(observed[10],trend[10],seasonal[10],resid[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z=y2.dropna()\n",
    "series = [i+randrange(10) for i in range(1,100)]\n",
    "result = seasonal_decompose(z.tolist(), model='multiplicative', freq=12)\n",
    "result.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z=y3.dropna()\n",
    "series = [i+randrange(10) for i in range(1,100)]\n",
    "result = seasonal_decompose(z.tolist(), model='multiplicative', freq=12)\n",
    "result.plot()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ADF Testi herbir özellik için\n",
    "#Hangi degerin teste girecğini belirlemek için\n",
    "\n",
    "X=X1.dropna() \n",
    "Xhat=X1hat.dropna()\n",
    "\n",
    "#   Herbir özellik için ADF Calısır\n",
    "\n",
    "n_feature=X.shape[1]\n",
    "sonuc=[]\n",
    "Stationary_sonuc=np.zeros((4,X.shape[1]))\n",
    "\n",
    "for i in range(n_feature):\n",
    "        \n",
    "        x=X.iloc[:, i]\n",
    "        xhat=Xhat.iloc[:, i]\n",
    "        title=list(X)[i:i+1]\n",
    "       \n",
    "        analiz_sonuc_x=Stationary_Analiz_Short(x)\n",
    "        analiz_sonuc_xhat=Stationary_Analiz_Short(xhat)\n",
    "        \n",
    "        sonuc.append(title)\n",
    "        sonuc.append(analiz_sonuc_x)\n",
    "        sonuc.append(analiz_sonuc_xhat)\n",
    "\n",
    "sonuc_array=np.asarray(sonuc).reshape(n_feature,3)\n",
    "\n",
    "sonuc_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(28,5),columns='Title A P Ahat Phat'.split())\n",
    "#sonuc=np.asarray(sonuc).reshape(n_feature,3)  \n",
    "for i in range(n_feature):   \n",
    "\n",
    "#        print(str(sonuc[0+3*i]))\n",
    "#        print (sonuc[1+3*i][0])\n",
    "#        print (sonuc[1+3*i][1])\n",
    "#        print (sonuc[2+3*i][0])\n",
    "#        print (sonuc[2+3*i][1])\n",
    "        df.iloc[i, 0]=str(sonuc[0+3*i])\n",
    "        df.iloc[i,1]=sonuc[1+3*i][0]\n",
    "        df.iloc[i, 2]=sonuc[1+3*i][1]\n",
    "        df.iloc[i, 3]=sonuc[2+3*i][0]\n",
    "        df.iloc[i, 4]=sonuc[2+3*i][1]\n",
    "df.to_excel('Stationary_Analiz_X1.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(randn(28,5),columns='Title A P Ahat Phat'.split())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=25\n",
    "df.iloc[0, 4]=str(sonuc[0+3*i])\n",
    "df.iloc[0, 4]\n",
    "df.iloc[i-1, 1]=sonuc[1+3*i][0]\n",
    "print(df.iloc[24, 1])\n",
    "print(sonuc[76][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# O sutunun adını donuyor.\n",
    "print(list(X1)[15:16])\n",
    "# O sutunun verisini donuyor\n",
    "#X1.iloc[:, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(X1)[15:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Analiz(X1.iloc[:, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ts_diagnostics(y, lags=None, title=''):\n",
    "    '''\n",
    "    Calculate acf, pacf, qq plot and Augmented Dickey Fuller test for a given time series\n",
    "    '''\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y)\n",
    "        \n",
    "    # weekly moving averages (5 day window because of workdays)\n",
    "    rolling_mean = pd.rolling_mean(y, window=24)\n",
    "    rolling_std = pd.rolling_std(y, window=24)\n",
    "    \n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    layout = (3, 2)\n",
    "    ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n",
    "    acf_ax = plt.subplot2grid(layout, (1, 0))\n",
    "    pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "    qq_ax = plt.subplot2grid(layout, (2, 0))\n",
    "    hist_ax = plt.subplot2grid(layout, (2, 1))\n",
    "    \n",
    "    # time series plot\n",
    "    y.plot(ax=ts_ax)\n",
    "    rolling_mean.plot(ax=ts_ax, color='crimson');\n",
    "    rolling_std.plot(ax=ts_ax, color='darkslateblue');\n",
    "    plt.legend(loc='best')\n",
    "    ts_ax.set_title(title, fontsize=24);\n",
    "    \n",
    "    # acf and pacf\n",
    "    plot_acf(y, lags=lags, ax=acf_ax, alpha=0.5)\n",
    "    plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.5) \n",
    "    \n",
    "    # qq plot\n",
    "    qqplot(y, line='s', ax=qq_ax)\n",
    "    qq_ax.set_title('QQ Plot')\n",
    "    \n",
    "    # hist plot\n",
    "    y.plot(ax=hist_ax, kind='hist', bins=25);\n",
    "    hist_ax.set_title('Histogram');\n",
    "    plt.tight_layout();\n",
    "    plt.savefig(\"{}Auto Correlation Study .png\".format(z.name), format='png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # perform Augmented Dickey Fuller test\n",
    "    print('Results of Dickey-Fuller test:')\n",
    "    dftest = adfuller(y, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['test statistic', 'p-value', '# of lags', '# of observations'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z=y3\n",
    "y_diff = np.diff(z)\n",
    "#y_diff=z\n",
    "ts_diagnostics(y_diff, lags=30, title='Auto Correlation Study for {}hat'.format(z.name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z=y3\n",
    "result = adfuller(z,maxlag=13)\n",
    "#result = adfuller(z,maxlag=13)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print(result[4])\n",
    "\n",
    "#result = adfuller(z,maxlag=13,regression='ct',autolag='t-stat')\n",
    "result = adfuller(z,maxlag=13,autolag='AIC')\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print(result[4])\n",
    "\n",
    "\n",
    "result = adfuller(z)\n",
    "#result = adfuller(z,maxlag=24,regression='ct',autolag='t-stat')\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print(result[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z=y1\n",
    "result = adfuller(z,maxlag=24,regression='ct')\n",
    "\n",
    "#result = adfuller(z,maxlag=24,regression='ct',autolag='t-stat')\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print(result[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z=y1\n",
    "\n",
    "result = adfuller(z,maxlag=24,regression='ct',autolag='t-stat')\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print(result[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=y1.dropna()\n",
    "#Analiz(X.iloc[:, 12])\n",
    "Analiz(a)\n",
    "Stationary_Analiz(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=y2.dropna()\n",
    "#Analiz(X.iloc[:, 0])\n",
    "Analiz(a)\n",
    "Stationary_Analiz(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=y3\n",
    "#Analiz(X.iloc[:, 0])\n",
    "Analiz(a)\n",
    "Stationary_Analiz(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a=y1hat.dropna()\n",
    "#Analiz(X.iloc[:, 0])\n",
    "Analiz(a)\n",
    "Stationary_Analiz(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=y2hat.dropna()\n",
    "#Analiz(X.iloc[:, 0])\n",
    "Analiz(a)\n",
    "Stationary_Analiz(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=y3hat.dropna()\n",
    "#Analiz(X.iloc[:, 0])\n",
    "Analiz(a)\n",
    "Stationary_Analiz(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the stationarity of a random walk\n",
    "from random import seed\n",
    "from random import random\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "#result = adfuller(X.iloc[:, 20])\n",
    "print(Product)\n",
    "result = adfuller(y1)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))\n",
    "# Section 12.4\n",
    "# additive decompose a contrived additive time series\n",
    "from random import randrange\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from matplotlib import pyplot\n",
    "\n",
    "series = [i+randrange(10) for i in range(1,100)]\n",
    "result = seasonal_decompose(y1.tolist(), model='additive', freq=12)\n",
    "\n",
    "result.plot()\n",
    "\n",
    "pyplot.show()\n",
    "plt.title('Page One')\n",
    "\n",
    "\n",
    "#result = seasonal_decompose(y.tolist(), model='multiplicative', freq=12)\n",
    "#result.plot()\n",
    "#pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#result = seasonal_decompose(y.tolist(), model='additive', freq=12)\n",
    "#print(result.trend)\n",
    "#print(result.seasonal)\n",
    "#print(result.resid)\n",
    "#print(result.observed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ACF plot of time series\n",
    "from pandas import Series\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "#series = Series.from_csv('daily-minimum-temperatures.csv', header=0)\n",
    "print(Product)\n",
    "plot_acf(y1,lags=30)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=pd.DataFrame(columns=['y1'],data=y1.values)\n",
    "b=pd.DataFrame(columns=['y1hat'],data=y1hat.values)\n",
    "#c=pd.concat([a, b], axis=1)\n",
    "\n",
    "#sns.pairplot(c[['y1','y1hat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(y1[4],y1[3],y1hat[3],y1[4]-y1[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y1hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ARIMA ICIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grid search ARIMA parameters for a time series\n",
    "import warnings\n",
    "from pandas import Series\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "# evaluate an ARIMA model for a given order (p,d,q) and return RMSE\n",
    "\n",
    "def evaluate_arima_model(X, arima_order):\n",
    "    # prepare training dataset\n",
    "    X = X.astype('float32')\n",
    "    train_size = int(len(X) * 0.50)\n",
    "    train, test = X[0:train_size], X[train_size:]\n",
    "    history = [x for x in train]\n",
    "    # make predictions\n",
    "    predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        model = ARIMA(history, order=arima_order)\n",
    "        # model_fit = model.fit(disp=0)\n",
    "        model_fit = model.fit(trend='nc', disp=0)\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        predictions.append(yhat)\n",
    "        history.append(test[t])\n",
    "        # calculate out of sample error\n",
    "    rmse = sqrt(mean_squared_error(test, predictions))\n",
    "    r2=r2_score(test, predictions)\n",
    "    return rmse,test,predictions\n",
    "\n",
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "def evaluate_models(dataset, p_values, d_values, q_values):\n",
    "    dataset = dataset.astype('float32')\n",
    "    best_score = float(\"inf\")\n",
    "    best_cfg = float(\"inf\")\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p,d,q)\n",
    "                try:\n",
    "                    result = evaluate_arima_model(dataset, order)\n",
    "                    rmse = result[0]\n",
    "                    best_test=result[1]\n",
    "                    best_prediction=result[2]\n",
    "                    if rmse < best_score:\n",
    "#                    if rmse > best_score:\n",
    "\n",
    "                        best_score, best_cfg = rmse, order\n",
    "                        r2=r2_score(best_test,best_prediction)\n",
    "                        print('ARIMA%s RMSE=%.3f R2=%.3f' % (order,rmse,r2))\n",
    "    \n",
    "                        \n",
    "                except:\n",
    "                    continue\n",
    "    print('Best ARIMA%s RMSE=%.3f R2=%.3f' % (best_cfg, best_score,r2))\n",
    "    return best_test,best_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_values = range(0, 12)\n",
    "d_values = range(0, 3)\n",
    "q_values = range(0, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA(0, 0, 1) RMSE=7350.790 R2=-4.157\n",
      "ARIMA(0, 0, 2) RMSE=5743.919 R2=-2.149\n",
      "ARIMA(0, 0, 3) RMSE=4554.336 R2=-0.980\n",
      "ARIMA(0, 0, 4) RMSE=4461.230 R2=-0.899\n",
      "ARIMA(0, 0, 5) RMSE=3969.557 R2=-0.504\n",
      "ARIMA(0, 0, 7) RMSE=3915.106 R2=-0.463\n",
      "ARIMA(0, 0, 8) RMSE=3748.388 R2=-0.341\n",
      "ARIMA(0, 0, 9) RMSE=3627.428 R2=-0.256\n",
      "ARIMA(0, 1, 1) RMSE=2954.531 R2=0.167\n",
      "ARIMA(0, 1, 3) RMSE=2901.648 R2=0.196\n",
      "ARIMA(0, 1, 4) RMSE=2869.085 R2=0.214\n",
      "ARIMA(3, 1, 1) RMSE=2859.796 R2=0.219\n",
      "Best ARIMA(3, 1, 1) RMSE=2859.796 R2=0.219\n"
     ]
    }
   ],
   "source": [
    "\n",
    "series = y1\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "a=evaluate_models(series.values, p_values, d_values, q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "series = y1hat\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_models(series.values, p_values, d_values, q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA(0, 0, 1) RMSE=988.913 R2=-7.029\n",
      "ARIMA(0, 0, 2) RMSE=747.663 R2=-3.589\n",
      "ARIMA(0, 0, 3) RMSE=631.501 R2=-2.274\n",
      "ARIMA(0, 0, 4) RMSE=535.054 R2=-1.350\n",
      "ARIMA(0, 0, 6) RMSE=516.062 R2=-1.187\n",
      "ARIMA(0, 0, 7) RMSE=492.772 R2=-0.994\n",
      "ARIMA(0, 0, 9) RMSE=396.859 R2=-0.293\n",
      "ARIMA(0, 0, 10) RMSE=393.848 R2=-0.274\n",
      "ARIMA(0, 1, 1) RMSE=331.237 R2=0.099\n",
      "ARIMA(0, 1, 2) RMSE=324.892 R2=0.133\n",
      "ARIMA(0, 1, 3) RMSE=324.301 R2=0.137\n",
      "ARIMA(1, 1, 1) RMSE=324.075 R2=0.138\n",
      "ARIMA(10, 1, 0) RMSE=321.941 R2=0.149\n",
      "Best ARIMA(10, 1, 0) RMSE=321.941 R2=0.149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 547., 1654., 1326.,  790., 1025., 1175., 1678., 1788., 1773.,\n",
       "        1469., 1525., 1486., 1245., 1880., 1473., 1355.,  862., 1499.,\n",
       "        1875., 1474., 1418., 1358., 1521., 1603., 2182., 1446., 1097.,\n",
       "         873., 1000., 1272., 1899., 1797., 1592., 2150., 1948., 2162.,\n",
       "        1943., 1818., 1815., 1573., 1608., 2291., 1791., 1998., 1506.,\n",
       "        1718., 1841., 1977., 1675., 1519., 1234., 1330., 1494., 1373.,\n",
       "        1726., 1931., 1699., 2109., 1860., 1830., 1877., 1762., 1641.,\n",
       "        1216., 1808., 1575., 1665.], dtype=float32),\n",
       " [array([1425.15865662]),\n",
       "  array([1248.87811802]),\n",
       "  array([1165.01674278]),\n",
       "  array([1221.74218274]),\n",
       "  array([1226.1788561]),\n",
       "  array([1014.41625717]),\n",
       "  array([1065.13638383]),\n",
       "  array([1415.69678551]),\n",
       "  array([1915.53820693]),\n",
       "  array([1649.01941134]),\n",
       "  array([2109.67740548]),\n",
       "  array([1238.91026]),\n",
       "  array([1528.90332965]),\n",
       "  array([1742.85977184]),\n",
       "  array([1260.81975403]),\n",
       "  array([1562.73826332]),\n",
       "  array([1619.63306362]),\n",
       "  array([1332.12613643]),\n",
       "  array([1484.18952522]),\n",
       "  array([1785.27920909]),\n",
       "  array([1415.45234476]),\n",
       "  array([1259.08635073]),\n",
       "  array([1569.25887625]),\n",
       "  array([1245.91104932]),\n",
       "  array([1735.975388]),\n",
       "  array([1962.11234146]),\n",
       "  array([1526.32560984]),\n",
       "  array([1103.17877935]),\n",
       "  array([1061.15831865]),\n",
       "  array([1485.13777611]),\n",
       "  array([1109.68890211]),\n",
       "  array([1403.2179946]),\n",
       "  array([1620.17244478]),\n",
       "  array([1765.85663967]),\n",
       "  array([1973.56511256]),\n",
       "  array([2295.0857853]),\n",
       "  array([2044.19633172]),\n",
       "  array([1576.38249537]),\n",
       "  array([1635.94971502]),\n",
       "  array([1971.54336891]),\n",
       "  array([1851.88164565]),\n",
       "  array([1954.50695682]),\n",
       "  array([2416.02103359]),\n",
       "  array([1691.31544813]),\n",
       "  array([2152.43699374]),\n",
       "  array([1802.67734798]),\n",
       "  array([1632.30257698]),\n",
       "  array([1848.00537971]),\n",
       "  array([1726.39522616]),\n",
       "  array([1689.20258341]),\n",
       "  array([1582.26727514]),\n",
       "  array([1150.68693039]),\n",
       "  array([1699.05261822]),\n",
       "  array([1443.48608555]),\n",
       "  array([1268.42535892]),\n",
       "  array([1434.7321503]),\n",
       "  array([1704.81672113]),\n",
       "  array([1846.81455968]),\n",
       "  array([2086.05044699]),\n",
       "  array([1832.74372567]),\n",
       "  array([1700.66725272]),\n",
       "  array([1754.42506149]),\n",
       "  array([1709.2928435]),\n",
       "  array([1888.83349574]),\n",
       "  array([1428.36450794]),\n",
       "  array([1637.99616718]),\n",
       "  array([1945.50966688])])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = y2\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "a=evaluate_models(series.values, p_values, d_values, q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA(0, 0, 1) RMSE=1740.188 R2=-2.834\n",
      "ARIMA(0, 0, 2) RMSE=1375.309 R2=-1.395\n",
      "ARIMA(0, 0, 3) RMSE=1147.536 R2=-0.667\n",
      "ARIMA(0, 0, 5) RMSE=951.857 R2=-0.147\n",
      "ARIMA(0, 0, 6) RMSE=916.658 R2=-0.064\n",
      "ARIMA(0, 1, 1) RMSE=650.014 R2=0.465\n",
      "ARIMA(0, 1, 3) RMSE=649.535 R2=0.466\n",
      "ARIMA(0, 1, 4) RMSE=645.067 R2=0.473\n",
      "Best ARIMA(0, 1, 4) RMSE=645.067 R2=0.473\n"
     ]
    }
   ],
   "source": [
    "series = y3\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "a=evaluate_models(series.values, p_values, d_values, q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
