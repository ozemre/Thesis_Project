{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Sources_and_Preparation')\n",
    "#os.chdir('C:/Users/murat.ozemre/Documents/MOZEMRE-OZEL/Doktora/2017 Tez/Veri Analizi/Ver 3 Tez Izleme Calısmaları')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statsmodels: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import statsmodels\n",
    "print('statsmodels: %s' % statsmodels.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12-13 12:41'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murat.ozemre\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scaler_Type_Options = ['Normalizer', 'MinMaxScaler','MaxAbsScaler','RobustScaler','StandardScaler' ]\n",
    "Scaler_Type_Options = [ 'MinMaxScaler' ]\n",
    "Scalertype=Scaler_Type_Options[0]\n",
    "Product_Type_Options = [841810,841840,841850]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MinMaxScaler'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scalertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841840"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Product=Product_Type_Options[0] #841810\n",
    "Exp_Country='TUR' # 'CHN'\n",
    "Imp_Country='GBR'\n",
    "\n",
    "if Exp_Country=='CHN':\n",
    "    Currency='CNY'\n",
    "    EXP0='TUR'   \n",
    "elif Exp_Country=='TUR':\n",
    "    Currency='TRY'\n",
    "    EXP0='CHN'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MonthSeries=\"3\"\n",
    "MonthSeries_option=[\"1\",\"2\",\"3\",\"6\",\"12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Core1 = pd.ExcelFile('Data_{}_{}_{}.xlsx'.format(Exp_Country,Imp_Country,Product))\n",
    "y = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])['{}_{}_{}'.format(Exp_Country,Imp_Country,Product)]\n",
    "Z = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])[['Date','Year','Month']]\n",
    "\n",
    "X = Data_Core1.parse('X{}'.format(MonthSeries), header=0,index_col=None, na_values=['NA'])\n",
    "X.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "X_Column_Names=list(X.columns.values)\n",
    "n_feature=X.shape[1]\n",
    "\n",
    "Xhat = Data_Core1.parse('Xhat', header=0,index_col=None, na_values=['NA'])\n",
    "Xhat.drop(['Date','Year','Month'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Xscaler(X,y,scalertype):\n",
    "\n",
    "    if scalertype==\"Normalizer\":\n",
    "        X=pd.DataFrame(Normalizer().fit_transform(X,y))\n",
    "        print(\"normalize\")\n",
    "    elif scalertype==\"MinMaxScaler\":\n",
    "        X=pd.DataFrame(MinMaxScaler().fit_transform(X,y))\n",
    "        print(\"minmax\")\n",
    "    elif scalertype==\"MaxAbsScaler\":\n",
    "        X=pd.DataFrame(MaxAbsScaler().fit_transform(X,y))\n",
    "        print(\"maxabs\")\n",
    "    elif scalertype==\"RobustScaler\":\n",
    "        X=pd.DataFrame(RobustScaler().fit_transform(X,y))\n",
    "    elif scalertype==\"StandardScaler\":\n",
    "        X=pd.DataFrame(StandardScaler().fit_transform(X,y))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling Min Max and then spilt test and train according stratify to month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def X_Y_scaler_train_test_Split(X,y,Z,random=42):\n",
    "\n",
    "    values = X.values\n",
    "    values = values.astype('float32')\n",
    "    X_Column_X_Column_Names=X.columns\n",
    "    \n",
    "    scaler_X= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_X = scaler_X.fit_transform(values)\n",
    "    scaled_value_X = pd.DataFrame(data=scaled_value_X[:,:])\n",
    "    scaled_value_X.columns=X_Column_X_Column_Names\n",
    "    \n",
    "    values = y.values\n",
    "    values = values.astype('float32')\n",
    "    values = values.reshape(-1, 1)\n",
    "    \n",
    "    scaler_y= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_y = scaler_y.fit_transform(values)\n",
    "    scaled_value_y = pd.DataFrame(data=scaled_value_y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_value_X,scaled_value_y,test_size=0.2,random_state=42,stratify=Z['Month'])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler_X, scaler_y, scaled_value_X, scaled_value_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,plot_on):\n",
    "\n",
    "    y_predict_test=y_predict_test.reshape(-1, 1)\n",
    "    inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "    predictions=inv_y_predict_test\n",
    "\n",
    "  \n",
    "    inv_y_test = scaler_y.inverse_transform(y_test)\n",
    "    inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "    MAE=int(metrics.mean_absolute_error(inv_y_test, predictions))\n",
    "    MSE=int(sqrt(metrics.mean_squared_error(inv_y_test, predictions)))\n",
    "    R2=int(1000*(metrics.r2_score(inv_y_test, predictions)))/1000\n",
    "    \n",
    "    \n",
    "    print('MAE',MAE, 'MSE',MSE, 'R2',R2 )\n",
    "    \n",
    "    if plot_on =='YES':\n",
    "        plt.scatter(inv_y_test,predictions)\n",
    "    \n",
    "    return MAE,MSE,R2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Scaled_Train_Test_Split=X_Y_scaler_train_test_Split(X,y,Z)\n",
    "\n",
    "X_train = Scaled_Train_Test_Split[0]\n",
    "X_test = Scaled_Train_Test_Split[1]\n",
    "y_train = Scaled_Train_Test_Split[2]\n",
    "y_test = Scaled_Train_Test_Split[3]\n",
    "scaler_X = Scaled_Train_Test_Split[4]  \n",
    "scaler_y = Scaled_Train_Test_Split[5]\n",
    "scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "scaled_value_y=Scaled_Train_Test_Split[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 2352 MSE 3203 R2 0.54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2352, 3203, 0.54)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18d3c8a9630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Decison tree regressor model\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# Decison tree regressor model train\n",
    "DecisionTreeRegressor.fit(dt,X_train,y_train)\n",
    "\n",
    "# Decison tree regressor model predict\n",
    "y_predict_test = dt.predict(X_test)\n",
    "\n",
    "# Compare predicted Y and real Y \n",
    "inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 1797 MSE 2316 R2 0.76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1797, 2316, 0.76)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMwsx8XBzMxyXBzMzCzHxcHMzHL+P6e6hxUQ6s1vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18d41d269b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Foest Regressor model\n",
    "rfc=RandomForestRegressor(n_estimators=3000)\n",
    "\n",
    "# Random Foest Regressor model train\n",
    "RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "\n",
    "# Random Foest Regressor mode predict\n",
    "y_predict_test = rfc.predict(X_test)\n",
    "\n",
    "# Compare predicted Y and real Y \n",
    "inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02621113, 0.0141518 , 0.02234003, 0.02612442, 0.12534293,\n",
       "       0.01750001, 0.02402904, 0.02556985, 0.06732025, 0.0244008 ,\n",
       "       0.06661401, 0.01837386, 0.02273176, 0.01976855, 0.0494281 ,\n",
       "       0.01966076, 0.04407295, 0.01425537, 0.18794725, 0.01919714,\n",
       "       0.05810607, 0.02248924, 0.01174099, 0.02402174, 0.02914612,\n",
       "       0.01945582])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1 Nolu Blok\n",
    "# Internetten bulunan kod blogu\n",
    "# Random Forest'a gore Feature Importance Hesaplama\n",
    "# Butun veri setinin girildiği ona göre önemli olan özelliklerin bulundugu kod parçası\n",
    "\n",
    "ScalerType = Scalertype=Scaler_Type_Options[0]\n",
    "n_sample=len(X)\n",
    "\n",
    "rfc=RandomForestRegressor(n_estimators=3000)\n",
    "RandomForestRegressor.fit(rfc,scaled_value_X,scaled_value_y)\n",
    "\n",
    "\n",
    "predictions = rfc.predict(X_test)\n",
    "print('MAE',int(metrics.mean_absolute_error(y_test, predictions)),\n",
    "      'MSE',int(sqrt(metrics.mean_squared_error(y_test, predictions))),\n",
    "      'R2',int(1000*(metrics.r2_score(y_test, predictions)))/1000\n",
    "     )\n",
    "\n",
    "\n",
    "importances = rfc.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rfc.estimators_],axis=0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(n_feature):\n",
    "    print(\"%d. feature %s %d (%f) %f\" % (f+1, X_Column_Names[indices[f]], indices[f], importances[indices[f]],std[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"{} and -{} Month Feature Importances and Standart Deviation of Features with 3000 Different Estimations\".format(Product,MonthSeries))\n",
    "plt.bar(range(n_feature), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(n_feature), indices,rotation=90)\n",
    "plt.xlim([-1, n_feature])\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 15\n",
    "fig_size[1] = 10\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.savefig(\"Plots_Feature_Selection/{} and -{} Month Feature Importances and Standart Deviation of Features with 3000 Different Estimations.png\".format(Product,MonthSeries), format='png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2 Ver Nolu Blok\n",
    "# Internetten bulunan kod blogu http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "# Feature Importance Hesaplama\n",
    "# Burada asıl özellik bir veri seti yaratılıyor make_regression ile. Ve oaradakilere dogru çalışıp çalışmadığı test ediliyor.\n",
    "# Butun veri setinin girildiği ona göre önemli olan özelliklerin bulundugu kod parçası\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "\n",
    "n_sample=len(X)\n",
    "\n",
    "number_of_split=100\n",
    "number_of_row=29\n",
    "\n",
    "random_state_options = np.arange(0,number_of_split)\n",
    "y_predict= np.ones((number_of_row, number_of_split))\n",
    "\n",
    "feature_indices = np.ones((n_feature, number_of_split))\n",
    "feature_importances=np.ones((n_feature, number_of_split))\n",
    "feature_indices_score=np.ones((n_feature))\n",
    "feature_importances_score=np.ones((n_feature))\n",
    "j=0\n",
    "\n",
    "\n",
    "# For different split sets Random Forest Regressor runs.\n",
    "\n",
    "for random_state_i in random_state_options:\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_value_X,scaled_value_y,test_size=0.2,random_state=random_state_i,stratify=Z['Month'])\n",
    "\n",
    "    \n",
    "\n",
    "    rfc=RandomForestRegressor(n_estimators=30)\n",
    "    RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "\n",
    "    y_predict[:,j] = rfc.predict(X_test)\n",
    "    \n",
    "    result=inverse_scale_and_graph_Y_predict_and_test (y_predict[:,j],y_test,scaler_y,'NO')\n",
    "    \n",
    "    importances = rfc.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in rfc.estimators_],axis=0)\n",
    "\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    feature_indices[:,j]=indices\n",
    "    feature_importances[:,j]=importances\n",
    "    j=j+1\n",
    "    \n",
    "\n",
    "print (\"Features scores:\")    \n",
    "for i in range(n_feature):\n",
    "    feature_indices_score[i]=0\n",
    "    feature_importances_score[i]=0\n",
    "    for j in range(number_of_split):\n",
    "        \n",
    "        indice_coeff=feature_indices[i,j]\n",
    "        importances_coeff=feature_importances[i,j]\n",
    "        \n",
    "        feature_indices_score[i]=feature_indices_score[i]+(indice_coeff)\n",
    "        feature_importances_score[i]=feature_importances_score[i]+(importances_coeff)\n",
    "        \n",
    "#        print('feat=',i,'#ofsplit=',j,'tot_indice',feature_indices_score[i],\n",
    "#              'indice=',indice_coeff,'tot_importan=',feature_importances_score[i],'importan',importances_coeff )\n",
    "\n",
    "    print( i,X_Column_Names[i])#,feature_indices_score[i],'number_of_split',j+1) #,X_Column_Names[feature_indices[i,j]])\n",
    "    \n",
    "scored_feature_indices = np.argsort(feature_indices_score)\n",
    "scored_feature_importances = np.argsort(feature_importances_score)\n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "# Plot the feature importances of the forest\n",
    "plt.gcf().clear()\n",
    "plt.figure()\n",
    "plt.title(\"{} and -{} Month Cumulative Feature Importances with {} Different Splits.png\".format(Product,MonthSeries,number_of_split))\n",
    "plt.bar(range(n_feature), feature_importances_score[scored_feature_importances][::-1],\n",
    "       color=\"r\",  align=\"center\")\n",
    "plt.xticks(range(n_feature), scored_feature_importances[::-1],rotation=90)\n",
    "plt.xlim([-1, n_feature])\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 20\n",
    "fig_size[1] = 12\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.savefig(\"Plots_Feature_Selection/{} and -{} Month Cumulative Feature Importances with {} Different Splits.png\".format(Product,MonthSeries,number_of_split), format='png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3 Ver Blok Train Test Split olan\n",
    "# Internetten bulunan kod blogu\n",
    "# http://blog.datadive.net/selecting-good-features-part-iii-random-forests/\n",
    "# Use both RF Importances and R2 Accuracy with different number of splits\n",
    "\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter, attrgetter\n",
    "\n",
    "def getKey(item):\n",
    "    return item[0]\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "\n",
    "number_of_split=100\n",
    "number_of_row=29\n",
    "\n",
    "\n",
    "\n",
    "random_state_options = np.arange(0,number_of_split)\n",
    "predictions= np.ones((number_of_row, number_of_split))\n",
    "y_predict= np.ones((number_of_row, number_of_split))\n",
    "\n",
    "feature_indices = np.ones((n_feature, number_of_split))\n",
    "feature_importances=np.ones((n_feature, number_of_split))\n",
    "feature_indices_score=np.ones((n_feature))\n",
    "feature_importances_score=np.ones((n_feature))\n",
    "\n",
    "scores = defaultdict(list)\n",
    "#feature_indices = \n",
    "feature_std = np.ones((n_feature, number_of_split))\n",
    "feature_score=np.zeros((n_feature))\n",
    "\n",
    "#R2=defaultdict(list)\n",
    "R2=np.ones(number_of_split)\n",
    "j=0\n",
    "\n",
    "sonuc =[]\n",
    "\n",
    "\n",
    "for random_state_i in random_state_options:\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size=0.2,random_state=random_state_i,stratify=Z['Month'])\n",
    "\n",
    "    RandomForestRegressor.fit(rf,X_train, Y_train)    \n",
    "\n",
    "    y_predict[:,j] = rf.predict(X_test)\n",
    "    \n",
    "    acc = int(1000*(r2_score(Y_test, rf.predict(X_test))))/1000\n",
    "    R2[j] = int(1000*(r2_score(Y_test, rf.predict(X_test))))/1000\n",
    "        \n",
    "    importances = rf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    std = np.std([tree.feature_importances_ for tree in rf.estimators_],axis=0)\n",
    "\n",
    "\n",
    "    feature_importances[:,j]=importances\n",
    "    feature_indices[:,j]=indices\n",
    "    feature_std [:,j]=std\n",
    "\n",
    "    j=j+1\n",
    "\n",
    "R2_Adj=1-R2\n",
    "score_coefficient=n_feature*(R2_Adj - np.max(R2_Adj))/-np.ptp(R2_Adj)\n",
    "\n",
    "    \n",
    "print (\"Features scores:\")    \n",
    "for i in range(n_feature):\n",
    "    feature_score[i]=0\n",
    "    feature_indices_score[i]=0\n",
    "    feature_importances_score[i]=0\n",
    "    \n",
    "    for j in range(number_of_split):\n",
    "        \n",
    "        indice_coeff=feature_indices[i,j]+1\n",
    "        importances_coeff=int((feature_importances[i,j]*10000))/10000\n",
    "        score_coeff=int((score_coefficient[j]+1)*10)/10\n",
    "\n",
    "        feature_indices_score[i]=feature_indices_score[i]+(indice_coeff)\n",
    "        feature_importances_score[i]=feature_importances_score[i]+(importances_coeff)\n",
    "\n",
    "        score=score_coeff*(importances_coeff)\n",
    "        feature_score[i]=feature_score[i]+score\n",
    "\n",
    "\n",
    "#    print( feature_score[i],'number_of_split',j+1) #,X_Column_Names[feature_indices[i,j]])\n",
    "    \n",
    "scored_feature_indices = (np.argsort(feature_score)[::-1])\n",
    "\n",
    "for f in range(n_feature):\n",
    "    print(\"%d. feature %s %d (%f) %f\" % (f+1, X_Column_Names[scored_feature_indices[f]], scored_feature_indices[f], importances[scored_feature_indices[f]],std[scored_feature_indices[f]]))\n",
    "\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.gcf().clear()\n",
    "plt.figure()\n",
    "plt.title(\"{} and {} Month Cumulative Feature and Score Importances with {} Different Splits\".format(Product,MonthSeries,number_of_split))\n",
    "plt.bar(range(n_feature), feature_score[scored_feature_indices],\n",
    "       color=\"r\",  align=\"center\")\n",
    "plt.xticks(range(n_feature), scored_feature_indices,rotation=90)\n",
    "plt.xlim([-1, n_feature])\n",
    "\n",
    "#fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "#fig_size[0] = 20\n",
    "#fig_size[1] = 12\n",
    "#plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.savefig(\"Plots_Feature_Selection/{} and {} Month Cumulative Feature and Score Importances with {} Different Splits.png\".format(Product,MonthSeries,number_of_split), format='png', dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RAndom Forest denemeleri için kullanılan metod\n",
    "\n",
    "def randomforest(X_train, X_test, y_train, y_test,scaler_y,est,min_leaf,random,feat,max_leaf,min_weight,min_impurity):\n",
    "    from sklearn.model_selection import cross_val_score   \n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    \n",
    "    rfc=RandomForestRegressor(n_estimators=est,\n",
    "                              min_samples_leaf=min_leaf,\n",
    "                              random_state =random,\n",
    "                              max_features=feat,\n",
    "                              max_leaf_nodes=max_leaf,\n",
    "                              min_weight_fraction_leaf =min_weight,\n",
    "                              min_impurity_decrease=min_impurity\n",
    "                             )\n",
    "   \n",
    "    RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "\n",
    "    y_predict_test = rfc.predict(X_test)\n",
    "    \n",
    "    result=inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'NO')\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest(X_train, X_test, y_train, y_test,scaler_y,200,5,10,20,5,0.1,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest(X_train, X_test, y_train, y_test,scaler_y,200,5,10,20,5,0.1,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percentile=0\n",
    "threshold_for_feature_selection=np.percentile(feature_score[scored_feature_indices], percentile)\n",
    "X_threshold=X.iloc[:,scored_feature_indices[feature_score[scored_feature_indices]>threshold_for_feature_selection]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaled_Train_Test_Split=X_Y_scaler_train_test_Split(X_threshold,y,Z)\n",
    "\n",
    "X_train = Scaled_Train_Test_Split[0]\n",
    "X_test = Scaled_Train_Test_Split[1]\n",
    "y_train = Scaled_Train_Test_Split[2]\n",
    "y_test = Scaled_Train_Test_Split[3]\n",
    "scaler_X = Scaled_Train_Test_Split[4]  \n",
    "scaler_y = Scaled_Train_Test_Split[5]\n",
    "scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "scaled_value_y=Scaled_Train_Test_Split[7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Foest Regressor model\n",
    "rfc=RandomForestRegressor(n_estimators=3000)\n",
    "\n",
    "# Random Foest Regressor model train\n",
    "RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "\n",
    "# Random Foest Regressor mode predict\n",
    "y_predict_test = rfc.predict(X_test)\n",
    "\n",
    "# Compare predicted Y and real Y \n",
    "inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calıstır_randomforest(X_train, X_test, y_train, y_test,scaler_y,Product,MonthSeries,Scaler_Type):\n",
    "#ver2    estimator_options = [200, 300, 350, 400,1000]\n",
    "#ver2    sample_leaf_options = [1,5,10,30,50]\n",
    "    #sample_leaf_options = [1,5,10,20]\n",
    "    #random_state_options =[1,10,50,75,200]\n",
    "#ver2    random_state_options =[10]\n",
    "    #max_features_option=[3,5,10,20]\n",
    "    #max_features_option=[10,20,40,54]\n",
    "#ver2    max_features_option=[10,\"log2\",\"sqrt\",\"auto\"]\n",
    "    \n",
    "    estimation_method='random forest'\n",
    "#ver3    estimator_options = [200, 300]\n",
    "#ver3    min_sample_leaf_options = [5,10]\n",
    "#ver3     random_state_options =[10]\n",
    "#ver3     max_features_option=[10,\"log2\",\"sqrt\",\"auto\"]\n",
    "#ver3    max_leaf_nodes_options=[5] \n",
    "#ver3    min_weight_fraction_leaf_options=[0.01,0.1,0.5] \n",
    "#ver3    min_impurity_decrease_options =[0.00001,0.01,0.05,1]\n",
    "\n",
    "    estimator_options = [200]\n",
    "    min_sample_leaf_options = [5]\n",
    "    random_state_options =[10]\n",
    "    max_features_option=[10]#,\"log2\",\"sqrt\",\"auto\"]\n",
    "    max_leaf_nodes_options=[5] \n",
    "    min_weight_fraction_leaf_options=[0.01] \n",
    "    min_impurity_decrease_options =[0.00001,0.01,0.05,1]\n",
    "\n",
    "\n",
    "    \n",
    "#    estimator_options = [200, 300, 350, 400,1000]\n",
    "#    min_sample_leaf_options = [1,5,10,30,50]\n",
    "#    random_state_options =[10,35,86]\n",
    "#    max_features_option=[10,\"log2\",\"sqrt\",\"auto\"]\n",
    "#    max_leaf_nodes_options=[5,10,35] \n",
    "#    min_weight_fraction_leaf_options=[0.01,0.1,0.5] \n",
    "#    min_impurity_decrease_options =[0.00001,0.01,0.05,1]    \n",
    "    \n",
    "    sonuc = pd.DataFrame(columns='EstMethod Product Scaler MonthSeries EST LEAF FEAT MAX_LEAF MIN_WEIGHT MIN_IMPURITY MAE MSE R2'.split())\n",
    "    i=0\n",
    "    results = pd.DataFrame()\n",
    "    repeats=3\n",
    "    error_r2 = list()\n",
    "    for est in estimator_options:\n",
    "\n",
    "        for min_leaf in min_sample_leaf_options:\n",
    "        \n",
    "            for f in range(0, 1):\n",
    "        \n",
    "                feat=max_features_option[f]\n",
    "       \n",
    "                for random in random_state_options:\n",
    "                    \n",
    "                    for max_leaf in max_leaf_nodes_options:\n",
    "                        \n",
    "                         for min_weight in min_weight_fraction_leaf_options:\n",
    "                                \n",
    "                            for min_impurity in min_impurity_decrease_options:\n",
    "                                \n",
    "                              #  for r in range(repeats):\n",
    "                            \n",
    "                            \n",
    "                                    estimate_metric=randomforest(X_train, X_test, y_train, y_test,scaler_y,est,min_leaf,random,feat,\n",
    "                                                                 max_leaf,min_weight,min_impurity)\n",
    "                                    MAE=estimate_metric[0]\n",
    "                                    MSE=estimate_metric[1]\n",
    "                                    R2=estimate_metric[2]\n",
    "                                    print(MonthSeries,'esti',est,'leaf',min_leaf,'feature',feat,max_leaf,min_weight,min_impurity,MAE,MSE,R2)\n",
    "                                    sonuc.loc[i]=[estimation_method,Product,Scaler_Type,MonthSeries,est,min_leaf,feat,max_leaf,min_weight,min_impurity,MAE,MSE,R2]\n",
    "                                    i=i+1\n",
    "                                    error_r2.append(R2)\n",
    "                                    print(error_r2)\n",
    "                                    \n",
    "                              #  results[str(min_impurity)]=error_r2\n",
    "                              #  print(results)    \n",
    "    return sonuc     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Reduction percentile oranına göre oluyor\n",
    "percentile=25\n",
    "threshold_for_feature_selection=np.percentile(feature_score[scored_feature_indices], percentile)\n",
    "sonuc=pd.DataFrame()\n",
    "for ScalerType in Scaler_Type_Options:\n",
    "\n",
    "    Data_Core=readexcel(Product)\n",
    "    XY=set_Data(Product,Data_Core,MonthSeries)\n",
    "    y=set_y(Product,XY)\n",
    "    Z=set_z(Product,XY)\n",
    "    X=set_X(Product,XY)\n",
    "\n",
    "    \n",
    "    X= Xscaler(X,y,ScalerType)\n",
    "    scaler= MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "       \n",
    "    #Feature Reduction percentile oranına göre oluyor\n",
    "    X=X.loc[:,scored_feature_indices[feature_score[scored_feature_indices]>threshold_for_feature_selection]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "#    sonuc=pd.concat([sonuc,calıstır_randomforest(Product,MonthSeries,ScalerType)])\n",
    "#    sonuc=calıstır_randomforest(Product,MonthSeries,ScalerType)\n",
    "\n",
    "    for MonthSerie in MonthSeries_option:\n",
    "        XY=set_Data(Product,Data_Core,MonthSeries)\n",
    "        y=set_y(Product,XY)\n",
    "        Z=set_z(Product,XY)\n",
    "        X=set_X(Product,XY)\n",
    "\n",
    "        values = y.values\n",
    "        values = values.astype('float32')\n",
    "        scaler_y= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "        scaled_value_y = scaler_y.fit_transform(values)\n",
    "        scaled_value_y = pd.DataFrame(data=scaled_value_y)\n",
    "        \n",
    "        \n",
    "        X= Xscaler(X,y,ScalerType)\n",
    "    \n",
    "        X=X.loc[:,scored_feature_indices[feature_score[scored_feature_indices]>threshold_for_feature_selection]]\n",
    "\n",
    "    \n",
    "#        X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,scaled_value_y,test_size=0.2,random_state=42,stratify=Z['Month'])\n",
    "\n",
    "          sonuc=pd.concat([sonuc,calıstır_randomforest(X_train, X_test, y_train, y_test,scaler_y,Product,MonthSerie,ScalerType)])\n",
    "\n",
    "max_R2=int((sonuc['R2'].max())*1000)/1000\n",
    "filename='Out_Random_Predict_Results_{one}_Product{two}_{four}perc_with max{tre}'.format(one=datetime.now().strftime('Date_%m-%d_Time%H_%M'),\n",
    "                                                                                      two=Product,tre=max_R2,four=percentile)\n",
    "sonuc.to_excel('{}.xlsx'.format(filename),index = False)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#rfc=RandomForestRegressor()\n",
    "#RandomForestRegressor.fit(rfc,X,y)\n",
    "\n",
    "est = 200\n",
    "min_leaf = 5\n",
    "random =10\n",
    "feat=\"log2\"\n",
    "max_leaf=5 \n",
    "min_weight=0.01 \n",
    "min_impurity=0.00001\n",
    "\n",
    "\n",
    "rfc=RandomForestRegressor(n_estimators=est,\n",
    "                              min_samples_leaf=min_leaf,\n",
    "                              random_state =random,\n",
    "                              max_features=feat,\n",
    "                              max_leaf_nodes=max_leaf,\n",
    "                              min_weight_fraction_leaf =min_weight,\n",
    "                              min_impurity_split=min_impurity\n",
    "                             )\n",
    "\n",
    "#rfc=RandomForestRegressor()\n",
    "\n",
    "RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "\n",
    "y_predict_test = rfc.predict(X_test)\n",
    "inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "predictions=inv_y_predict_test\n",
    "\n",
    "inv_y_test = scaler_y.inverse_transform(y_test)\n",
    "inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "\n",
    "print('MAE',int(metrics.mean_absolute_error(inv_y_test, predictions)),\n",
    "      'MSE',int(sqrt(metrics.mean_squared_error(inv_y_test, predictions))),\n",
    "      'R2',int(1000*(metrics.r2_score(inv_y_test, predictions)))/1000\n",
    "     )\n",
    "plt.scatter(inv_y_test,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(sonuc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XY=set_Data(Product,Data_Core,MonthSeries)\n",
    "y=set_y(Product,XY)\n",
    "Z=set_z(Product,XY)\n",
    "X=set_X(Product,XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= Xscaler(X,y,ScalerType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn (alph,max_iteration,slv,random,hidden_layer):\n",
    "    MLP = MLPRegressor(\n",
    "                              alpha = alph,\n",
    "                              solver=slv ,\n",
    "                              max_iter=max_iteration,\n",
    "                              random_state =random,\n",
    "                              hidden_layer_sizes=hidden_layer\n",
    "    )\n",
    "    MLPRegressor.fit(MLP,X_train,y_train)\n",
    "    \n",
    "    predictions = MLP.predict(X_test)\n",
    "    MAE=int(metrics.mean_absolute_error(y_test, predictions))\n",
    "    MSE=int(sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "    R2=int(1000*(metrics.r2_score(y_test, predictions)))/1000\n",
    "    return MAE,MSE,R2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def calıstır_nn(Product,MonthSeries,Scaler_Type):\n",
    "    estimation_method='nn'\n",
    "    alpha_options = [0.0001,0.00000001]\n",
    "    solver_options = ['lbfgs', 'adam' ] # sgd solver cok sapıttı\n",
    "    max_iteration_options = [50000]#,60000,100000]\n",
    "    #random_state_options =[1,10,50,75,200]\n",
    "    #random_state_options =[10,50,90]\n",
    "    random_state_options =[90]\n",
    "    hidden_layer_sizes_options=[(30,100,10)]#,(30,30),(100,100),(30,30,30)]\n",
    "\n",
    "    sonuc = pd.DataFrame(columns='EstMethod Product Scaler MonthSeries alpha max_iteration slv hidden_layer random MAE MSE R2'.split())\n",
    "    i=0\n",
    "\n",
    "    for alpha in alpha_options:\n",
    "    \n",
    "        for max_iteration in max_iteration_options:\n",
    "\n",
    "            for slv in solver_options:\n",
    "        \n",
    "                for hidden_layer in hidden_layer_sizes_options:\n",
    "           \n",
    "                    for random in random_state_options:\n",
    "                \n",
    "                        estimate_metric=nn(alpha,max_iteration,slv,random,hidden_layer)\n",
    "                    \n",
    "                        MAE=estimate_metric[0]\n",
    "                        MSE=estimate_metric[1]\n",
    "                        R2=estimate_metric[2]\n",
    "                        print('iter:',max_iteration,'slvr:',slv,'random:',random,'layers:',hidden_layer,\n",
    "                          MAE,MSE,R2)\n",
    "                        sonuc.loc[i]=[estimation_method,Product,Scaler_Type,MonthSeries,alpha,max_iteration,slv,hidden_layer,random,MAE,MSE,R2]\n",
    "                        i=i+1\n",
    "    return sonuc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Data_Core=readexcel(Product)\n",
    "XY=set_Data(Product,Data_Core,MonthSeries)\n",
    "y=set_y(Product,XY)\n",
    "Z=set_z(Product,XY)\n",
    "X=set_X(Product,XY)\n",
    "\n",
    "values = X.values\n",
    "values = values.astype('float32')\n",
    "scaler_X= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaled_value_X = scaler_X.fit_transform(values)\n",
    "scaled_value_X = pd.DataFrame(data=scaled_value_X[:,:])\n",
    "\n",
    "values = y.values\n",
    "values = values.astype('float32')\n",
    "scaler_y= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaled_value_y = scaler_y.fit_transform(values)\n",
    "scaled_value_y = pd.DataFrame(data=scaled_value_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_value_X,scaled_value_y,test_size=0.2,random_state=42,stratify=Z['Month'])\n",
    "\n",
    "\n",
    "#Data_Core=readexcel(Product)\n",
    "#y=set_y(Product,Data_Core)\n",
    "#X=set_Data(Product,Data_Core,MonthSeries)\n",
    "\n",
    "#X=pd.DataFrame(StandardScaler().fit_transform(X,y))\n",
    "#X= Xscaler(X,y,ScalerType)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "sonuc=calıstır_nn(Product,MonthSeries,ScalerType)\n",
    "filename='Out_NN_Prediction_Results_{one}_Product{two}'.format(one=datetime.now().strftime('Date_%m-%d_Time%H_%M'),two=Product)\n",
    "\n",
    "\"\"\"for MonthSerie in MonthSeries_option:\n",
    "        XY=set_Data(Product,Data_Core,MonthSeries)\n",
    "        y=set_y(Product,XY)\n",
    "        Z=set_z(Product,XY)\n",
    "        X=set_X(Product,XY)\n",
    "\n",
    "        values = X.values\n",
    "        values = values.astype('float32')\n",
    "        scaler_X= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "        scaled_value_X = scaler_X.fit_transform(values)\n",
    "        scaled_value_X = pd.DataFrame(data=scaled_value_X[:,:])\n",
    "\n",
    "        values = y.values\n",
    "        values = values.astype('float32')\n",
    "        scaler_y= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "        scaled_value_y = scaler_y.fit_transform(values)\n",
    "        scaled_value_y = pd.DataFrame(data=scaled_value_y)\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_value_X,scaled_value_y,test_size=0.2,random_state=42,stratify=Z['Month'])\n",
    "\n",
    "    \n",
    "        sonuc=pd.concat([sonuc,calıstır_nn(Product,MonthSerie,ScalerType)])\n",
    "\"\"\"\n",
    "sonuc.to_excel('{}.xlsx'.format(filename),index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Diğer Deneme Calısmaları\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RandomizedSearch ve Grid Search"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf = RandomForestRegressor()\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "rfc=RandomForestRegressor()\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   \n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [\"auto\", \"sqrt\",\"log2\",None],\n",
    "              \"min_samples_split\": sp_randint(2,11),\n",
    "#              \"min_weight_fraction_leaf\": sp_randint(0., 0.5),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "#              \"warm_start\": [True, False],\n",
    "#              \"random_state\": sp_randint(2, 20)\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run randomized search\n",
    "n_iter_search = 50\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use a full grid over all parameters\n",
    "param_grid = {\n",
    "\n",
    "#              \"max_depth\": [3, None],\n",
    "#              \"max_features\": [\"auto\", \"sqrt\",\"log2\",None],\n",
    "#              \"min_samples_split\": [2, 3, 10],\n",
    "#              \"min_samples_split\": [2],\n",
    "#              \"min_samples_leaf\": [1, 3, 10, 20],\n",
    "#              \"bootstrap\": [True, False],\n",
    "#              \"criterion\": [\"gini\", \"entropy\"]\n",
    "    \"n_estimators\":[200, 300, 350, 400,1000],\n",
    "    \"min_samples_leaf\" :[1,5,10],\n",
    "    \"random_state\" : [10],\n",
    "    \"max_features\":[1,2]\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#    \"n_estimators\":[200, 300, 350, 400,1000],\n",
    "#    \"min_samples_leaf\" :[1,5,10],\n",
    "#    \"random_state\" : [10],\n",
    "#    \"max_features\":[3,5,10,20],\n",
    "\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
