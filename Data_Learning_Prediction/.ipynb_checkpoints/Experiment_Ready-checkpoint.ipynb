{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Sources_and_Preparation')\n",
    "#os.chdir('C:/Users/murat.ozemre/Documents/MOZEMRE-OZEL/Doktora/2017 Tez/Veri Analizi/Ver 3 Tez Izleme Calısmaları')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statsmodels: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import statsmodels\n",
    "print('statsmodels: %s' % statsmodels.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12-27 13:40'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from math import log\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scaler_Type_Options = ['Normalizer', 'MinMaxScaler','MaxAbsScaler','RobustScaler','StandardScaler' ]\n",
    "Scaler_Type_Options = [ 'MinMaxScaler' ]\n",
    "Scalertype=Scaler_Type_Options[0]\n",
    "Product_Type_Options = [841810,841840,841850]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MinMaxScaler'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scalertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Product=Product_Type_Options[0] #841810\n",
    "Exp_Country='TUR' # 'CHN'\n",
    "Imp_Country='GBR'\n",
    "\n",
    "if Exp_Country=='CHN':\n",
    "    Currency='CNY'\n",
    "    EXP0='TUR'   \n",
    "elif Exp_Country=='TUR':\n",
    "    Currency='TRY'\n",
    "    EXP0='CHN'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841810"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MonthSeries=\"3\"\n",
    "MonthSeries_option=[\"1\",\"2\",\"3\",\"6\",\"12\"]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Core1 = pd.ExcelFile('Data_{}_{}_{}.xlsx'.format(Exp_Country,Imp_Country,Product))\n",
    "y = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])['{}_{}_{}'.format(Exp_Country,Imp_Country,Product)]\n",
    "Z = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])[['Date','Year','Month']]\n",
    "\n",
    "X = Data_Core1.parse('X{}'.format(MonthSeries), header=0,index_col=None, na_values=['NA'])\n",
    "X.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "X_Column_Names=list(X.columns.values)\n",
    "n_feature=X.shape[1]\n",
    "\n",
    "Xhat = Data_Core1.parse('Xhat', header=0,index_col=None, na_values=['NA'])\n",
    "Xhat.drop(['Date','Year','Month'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Xscaler(X,y,scalertype):\n",
    "\n",
    "    if scalertype==\"Normalizer\":\n",
    "        X=pd.DataFrame(Normalizer().fit_transform(X,y))\n",
    "        print(\"normalize\")\n",
    "    elif scalertype==\"MinMaxScaler\":\n",
    "        X=pd.DataFrame(MinMaxScaler().fit_transform(X,y))\n",
    "        print(\"minmax\")\n",
    "    elif scalertype==\"MaxAbsScaler\":\n",
    "        X=pd.DataFrame(MaxAbsScaler().fit_transform(X,y))\n",
    "        print(\"maxabs\")\n",
    "    elif scalertype==\"RobustScaler\":\n",
    "        X=pd.DataFrame(RobustScaler().fit_transform(X,y))\n",
    "    elif scalertype==\"StandardScaler\":\n",
    "        X=pd.DataFrame(StandardScaler().fit_transform(X,y))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling Min Max and then spilt test and train according stratify to month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def X_Y_scaler_train_test_Split(X,y,Z,random=42):\n",
    "\n",
    "    values = X.values\n",
    "    values = values.astype('float32')\n",
    "    X_Column_X_Column_Names=X.columns\n",
    "    \n",
    "    scaler_X= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_X = scaler_X.fit_transform(values)\n",
    "    scaled_value_X = pd.DataFrame(data=scaled_value_X[:,:])\n",
    "    scaled_value_X.columns=X_Column_X_Column_Names\n",
    "    \n",
    "    values = y.values\n",
    "    values = values.astype('float32')\n",
    "    values = values.reshape(-1, 1)\n",
    "    \n",
    "    scaler_y= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_y = scaler_y.fit_transform(values)\n",
    "    scaled_value_y = pd.DataFrame(data=scaled_value_y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_value_X,scaled_value_y,test_size=0.2,random_state=42,stratify=Z['Month'])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler_X, scaler_y, scaled_value_X, scaled_value_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,plot_on):\n",
    "\n",
    "    y_predict_test=y_predict_test.reshape(-1, 1)\n",
    "    inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "    predictions=inv_y_predict_test\n",
    "\n",
    "  \n",
    "    inv_y_test = scaler_y.inverse_transform(y_test)\n",
    "    inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "    MAE=int(metrics.mean_absolute_error(inv_y_test, predictions))\n",
    "    MSE=int(sqrt(metrics.mean_squared_error(inv_y_test, predictions)))\n",
    "    R2=int(1000*(metrics.r2_score(inv_y_test, predictions)))/1000\n",
    "    \n",
    "    \n",
    "    print('MAE',MAE, 'MSE',MSE, 'R2',R2 )\n",
    "    \n",
    "    if plot_on =='YES':\n",
    "        plt.scatter(inv_y_test,predictions)\n",
    "    \n",
    "    return MAE,MSE,R2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302585092994046"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# R' Denemesi İçin Kod parcası\n",
    "def inverse_scale_and_graph_Y_predict_and_test_R2(y_predict_test,y_test,scaler_y,plot_on):\n",
    "\n",
    "    y_predict_test=y_predict_test.reshape(-1, 1)\n",
    "    inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "    \n",
    "    predictions=log(inv_y_predict_test)\n",
    "\n",
    "  \n",
    "    inv_y_test = scaler_y.inverse_transform(y_test)\n",
    "    inv_y_test = log(inv_y_test[:,0])\n",
    "\n",
    "    MAE=int(metrics.mean_absolute_error(inv_y_test, predictions))\n",
    "    MSE=int(sqrt(metrics.mean_squared_error(inv_y_test, predictions)))\n",
    "    R2=int(1000*(metrics.r2_score(inv_y_test, predictions)))/1000\n",
    "    \n",
    "    \n",
    "    print('MAE',MAE, 'MSE',MSE, 'R2',R2 )\n",
    "    \n",
    "    if plot_on =='YES':\n",
    "        plt.scatter(inv_y_test,predictions)\n",
    "    \n",
    "    return MAE,MSE,R2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Scaled_Train_Test_Split=X_Y_scaler_train_test_Split(X,y,Z)\n",
    "\n",
    "X_train = Scaled_Train_Test_Split[0]\n",
    "X_test = Scaled_Train_Test_Split[1]\n",
    "y_train = Scaled_Train_Test_Split[2]\n",
    "y_test = Scaled_Train_Test_Split[3]\n",
    "scaler_X = Scaled_Train_Test_Split[4]  \n",
    "scaler_y = Scaled_Train_Test_Split[5]\n",
    "scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "scaled_value_y=Scaled_Train_Test_Split[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For Random Forest with variable tuning \n",
    "\n",
    "def randomforest(X_train, X_test, y_train, y_test,scaler_y,est=10,min_leaf=1,random=50,feat='auto',max_leaf=None,min_weight=0.0,min_impurity=1e-07):\n",
    "    from sklearn.model_selection import cross_val_score   \n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    \n",
    "    rfc=RandomForestRegressor(n_estimators=est,\n",
    "                              min_samples_leaf=min_leaf,\n",
    "                              random_state =random,\n",
    "                              max_features=feat,\n",
    "                              max_leaf_nodes=max_leaf,\n",
    "                              min_weight_fraction_leaf =min_weight,\n",
    "                              min_impurity_decrease=min_impurity\n",
    "                            )\n",
    "   \n",
    "    RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "\n",
    "    y_predict_test = rfc.predict(X_test)\n",
    "    y_predict_train = rfc.predict(X_train)\n",
    "    \n",
    "    result_test=inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'NO')\n",
    "    result_train=inverse_scale_and_graph_Y_predict_and_test(y_predict_train,y_train,scaler_y,'NO')\n",
    "    \n",
    "    return result_test, result_train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 2667 MSE 3585 R2 0.424\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-ec9bcb11a742>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Compare predicted Y and real Y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0minverse_scale_and_graph_Y_predict_and_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaler_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'YES'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0minverse_scale_and_graph_Y_predict_and_test_R2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaler_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'YES'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-fdc0c8bb4cde>\u001b[0m in \u001b[0;36minverse_scale_and_graph_Y_predict_and_test_R2\u001b[1;34m(y_predict_test, y_test, scaler_y, plot_on)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minv_y_predict_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minv_y_predict_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzKo4OZiZWRUnBzMzq/L/AZCIyZmtu6QVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cbc0b6c2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Decison tree regressor model\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# Decison tree regressor model train\n",
    "DecisionTreeRegressor.fit(dt,X_train,y_train)\n",
    "\n",
    "# Decison tree regressor model predict\n",
    "y_predict_test = dt.predict(X_test)\n",
    "\n",
    "# Compare predicted Y and real Y \n",
    "inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'YES')\n",
    "inverse_scale_and_graph_Y_predict_and_test_R2(y_predict_test,y_test,scaler_y,'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Foest Regressor model\n",
    "rfc=RandomForestRegressor(n_estimators=3000)\n",
    "\n",
    "# Random Foest Regressor model train\n",
    "RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "\n",
    "# Random Foest Regressor mode predict\n",
    "y_predict_test = rfc.predict(X_test)\n",
    "\n",
    "# Compare predicted Y and real Y \n",
    "inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1 Version for Feature selection\n",
    "# Internetten bulunan kod blogu\n",
    "# Random Forest'a gore Feature Importance Hesaplama\n",
    "# Butun veri setinin girildiği ona göre önemli olan özelliklerin bulundugu kod parçası\n",
    "\n",
    "ScalerType = Scalertype=Scaler_Type_Options[0]\n",
    "n_sample=len(X)\n",
    "\n",
    "rfc=RandomForestRegressor(n_estimators=3000)\n",
    "RandomForestRegressor.fit(rfc,scaled_value_X,scaled_value_y)\n",
    "\n",
    "\n",
    "predictions = rfc.predict(X_test)\n",
    "print('MAE',int(metrics.mean_absolute_error(y_test, predictions)),\n",
    "      'MSE',int(sqrt(metrics.mean_squared_error(y_test, predictions))),\n",
    "      'R2',int(1000*(metrics.r2_score(y_test, predictions)))/1000\n",
    "     )\n",
    "\n",
    "\n",
    "importances = rfc.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rfc.estimators_],axis=0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(n_feature):\n",
    "    print(\"%d. feature %s %d (%f) %f\" % (f+1, X_Column_Names[indices[f]], indices[f], importances[indices[f]],std[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"{} and -{} Month Feature Importances and Standart Deviation of Features with 3000 Different Estimations\".format(Product,MonthSeries))\n",
    "plt.bar(range(n_feature), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(n_feature), indices,rotation=90)\n",
    "plt.xlim([-1, n_feature])\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 15\n",
    "fig_size[1] = 10\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.savefig(\"Plots_Feature_Selection/{} and -{} Month Feature Importances and Standart Deviation of Features with 3000 Different Estimations.png\".format(Product,MonthSeries), format='png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  2 Version for Feature selection \n",
    "# Internetten bulunan kod blogu http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "# Feature Importance Hesaplama\n",
    "# Burada asıl özellik bir veri seti yaratılıyor make_regression ile. Ve oaradakilere dogru çalışıp çalışmadığı test ediliyor.\n",
    "# Butun veri setinin girildiği ona göre önemli olan özelliklerin bulundugu kod parçası\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "\n",
    "n_sample=len(X)\n",
    "\n",
    "number_of_split=100\n",
    "number_of_row=29\n",
    "\n",
    "random_state_options = np.arange(0,number_of_split)\n",
    "y_predict= np.ones((number_of_row, number_of_split))\n",
    "\n",
    "feature_indices = np.ones((n_feature, number_of_split))\n",
    "feature_importances=np.ones((n_feature, number_of_split))\n",
    "feature_indices_score=np.ones((n_feature))\n",
    "feature_importances_score=np.ones((n_feature))\n",
    "j=0\n",
    "\n",
    "\n",
    "# For different split sets Random Forest Regressor runs.\n",
    "\n",
    "for random_state_i in random_state_options:\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_value_X,scaled_value_y,test_size=0.2,random_state=random_state_i,stratify=Z['Month'])\n",
    "\n",
    "    \n",
    "\n",
    "    rfc=RandomForestRegressor(n_estimators=30)\n",
    "    RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "\n",
    "    y_predict[:,j] = rfc.predict(X_test)\n",
    "    \n",
    "    result=inverse_scale_and_graph_Y_predict_and_test (y_predict[:,j],y_test,scaler_y,'NO')\n",
    "    \n",
    "    importances = rfc.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in rfc.estimators_],axis=0)\n",
    "\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    feature_indices[:,j]=indices\n",
    "    feature_importances[:,j]=importances\n",
    "    j=j+1\n",
    "    \n",
    "\n",
    "print (\"Features scores:\")    \n",
    "for i in range(n_feature):\n",
    "    feature_indices_score[i]=0\n",
    "    feature_importances_score[i]=0\n",
    "    for j in range(number_of_split):\n",
    "        \n",
    "        indice_coeff=feature_indices[i,j]\n",
    "        importances_coeff=feature_importances[i,j]\n",
    "        \n",
    "        feature_indices_score[i]=feature_indices_score[i]+(indice_coeff)\n",
    "        feature_importances_score[i]=feature_importances_score[i]+(importances_coeff)\n",
    "        \n",
    "#        print('feat=',i,'#ofsplit=',j,'tot_indice',feature_indices_score[i],\n",
    "#              'indice=',indice_coeff,'tot_importan=',feature_importances_score[i],'importan',importances_coeff )\n",
    "\n",
    "    print( i,X_Column_Names[i])#,feature_indices_score[i],'number_of_split',j+1) #,X_Column_Names[feature_indices[i,j]])\n",
    "    \n",
    "scored_feature_indices = np.argsort(feature_indices_score)\n",
    "scored_feature_importances = np.argsort(feature_importances_score)\n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "# Plot the feature importances of the forest\n",
    "plt.gcf().clear()\n",
    "plt.figure()\n",
    "plt.title(\"{} and -{} Month Cumulative Feature Importances with {} Different Splits.png\".format(Product,MonthSeries,number_of_split))\n",
    "plt.bar(range(n_feature), feature_importances_score[scored_feature_importances][::-1],\n",
    "       color=\"r\",  align=\"center\")\n",
    "plt.xticks(range(n_feature), scored_feature_importances[::-1],rotation=90)\n",
    "plt.xlim([-1, n_feature])\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 20\n",
    "fig_size[1] = 12\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.savefig(\"Plots_Feature_Selection/{} and -{} Month Cumulative Feature Importances with {} Different Splits.png\".format(Product,MonthSeries,number_of_split), format='png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3 Version for Train Test Split and Feature selection \n",
    "# http://blog.datadive.net/selecting-good-features-part-iii-random-forests/\n",
    "# Use both RF Importances and R2 Accuracy with different number of splits\n",
    "\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter, attrgetter\n",
    "\n",
    "def getKey(item):\n",
    "    return item[0]\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "\n",
    "number_of_split=100\n",
    "number_of_row=29\n",
    "\n",
    "\n",
    "\n",
    "random_state_options = np.arange(0,number_of_split)\n",
    "predictions= np.ones((number_of_row, number_of_split))\n",
    "y_predict= np.ones((number_of_row, number_of_split))\n",
    "\n",
    "feature_indices = np.ones((n_feature, number_of_split))\n",
    "feature_importances=np.ones((n_feature, number_of_split))\n",
    "feature_indices_score=np.ones((n_feature))\n",
    "feature_importances_score=np.ones((n_feature))\n",
    "\n",
    "scores = defaultdict(list)\n",
    "#feature_indices = \n",
    "feature_std = np.ones((n_feature, number_of_split))\n",
    "feature_score=np.zeros((n_feature))\n",
    "\n",
    "#R2=defaultdict(list)\n",
    "R2=np.ones(number_of_split)\n",
    "j=0\n",
    "\n",
    "sonuc =[]\n",
    "\n",
    "\n",
    "for random_state_i in random_state_options:\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size=0.2,random_state=random_state_i,stratify=Z['Month'])\n",
    "\n",
    "    RandomForestRegressor.fit(rf,X_train, Y_train)    \n",
    "\n",
    "    y_predict[:,j] = rf.predict(X_test)\n",
    "    \n",
    "    acc = int(1000*(r2_score(Y_test, rf.predict(X_test))))/1000\n",
    "    R2[j] = int(1000*(r2_score(Y_test, rf.predict(X_test))))/1000\n",
    "        \n",
    "    importances = rf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    std = np.std([tree.feature_importances_ for tree in rf.estimators_],axis=0)\n",
    "\n",
    "\n",
    "    feature_importances[:,j]=importances\n",
    "    feature_indices[:,j]=indices\n",
    "    feature_std [:,j]=std\n",
    "\n",
    "    j=j+1\n",
    "\n",
    "R2_Adj=1-R2\n",
    "score_coefficient=n_feature*(R2_Adj - np.max(R2_Adj))/-np.ptp(R2_Adj)\n",
    "\n",
    "    \n",
    "print (\"Features scores:\")    \n",
    "for i in range(n_feature):\n",
    "    feature_score[i]=0\n",
    "    feature_indices_score[i]=0\n",
    "    feature_importances_score[i]=0\n",
    "    \n",
    "    for j in range(number_of_split):\n",
    "        \n",
    "        indice_coeff=feature_indices[i,j]+1\n",
    "        importances_coeff=int((feature_importances[i,j]*10000))/10000\n",
    "        score_coeff=int((score_coefficient[j]+1)*10)/10\n",
    "\n",
    "        feature_indices_score[i]=feature_indices_score[i]+(indice_coeff)\n",
    "        feature_importances_score[i]=feature_importances_score[i]+(importances_coeff)\n",
    "\n",
    "        score=score_coeff*(importances_coeff)\n",
    "        feature_score[i]=feature_score[i]+score\n",
    "\n",
    "\n",
    "#    print( feature_score[i],'number_of_split',j+1) #,X_Column_Names[feature_indices[i,j]])\n",
    "    \n",
    "scored_feature_indices = (np.argsort(feature_score)[::-1])\n",
    "\n",
    "for f in range(n_feature):\n",
    "    print(\"%d. feature %s %d (%f) %f\" % (f+1, X_Column_Names[scored_feature_indices[f]], scored_feature_indices[f], importances[scored_feature_indices[f]],std[scored_feature_indices[f]]))\n",
    "\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.gcf().clear()\n",
    "plt.figure()\n",
    "plt.title(\"{} and {} Month Cumulative Feature and Score Importances with {} Different Splits\".format(Product,MonthSeries,number_of_split))\n",
    "plt.bar(range(n_feature), feature_score[scored_feature_indices],\n",
    "       color=\"r\",  align=\"center\")\n",
    "plt.xticks(range(n_feature), scored_feature_indices,rotation=90)\n",
    "plt.xlim([-1, n_feature])\n",
    "\n",
    "#fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "#fig_size[0] = 20\n",
    "#fig_size[1] = 12\n",
    "#plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.savefig(\"Plots_Feature_Selection/{} and {} Month Cumulative Feature and Score Importances with {} Different Splits.png\".format(Product,MonthSeries,number_of_split), format='png', dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calling function by single parameter set \n",
    "a=randomforest(X_train, X_test, y_train, y_test,scaler_y,200,5,10,10,5,0.1,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# By using Ver 3 for Feature Selection results\n",
    "# Percentile variable takes the most important variables according to its feature score and omits the others.\n",
    "# ie.25 percentile takes %75 importance variables and omits %25 least important features\n",
    "\n",
    "percentile=25\n",
    "threshold_for_feature_selection=np.percentile(feature_score[scored_feature_indices], percentile)\n",
    "X_threshold=X.iloc[:,scored_feature_indices[feature_score[scored_feature_indices]>threshold_for_feature_selection]]\n",
    "\n",
    "# Train Test Split after percentile selection\n",
    "\n",
    "Scaled_Train_Test_Split=X_Y_scaler_train_test_Split(X_threshold,y,Z)\n",
    "\n",
    "X_train = Scaled_Train_Test_Split[0]\n",
    "X_test = Scaled_Train_Test_Split[1]\n",
    "y_train = Scaled_Train_Test_Split[2]\n",
    "y_test = Scaled_Train_Test_Split[3]\n",
    "scaler_X = Scaled_Train_Test_Split[4]  \n",
    "scaler_y = Scaled_Train_Test_Split[5]\n",
    "scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "scaled_value_y=Scaled_Train_Test_Split[7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Foest Regressor model\n",
    "rfc=RandomForestRegressor(n_estimators=3000,random_state=50)\n",
    "\n",
    "# Random Foest Regressor model train\n",
    "RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "\n",
    "# Random Foest Regressor mode predict\n",
    "y_predict_test = rfc.predict(X_test)\n",
    "\n",
    "# Compare predicted Y and real Y \n",
    "inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest(X_train, X_test, y_train, y_test,scaler_y,est=3000,random=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
