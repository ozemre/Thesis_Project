{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murat.ozemre\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\murat.ozemre\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "C:\\Users\\murat.ozemre\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "from math import sqrt\n",
    "from math import exp\n",
    "import math\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.layers import Dense,Input, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from random import gauss\n",
    "from random import seed\n",
    "#from pandas import Series\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from random import randrange\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import gauss\n",
    "from random import seed\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "from scipy.stats.stats import pearsonr    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'07-15 15:57'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Experiment_Ready as experim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\murat.ozemre\\\\Desktop\\\\Thesis_Project\\\\Data_Learning_Prediction'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Product_Type_Options = [841810,841840,841850]\n",
    "Product=Product_Type_Options[0] #841810\n",
    "\n",
    "Productname=Product\n",
    "Exp_Country='TUR' # 'CHN'\n",
    "Imp_Country='GBR'\n",
    "\n",
    "if Exp_Country=='CHN':\n",
    "    Currency='CNY'\n",
    "    EXP0='TUR'   \n",
    "elif Exp_Country=='TUR':\n",
    "    Currency='TRY'\n",
    "    EXP0='CHN'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TUR\n"
     ]
    }
   ],
   "source": [
    "#Default values\n",
    "\n",
    "dependenttype='same'\n",
    "percent=100\n",
    "\n",
    "\n",
    "if Exp_Country=='CHN':\n",
    "        \n",
    "        if Product==841810:\n",
    "            MonthSeries=\"_34\"\n",
    "            percent=50\n",
    "            dependenttype='same'\n",
    "        elif Product==841840:\n",
    "            MonthSeries=\"_345\"\n",
    "            percent=50\n",
    "            dependenttype='log'\n",
    "        elif Product==841850:\n",
    "            MonthSeries=\"_34\"\n",
    "            percent=100\n",
    "            dependenttype='log'\n",
    "elif Exp_Country=='TUR':\n",
    "    \n",
    "        if Product==841810:\n",
    "            MonthSeries=\"_456\"\n",
    "            percent=50\n",
    "            dependenttype='same'\n",
    "        elif Product==841840:\n",
    "            MonthSeries=\"4\"\n",
    "            percent=50\n",
    "            dependenttype='log'\n",
    "        elif Product==841850:\n",
    "            MonthSeries=\"_45\"\n",
    "            percent=50\n",
    "            dependenttype='same'\n",
    "\n",
    "print(Exp_Country)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Sources_and_Preparation')\n",
    "\n",
    "Data_Core1 = pd.ExcelFile('Data_{}_{}_{}.xlsx'.format(Exp_Country,Imp_Country,Product))\n",
    "y = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])['{}_{}_{}'.format(Exp_Country,Imp_Country,Product)]\n",
    "Z = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])[['Date','Year','Month']]\n",
    "\n",
    "X = Data_Core1.parse('X{}'.format(MonthSeries), header=0,index_col=None, na_values=['NA'])\n",
    "X.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "X_Column_Names=list(X.columns.values)\n",
    "n_feature=X.shape[1]\n",
    "\n",
    "#y=y.iloc[3:]\n",
    "#X=X.iloc[3:,:]\n",
    "#Z=Z.iloc[3:,:]\n",
    "\n",
    "Xhat = Data_Core1.parse('Xhat', header=0,index_col=None, na_values=['NA'])\n",
    "Xhat.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if dependenttype=='same':\n",
    "    dependent_variable=y\n",
    "elif dependenttype=='log':\n",
    "    dependent_variable=y.apply(np.log)\n",
    "elif dependenttype=='sqrt':\n",
    "    dependent_variable=y.apply(np.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate Feature Importace according Month Series\n",
    "number_of_split_for_feature=100\n",
    "result=experim.get_feature_importance_result (X,dependent_variable,Z,n_feature,number_of_split_for_feature)\n",
    "scored_feature_indices=result[0]\n",
    "feature_score=result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Omit Features according percentage\n",
    "percentile=100-percent\n",
    "threshold_for_feature_selection=np.percentile(feature_score[scored_feature_indices], percentile)\n",
    "X_threshold=X.iloc[:,scored_feature_indices[feature_score[scored_feature_indices]>threshold_for_feature_selection]]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 58, 61,  1, 60, 57, 30, 62, 63, 80, 42, 44, 59, 72, 35, 70, 34,\n",
       "       23, 81, 79,  9, 24, 33, 53, 52, 29, 14,  4,  0, 10, 38, 32, 51, 49,\n",
       "       56, 64, 65,  8, 67, 73, 82,  6, 28,  7,  5, 25, 40, 19, 12, 26, 37,\n",
       "       41, 31, 16, 69, 77, 68, 27, 83,  3, 13, 36, 76, 21, 11, 39, 54, 45,\n",
       "       74, 50, 55, 17, 66, 22, 78, 43, 15, 47, 48, 20, 75, 18, 71, 46],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_feature_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set X train, X test, y train, y test\n",
    "rs=42 # 841810 -3\n",
    "\n",
    "Scaled_Train_Test_Split=experim.X_Y_scaler_train_test_Split(X_threshold,dependent_variable,Z,random=rs)\n",
    "\n",
    "X_train = Scaled_Train_Test_Split[0]\n",
    "X_test = Scaled_Train_Test_Split[1]\n",
    "y_train = Scaled_Train_Test_Split[2]\n",
    "y_test = Scaled_Train_Test_Split[3]\n",
    "scaler_X = Scaled_Train_Test_Split[4]  \n",
    "scaler_y = Scaled_Train_Test_Split[5]\n",
    "scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "scaled_value_y=Scaled_Train_Test_Split[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomforest rs= 44\n",
      "R2_Test 0.838 R2_Train 0.968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1490,\n",
       "  1920,\n",
       "  0.838,\n",
       "  0.838,\n",
       "  array([1.50000000e+01, 3.80799997e+03, 1.63370000e+04, 2.97399998e+03,\n",
       "         9.30000059e+01, 3.64699982e+03, 8.97100004e+03, 5.46800028e+03,\n",
       "         1.14269999e+04, 4.21500006e+03, 1.03650003e+04, 7.28000011e+03,\n",
       "         1.11379999e+04, 1.81199997e+04, 9.60100012e+03, 1.33380006e+04,\n",
       "         3.75499985e+03, 1.49190007e+04, 9.51900014e+03, 7.62200053e+03,\n",
       "         9.40000032e+03, 6.04400020e+03, 9.67400008e+03, 1.48550008e+04,\n",
       "         1.45309998e+04, 7.54800024e+03, 1.27859997e+04, 3.86000006e+03,\n",
       "         1.20939998e+04]),\n",
       "  array([  942.87001559,  4978.70319508, 12278.71455652,  3721.40651838,\n",
       "          2259.2730559 ,  4274.88434933,  9769.13917487,  4085.49589628,\n",
       "         12539.64315071,  2901.17785477,  9923.77807611,  7991.91839867,\n",
       "          9729.75382399, 13703.21264895,  9829.52503183, 13045.39762519,\n",
       "          4249.57532463, 14077.84093619, 11698.70027742, 11292.54357724,\n",
       "         10727.1052767 ,  8121.69015698, 12065.33130172, 14077.17518317,\n",
       "         10567.33240816,  4944.98230284, 12961.90055558,  4013.52173249,\n",
       "         12869.24870538])),\n",
       " (648,\n",
       "  835,\n",
       "  0.968,\n",
       "  0.968,\n",
       "  array([1.06770008e+04, 1.34220000e+04, 4.50699987e+03, 9.47900049e+03,\n",
       "         8.18600002e+03, 1.18070005e+04, 4.61900004e+03, 8.86600012e+03,\n",
       "         1.94499994e+03, 1.37639999e+04, 6.26400040e+03, 5.79600020e+03,\n",
       "         2.78799982e+03, 6.03000030e+03, 3.66599992e+03, 1.07650004e+04,\n",
       "         4.90700000e+03, 2.68700005e+03, 9.24400005e+03, 3.67299987e+03,\n",
       "         6.12200004e+03, 1.15769999e+04, 9.51600034e+03, 2.38199992e+03,\n",
       "         1.53220007e+04, 7.42100013e+03, 1.10390002e+04, 1.18119997e+04,\n",
       "         2.45999986e+02, 1.28770003e+04, 6.89300015e+03, 7.80200047e+03,\n",
       "         2.66599989e+03, 5.36500044e+03, 1.01310008e+04, 1.24469997e+04,\n",
       "         1.06710000e+04, 9.24300032e+03, 1.21250006e+04, 9.35400045e+03,\n",
       "         7.19900046e+03, 3.61200005e+03, 1.24289997e+04, 1.34499998e+04,\n",
       "         1.12460002e+04, 4.04799999e+03, 1.00000000e+01, 7.51800035e+03,\n",
       "         1.20479999e+04, 4.05999983e+03, 3.93899993e+03, 1.34139997e+04,\n",
       "         3.38100006e+03, 1.65359998e+04, 1.87420001e+04, 5.87199996e+03,\n",
       "         1.14060000e+04, 7.11700049e+03, 1.23999998e+03, 1.25930008e+04,\n",
       "         6.27600023e+03, 6.69400042e+03, 5.95100013e+03, 9.97699998e+03,\n",
       "         7.44000052e+03, 6.22800029e+03, 4.19999981e+03, 7.68300005e+03,\n",
       "         1.71630006e+04, 6.02400008e+03, 8.30899999e+03, 1.02069999e+04,\n",
       "         6.98000001e+03, 6.37300046e+03, 4.76399990e+03, 9.93599999e+03,\n",
       "         6.86000045e+03, 1.06059997e+04, 1.01790001e+04, 1.08239999e+04,\n",
       "         4.37100003e+03, 5.51100034e+03, 6.39700013e+03, 1.38480005e+04,\n",
       "         1.59520001e+04, 4.67600001e+03, 6.55400013e+03, 6.68000051e+03,\n",
       "         1.09519997e+04, 1.44840008e+04, 7.14800011e+03, 2.96399991e+03,\n",
       "         1.77890000e+04, 1.13490000e+04, 1.31069997e+04, 7.86500006e+03,\n",
       "         4.15099983e+03, 3.97299997e+03, 6.49700016e+03, 8.05800017e+03,\n",
       "         1.24759999e+04, 4.30099988e+03, 6.21500012e+03, 2.02059993e+04,\n",
       "         5.74700052e+03, 6.46600054e+03, 1.39300005e+04, 7.75400053e+03,\n",
       "         1.35770006e+04, 8.65100041e+03, 6.96400003e+03, 3.49799981e+03,\n",
       "         4.49600007e+03, 1.60619999e+04, 1.34620003e+04]),\n",
       "  array([ 9777.13029113, 13082.56973633,  4636.68865536,  9738.72904432,\n",
       "          9215.22666629, 12038.71282434,  4517.88686195,  7286.09610887,\n",
       "          2575.33831897, 12855.82994976,  7089.43762217,  5854.54683424,\n",
       "          3697.22659522,  5794.31438978,  4218.47997742,  9815.24148835,\n",
       "          5220.68007537,  3051.57916295,  9739.22516432,  4169.0042969 ,\n",
       "          5719.22939382, 10349.25136425, 11016.83315319,  3432.71498076,\n",
       "         14566.83044875,  8131.62883574, 11046.93414096, 10110.84007445,\n",
       "          2125.98304268, 12541.68990811,  6310.54850059,  8900.71469154,\n",
       "          3270.86248578,  4957.34128161, 10651.14883036, 12176.78055725,\n",
       "         10651.10672932,  9227.89490825, 13171.73522235, 10383.5063427 ,\n",
       "          8578.34871506,  4042.83322803, 13351.29180732, 11842.33529367,\n",
       "         11474.04855391,  4423.57351725,   876.63001948,  8052.31000827,\n",
       "         11599.72651623,  4491.40827431,  4586.18920651, 12448.16626578,\n",
       "          3282.95337171, 15444.40988682, 17392.26836936,  5581.8608514 ,\n",
       "         10912.45139093,  7199.92433591,  2126.60099623, 11716.75060116,\n",
       "          7837.1267508 ,  6055.51946112,  5880.97562949, 10033.87403526,\n",
       "          8284.26650897,  6632.02120286,  4986.0614558 ,  7968.32063955,\n",
       "         15005.4938148 ,  5583.36556216,  8613.47510143, 10391.54604966,\n",
       "          6706.96889765,  5955.62659546,  5052.11999074, 10787.4432244 ,\n",
       "          7316.23946231, 10684.86156857, 10587.0583235 , 11770.53877773,\n",
       "          4910.13338064,  4833.10122733,  6111.15487919, 13473.70488409,\n",
       "         13969.34515783,  5041.07338776,  7536.13515135,  6195.87105116,\n",
       "         10767.7689445 , 13900.48962528,  7040.34480534,  3386.82142902,\n",
       "         16188.55590089, 10239.15178644, 11372.95074801,  8035.36811313,\n",
       "          4521.3264255 ,  3956.97785939,  6048.71768762,  8161.63570904,\n",
       "         12848.3499414 ,  4488.9199486 ,  7114.72873223, 17425.77826399,\n",
       "          5195.40621897,  5827.50912779, 13681.71819289,  8160.48202024,\n",
       "         13334.08341957,  9441.85765203,  7523.39358656,  3380.09305922,\n",
       "          4137.64539432, 14131.87436756, 13395.53571965])))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experim.randomforest(X_train, X_test, y_train, y_test,scaler_y,est=100,\n",
    "                       rand=20,is_random_fixed='FALSE',dependenttype=dependenttype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomforest rs= 7\n",
      "R2_Test 0.822 R2_Train 0.958\n",
      "randomforest rs= 30\n",
      "R2_Test 0.788 R2_Train 0.951\n",
      "randomforest rs= 36\n",
      "R2_Test 0.791 R2_Train 0.948\n",
      "randomforest rs= 26\n",
      "R2_Test 0.759 R2_Train 0.935\n",
      "randomforest rs= 98\n",
      "R2_Test 0.766 R2_Train 0.949\n",
      "randomforest rs= 59\n",
      "R2_Test 0.804 R2_Train 0.944\n",
      "randomforest rs= 3\n",
      "R2_Test 0.79 R2_Train 0.948\n",
      "randomforest rs= 58\n",
      "R2_Test 0.78 R2_Train 0.951\n",
      "randomforest rs= 70\n",
      "R2_Test 0.791 R2_Train 0.937\n",
      "randomforest rs= 33\n",
      "R2_Test 0.829 R2_Train 0.951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.788"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experim.experiment_RandomForest(10,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                                rand=20,is_random_fixed='FALSE',dependenttype=dependenttype)[1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomforest rs= 68\n",
      "R2_Test 0.81 R2_Train 0.95\n",
      "randomforest rs= 31\n",
      "R2_Test 0.832 R2_Train 0.954\n",
      "randomforest rs= 93\n",
      "R2_Test 0.814 R2_Train 0.96\n",
      "randomforest rs= 80\n",
      "R2_Test 0.795 R2_Train 0.945\n",
      "randomforest rs= 22\n",
      "R2_Test 0.788 R2_Train 0.955\n",
      "randomforest rs= 71\n",
      "R2_Test 0.811 R2_Train 0.961\n",
      "randomforest rs= 98\n",
      "R2_Test 0.766 R2_Train 0.949\n",
      "randomforest rs= 71\n",
      "R2_Test 0.811 R2_Train 0.961\n",
      "randomforest rs= 15\n",
      "R2_Test 0.782 R2_Train 0.946\n",
      "randomforest rs= 85\n",
      "R2_Test 0.8 R2_Train 0.936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.81, 0.832, 0.814, 0.795, 0.788, 0.811, 0.766, 0.811, 0.782, 0.8],\n",
       " [0.81, 0.832, 0.814, 0.795, 0.788, 0.811, 0.766, 0.811, 0.782, 0.8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experim.experiment_RandomForest(10,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                                rand=20,is_random_fixed='FALSE',dependenttype=dependenttype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomforest rs= 85\n",
      "R2_Test 0.831 R2_Train 0.97\n",
      "randomforest rs= 85\n",
      "R2_Test 0.831 R2_Train 0.97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.831, 0.831], [0.831, 0.831])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TUR 841840 RS =43\n",
    "experim.experiment_RandomForest(2,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,est=3000,rand=85,dependenttype=dependenttype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START OF RANDOM FOREST EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Learning_Prediction/Box_Plots_For_RandomForest/{}'.format(Exp_Country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAIN for Random Forest Experiments\n",
    "# EXPERIMENT (with fixed split set) 1 For \"max_features_options\"\n",
    "repeats=5\n",
    "\n",
    "# Initialize results\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "# Defaults for variables for the first experiment\n",
    "feat=10\n",
    "min_leaf=5\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "est=200\n",
    "\n",
    "# Get the range for variables\n",
    "max_features_options=[10,\"log2\",\"sqrt\",\"auto\"]\n",
    "min_sample_leaf_options = [1,2,5,20,30]\n",
    "max_leaf_nodes_options=[2,5,10,100,200,300] \n",
    "min_impurity_decrease_options =[0.000001,0.00001,0.001,0.01]\n",
    "min_weight_fraction_leaf_options=[0.00001,0.0001,0.001,0.01,0.1] \n",
    "estimator_options = [100,200,500,1000,5000,10000,20000]\n",
    "\n",
    "rs=42\n",
    "\n",
    "    \n",
    "#Scaled_Train_Test_Split=experim.X_Y_scaler_train_test_Split(X_threshold,dependent_variable,Z,random=rs)\n",
    "\n",
    "#X_train = Scaled_Train_Test_Split[0]\n",
    "#X_test = Scaled_Train_Test_Split[1]\n",
    "#y_train = Scaled_Train_Test_Split[2]\n",
    "#y_test = Scaled_Train_Test_Split[3]\n",
    "#scaler_X = Scaled_Train_Test_Split[4]  \n",
    "#scaler_y = Scaled_Train_Test_Split[5]\n",
    "#scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "#scaled_value_y=Scaled_Train_Test_Split[7]\n",
    "    \n",
    "    \n",
    "for feat in max_features_options:\n",
    "        results_exp[str(feat)] =experim.experiment_RandomForest(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype,\n",
    "                  est=est,min_leaf=min_leaf,feat=feat,max_leaf=max_leaf,min_weight=min_weight,min_impurity=min_impurity)[1] \n",
    "    \n",
    "results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(Productname,MonthSeries,  est, min_leaf,rs,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(Productname,MonthSeries,est,min_leaf,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "results.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAIN for Random Forest Experiments\n",
    "# EXPERIMENT (with fixed split set) 2 for max_features_options \n",
    "\n",
    "# Get the best of from previous experiment\n",
    "feat=10\n",
    "\n",
    "# Initialize results\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "   \n",
    "for min_leaf in min_sample_leaf_options:\n",
    "            results_exp[str(min_leaf)] =experim.experiment_RandomForest(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype,\n",
    "                  est=est,min_leaf=min_leaf,feat=feat,max_leaf=max_leaf,min_weight=min_weight,min_impurity=min_impurity)[1] \n",
    "    \n",
    "        \n",
    "results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "#save boxplot\n",
    "\n",
    "\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(Productname,MonthSeries,  est, min_sample_leaf_options,rs,feat,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(Productname,MonthSeries,est,min_sample_leaf_options,feat,max_leaf,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "results.median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAIN for Random Forest Experiments\n",
    "# EXPERIMENT (with fixed split set) 3 for max_leaf_nodes_options \n",
    "\n",
    "# Get the best of from previous experiment\n",
    "min_leaf=5\n",
    "\n",
    "# Initialize results\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "  \n",
    "for max_leaf in max_leaf_nodes_options:\n",
    "                results_exp[str(max_leaf)]  =experim.experiment_RandomForest(repeats,\n",
    "                X_train, X_test, y_train, y_test,scaler_y,\n",
    "                rand=20,is_random_fixed='FALSE',dependenttype=dependenttype,\n",
    "                est=est,min_leaf=min_leaf,feat=feat,max_leaf=max_leaf,min_weight=min_weight,min_impurity=min_impurity)[1] \n",
    "    \n",
    "results=pd.concat([results,results_exp])\n",
    "            \n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(Productname,MonthSeries,  est, min_leaf,rs,feat,max_leaf_nodes_options,min_weight,min_impurity))\n",
    "plt.savefig('RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(Productname,MonthSeries,est,min_leaf,feat,max_leaf_nodes_options,min_weight,min_impurity))\n",
    "results.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAIN for Random Forest Experiments\n",
    "# EXPERIMENT (with fixed split set) 4 for min_impurity_decrease_options\n",
    "\n",
    "# Get the best of from previous experiment\n",
    "max_leaf=10\n",
    "\n",
    "\n",
    "# Initialize results\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "for min_impurity in min_impurity_decrease_options:\n",
    "                results_exp[str(min_impurity)]  =experim.experiment_RandomForest(repeats,\n",
    "                X_train, X_test, y_train, y_test,scaler_y,\n",
    "                rand=20,is_random_fixed='FALSE',dependenttype=dependenttype,\n",
    "                est=est,min_leaf=min_leaf,feat=feat,max_leaf=max_leaf,min_weight=min_weight,min_impurity=min_impurity)[1] \n",
    "    \n",
    "results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(Productname,MonthSeries,  est, min_leaf,rs,feat,max_leaf,min_weight,min_impurity_decrease_options))\n",
    "plt.savefig('RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weig,{}min_impu.png'\n",
    "               .format(Productname,MonthSeries,est,min_leaf,feat,max_leaf,min_weight,min_impurity_decrease_options))\n",
    "results.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAIN for Random Forest Experiments\n",
    "# EXPERIMENT (with fixed split set) 5 for min_weight_fraction_leaf_options\n",
    "\n",
    "# Get the best of from previous experiment\n",
    "min_impurity=1e-06\n",
    "\n",
    "# Initialize results\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "for min_weight in min_weight_fraction_leaf_options:\n",
    "                results_exp[str(min_weight)]  =experim.experiment_RandomForest(repeats,\n",
    "                X_train, X_test, y_train, y_test,scaler_y,\n",
    "                rand=20,is_random_fixed='FALSE',dependenttype=dependenttype,\n",
    "                est=est,min_leaf=min_leaf,feat=feat,max_leaf=max_leaf,min_weight=min_weight,min_impurity=min_impurity)[1] \n",
    "    \n",
    "results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(Productname,MonthSeries,  est, min_leaf,rs,feat,max_leaf,min_weight_fraction_leaf_options,min_impurity))\n",
    "plt.savefig('RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weig,{}min_impu.png'\n",
    "               .format(Productname,MonthSeries,est,min_leaf,feat,max_leaf,min_weight_fraction_leaf_options,min_impurity))\n",
    "results.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAIN for Random Forest Experiments\n",
    "# EXPERIMENT (with fixed split set) 6 for estimator_options\n",
    "\n",
    "# Get the best of from previous experiment\n",
    "min_weight=0.1 \n",
    "\n",
    "\n",
    "# Initialize results\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "for est in estimator_options:\n",
    "            results_exp[str(est)] =experim.experiment_RandomForest(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype,\n",
    "                  est=est,min_leaf=min_leaf,feat=feat,max_leaf=max_leaf,min_weight=min_weight,min_impurity=min_impurity)[1] \n",
    "    \n",
    "results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(Productname,MonthSeries,  estimator_options, min_leaf,rs,feat,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} minweig,{}minimp.png'\n",
    "               .format(Productname,MonthSeries,estimator_options,min_leaf,feat,max_leaf,min_weight,min_impurity))\n",
    "results.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best of from previous experiment\n",
    "est=1000\n",
    "\n",
    "when=datetime.now().strftime('%m-%d %H:%M')\n",
    "print(\"Product=\",Productname)\n",
    "print(\"Month = \",MonthSeries)\n",
    "print(\"percent =\",percent)\n",
    "print(\"dependenttype =\",dependenttype)\n",
    "\n",
    "\n",
    "#Tuned Parameters after experiments\n",
    "print(\"max_features=\",feat) # EXP1\n",
    "print(\"min_sample_leaf=\", min_leaf) # EXP2\n",
    "print(\"max_leaf_nodes=\", max_leaf) # EXP3\n",
    "print(\"min_impurity_decrease=\", min_impurity) # EXP4\n",
    "print(\"min_weight_fraction_leaf=\", min_weight) # EXP5\n",
    "print(\"est=\", est) # EXP6\n",
    "\n",
    "\n",
    "# store as parameters\n",
    "parameters=[Product,Exp_Country,Imp_Country,MonthSeries,percent,dependenttype,rs,feat,min_leaf,max_leaf,min_impurity,min_weight,est,when]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAIN for Random Forest Experiments\n",
    "# EXPERIMENT (with fixed split set) for Before Tuning and After Tuning \n",
    "\n",
    "tune_options=[ 'Not_Tuned','Tuned']\n",
    "\n",
    "# Initialize results\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "repeats=20\n",
    "\n",
    "for tune in tune_options:\n",
    "    \n",
    "            if tune=='Tuned':\n",
    "                print(tune)\n",
    "                \n",
    "                results_exp[str(tune)] =experim.experiment_RandomForest(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype,\n",
    "                  est=est,min_leaf=min_leaf,feat=feat,max_leaf=max_leaf,min_weight=min_weight,min_impurity=min_impurity)[1] \n",
    "    \n",
    "            elif tune=='Not_Tuned':\n",
    "                print(tune)\n",
    "                \n",
    "            # Defaults for variables for the first experiment\n",
    "\n",
    "                results_exp[str(tune)] =experim.experiment_RandomForest(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype)[1] \n",
    "    \n",
    "    \n",
    "    \n",
    "results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{}, Before and After Tuning, {} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity  \"\n",
    "          .format(Productname,MonthSeries, est, min_leaf,rs,feat,max_leaf,min_weight,min_impurity))\n",
    "\n",
    "plt.savefig(\"RF-BoxPlotfor {}-{}, Before and After Tuning with fixed splits.png \"\n",
    "          .format(Productname,MonthSeries), format='png', dpi=300)\n",
    "\n",
    "tuned_results_fixed_split=[results['Tuned'].describe()[5],results['Tuned'].describe()[6]]\n",
    "results.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAIN for Random Forest Experiments\n",
    "# EXPERIMENT (with different split sets) for Before Tuning and After Tuning \n",
    "\n",
    "\n",
    "# Initialize results\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "\n",
    "repeats=20\n",
    "random_range_for_split=5\n",
    "\n",
    "for r in range (random_range_for_split):\n",
    "\n",
    "    rs=random.randint(1,100)\n",
    "\n",
    "    print('split rs=',rs)\n",
    "    \n",
    "    Scaled_Train_Test_Split=experim.X_Y_scaler_train_test_Split(X_threshold,dependent_variable,Z,random=rs)\n",
    "\n",
    "    X_train = Scaled_Train_Test_Split[0]\n",
    "    X_test = Scaled_Train_Test_Split[1]\n",
    "    y_train = Scaled_Train_Test_Split[2]\n",
    "    y_test = Scaled_Train_Test_Split[3]\n",
    "    scaler_X = Scaled_Train_Test_Split[4]  \n",
    "    scaler_y = Scaled_Train_Test_Split[5]\n",
    "    scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "    scaled_value_y=Scaled_Train_Test_Split[7]\n",
    "     \n",
    "    \n",
    "    for tune in tune_options:\n",
    "    \n",
    "            if tune=='Not_Tuned':\n",
    "                \n",
    "                results_exp[str(tune)]  =experim.experiment_RandomForest(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype)[1] \n",
    "\n",
    "                            \n",
    "            elif tune=='Tuned':\n",
    "                \n",
    "                results_exp[str(tune)] =experim.experiment_RandomForest(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype,\n",
    "                  est=est,min_leaf=min_leaf,feat=feat,max_leaf=max_leaf,min_weight=min_weight,min_impurity=min_impurity)[1] \n",
    "                \n",
    "    results=pd.concat([results,results_exp])\n",
    "    \n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{}, Before and After Tuning, {} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity  \"\n",
    "          .format(Productname,MonthSeries, est, min_leaf,rs,feat,max_leaf,min_weight,min_impurity))\n",
    "\n",
    "plt.savefig(\"RF-Box Plot for {}-{}, Before and After Tuning with different splits.png \"\n",
    "          .format(Productname,MonthSeries), format='png', dpi=300)\n",
    "\n",
    "tuned_results_mixed_split=[results['Tuned'].describe()[5],results['Tuned'].describe()[6]]\n",
    "results.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Learning_Prediction')\n",
    "# Read from Excel Tuning paremeters\n",
    "Tuned_set = pd.ExcelFile('Tuned_Parameters.xlsx'.format(Exp_Country,Imp_Country,Product))\n",
    "Tuned_set_RF_all = Tuned_set.parse('RF', header=0,index_col=None, na_values=['NA'])\n",
    "Tuned_set_NN_all = Tuned_set.parse('NN', header=0,index_col=None, na_values=['NA'])\n",
    "\n",
    "\n",
    "# For this experiment \n",
    "tuned_results_RF=tuned_results_fixed_split+tuned_results_mixed_split\n",
    "\n",
    "Tuned_set_RF =  DataFrame(columns='Product Exp Imp Month dependenttype perc rs_split max_features min_sample_leaf max_leaf_nodes min_impurity min_weight est Datetime fix_p50 fix_p75 mix_p50 mix_p75'.split())\n",
    "Tuned_set_RF.loc[0]= parameters + tuned_results_RF\n",
    "\n",
    "# Combine with the other experiments \n",
    "Tuned_set_RF_all= pd.concat([Tuned_set_RF_all,Tuned_set_RF])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Learning_Prediction')\n",
    "# Write to Excel this and previous Tuning paremeters\n",
    "writer = pd.ExcelWriter('Tuned_Parameters.xlsx')\n",
    "Tuned_set_RF_all.to_excel(writer,'RF')\n",
    "Tuned_set_NN_all.to_excel(writer,'NN')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF RANDOM FOREST EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START OF NN EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Learning_Prediction/Box_Plots_For_NeuralNetworks/{}'.format(Exp_Country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experim.NeuralNetwork(X_train, X_test, y_train, y_test,scaler_y,rand=41,dependenttype=dependenttype)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experim.experiment_NN(3,X_train, X_test, y_train, y_test,scaler_y,is_random_fixed='FALSE',dependenttype=dependenttype)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAIN for Neural Network Experiments\n",
    "# EXPERIMENT (with fixed split set) 1 For \"solver_options\"\n",
    "\n",
    "repeats=5\n",
    "\n",
    "# Initialize results\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "# Defaults for variables for the first experiment\n",
    "slv='adam'\n",
    "activ ='identity'\n",
    "alph=0.0001 \n",
    "max_iteration=200  \n",
    "hidden_layer=(30,30)\n",
    "\n",
    "# Get the range for variables\n",
    "solver_options = ['lbfgs', 'adam','sgd' ]\n",
    "activation_options = ['identity', 'logistic', 'tanh', 'relu']\n",
    "alpha_options = [0.001,0.00001,0.0000001]\n",
    "max_iteration_options = [1000,10000,50000,100000]\n",
    "hidden_layer_sizes_options=[(10,10),(30,30),(100,100),(30,30,30),(30,100,30)]\n",
    "\n",
    "rs=42\n",
    "\n",
    "    \n",
    "Scaled_Train_Test_Split=experim.X_Y_scaler_train_test_Split(X_threshold,dependent_variable,Z,random=rs)\n",
    "\n",
    "X_train = Scaled_Train_Test_Split[0]\n",
    "X_test = Scaled_Train_Test_Split[1]\n",
    "y_train = Scaled_Train_Test_Split[2]\n",
    "y_test = Scaled_Train_Test_Split[3]\n",
    "scaler_X = Scaled_Train_Test_Split[4]  \n",
    "scaler_y = Scaled_Train_Test_Split[5]\n",
    "scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "scaled_value_y=Scaled_Train_Test_Split[7]\n",
    "    \n",
    "    \n",
    "for slv in solver_options:\n",
    "        results_exp[str(slv)] =experim.experiment_NN(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype,\n",
    "                  activ=activ,alph=alph,max_iteration=max_iteration, slv=slv, hidden_layer=hidden_layer)[1] \n",
    "    \n",
    "results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"NN-Box Plot for {}-{}, {}solver, {}activ, {}alpha, {}max_ite, {}hiddenlayer \"\n",
    "          .format(Productname,MonthSeries, solver_options, activ, alph, max_iteration, hidden_layer))\n",
    "\n",
    "plt.savefig(\"NN-Box Plot for {}-{}, {}solver, {}activ, {}alpha, {}max_ite, {}layer.png \"\n",
    "          .format(Productname,MonthSeries,solver_options, activ,alph, max_iteration,hidden_layer), format='png', dpi=300)\n",
    "results.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN for Neural Network Experiments\n",
    "# EXPERIMENT (with fixed split set) 2 for activation__options \n",
    "\n",
    "slv='lbfgs'\n",
    "# Get the best of from previous experiment\n",
    "\n",
    "# Initialize results\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "for activ in activation_options:\n",
    "        results_exp[str(activ)] =experim.experiment_NN(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype,\n",
    "                  activ=activ,alph=alph,max_iteration=max_iteration, slv=slv, hidden_layer=hidden_layer)[1] \n",
    "    \n",
    "results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"NN-Box Plot for {}-{}, {}solver, {}activ, {}alpha, {}max_ite, {}hiddenlayer \"\n",
    "          .format(Productname,MonthSeries, slv, activation_options, alph, max_iteration, hidden_layer))\n",
    "\n",
    "plt.savefig(\"NN-Box Plot for {}-{}, {}solver, {}activ, {}alpha, {}max_ite, {}layer.png \"\n",
    "          .format(Productname,MonthSeries, slv, activation_options, alph, max_iteration, hidden_layer), format='png', dpi=300)\n",
    "results.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN for Neural Network Experiments\n",
    "# EXPERIMENT (with fixed split set) 3 for alpha_options \n",
    "\n",
    "activ ='identity'\n",
    "# Get the best of from previous experiment\n",
    "\n",
    "# Initialize results\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    " \n",
    "for alph in alpha_options:\n",
    "        results_exp[str(alph)] =experim.experiment_NN(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype,\n",
    "                  activ=activ,alph=alph,max_iteration=max_iteration, slv=slv, hidden_layer=hidden_layer)[1] \n",
    "    \n",
    "results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"NN-Box Plot for {}-{}, {}solver, {}activ, {}alpha, {}max_ite, {}hiddenlayer \"\n",
    "          .format(Productname,MonthSeries, slv, activ, alpha_options, max_iteration, hidden_layer))\n",
    "\n",
    "plt.savefig(\"NN-Box Plot for {}-{}, {}solver, {}activ, {}alpha, {}max_ite, {}layer.png \"\n",
    "          .format(Productname,MonthSeries, slv, activ, alpha_options, max_iteration, hidden_layer), format='png', dpi=300)\n",
    "results.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAIN for Neural Network Experiments\n",
    "# EXPERIMENT (with fixed split set) 4 for hidden_layer_sizes_options\n",
    "\n",
    "alph=1e-05\n",
    "\n",
    "# Get the best of from previous experiment\n",
    "\n",
    "# Initialize results\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "for hidden_layer in hidden_layer_sizes_options:\n",
    "        results_exp[str(hidden_layer)] =experim.experiment_NN(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype,\n",
    "                  activ=activ,alph=alph,max_iteration=max_iteration, slv=slv, hidden_layer=hidden_layer)[1] \n",
    "    \n",
    "results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"NN-Box Plot for {}-{}, {}solver, {}activ, {}alpha, {}max_ite, {}hiddenlayer \"\n",
    "          .format(Productname,MonthSeries, slv, activ, alph, max_iteration, hidden_layer_sizes_options))\n",
    "\n",
    "plt.savefig(\"NN-Box Plot for {}-{}, {}solver, {}activ, {}alpha, {}max_ite, {}layer.png \"\n",
    "          .format(Productname,MonthSeries, slv, activ, alph, max_iteration, hidden_layer_sizes_options), format='png', dpi=300)\n",
    "results.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAIN for Neural Network Experiments\n",
    "# EXPERIMENT (with fixed split set) 5 for max_iteration_options\n",
    "\n",
    "hidden_layer=(100,100)\n",
    "\n",
    "# Get the best of from previous experiment\n",
    "\n",
    "# Initialize results\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "for max_iteration in max_iteration_options:\n",
    "        results_exp[str(max_iteration)] =experim.experiment_NN(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype,\n",
    "                  activ=activ,alph=alph,max_iteration=max_iteration, slv=slv, hidden_layer=hidden_layer)[1] \n",
    "    \n",
    "results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"NN-Box Plot for {}-{}, {}solver, {}activ, {}alpha, {}max_ite, {}hiddenlayer \"\n",
    "          .format(Productname,MonthSeries, slv, activ, alph, max_iteration_options, hidden_layer))\n",
    "\n",
    "plt.savefig(\"NN-Box Plot for {}-{}, {}solver, {}activ, {}alpha, {}max_ite, {}layer.png \"\n",
    "          .format(Productname,MonthSeries, slv, activ, alph, max_iteration_options, hidden_layer), format='png', dpi=300)\n",
    "results.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iteration=100000\n",
    "# Get the best of from previous experiment\n",
    "\n",
    "when=datetime.now().strftime('%m-%d %H:%M')\n",
    "\n",
    "print(\"Product=\",Productname)\n",
    "print(\"Month = \",MonthSeries)\n",
    "print(\"rs for split\",rs)\n",
    "\n",
    "\n",
    "print(\"percent\",percent)\n",
    "print(\"dependenttype\",dependenttype)\n",
    "\n",
    "#Tuned Parameters after experiments\n",
    "print(\"solver=\",slv) # EXP1\n",
    "print(\"activity=\", activ) # EXP2\n",
    "print(\"alpha=\", alph) # EXP3\n",
    "print(\"hidden_layer=\", hidden_layer) # EXP4\n",
    "print(\"max_iteration=\", max_iteration) # EXP5\n",
    "\n",
    "# store as parameters\n",
    "parameters=[Product,Exp_Country,Imp_Country,MonthSeries,percent,dependenttype, rs,slv,activ,alph,hidden_layer,max_iteration,when]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN for Neural Network Experiments\n",
    "# EXPERIMENT (with fixed split set) for Before Tuning and After Tuning \n",
    "\n",
    "\n",
    "# Initialize results\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "tune_options=[ 'Not_Tuned','Tuned']\n",
    "\n",
    "for tune in tune_options:\n",
    "\n",
    "        if tune=='Tuned':\n",
    "            print(tune)\n",
    "            \n",
    "\n",
    "            results_exp[str(tune)] =experim.experiment_NN(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype,\n",
    "                  activ=activ,alph=alph,max_iteration=max_iteration, slv=slv, hidden_layer=hidden_layer)[1] \n",
    "    \n",
    "        elif tune=='Not_Tuned':\n",
    "            print(tune)\n",
    "                \n",
    "            # Defaults for variables for the first experiment\n",
    "            results_exp[str(tune)] =experim.experiment_NN(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype)[1] \n",
    "    \n",
    "    \n",
    "results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "\n",
    "plt.title(\"NN-Box Plot for {}-{}, Before and After Tuning, {}solver, {}activ, {}alpha, {}max_ite, {}hiddenlayer \"\n",
    "          .format(Productname,MonthSeries, slv, activ, alph, max_iteration,hidden_layer))\n",
    "\n",
    "plt.savefig(\"NN-Box Plot for {}-{}, Before and After Tuning with fixed splits.png \"\n",
    "          .format(Productname,MonthSeries), format='png', dpi=300)\n",
    "\n",
    "tuned_results_fixed_split=[results['Tuned'].describe()[5],results['Tuned'].describe()[6]]\n",
    "results.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MAIN for Neural Network Experiments\n",
    "# EXPERIMENT (with different split sets) for Before Tuning and After Tuning \n",
    "\n",
    "\n",
    "# Initialize results\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "\n",
    "repeats=5\n",
    "random_range_for_split=5\n",
    "\n",
    "for r in range (random_range_for_split):\n",
    "\n",
    "    rs=random.randint(1,100)\n",
    "\n",
    "    print('split rs=',rs)\n",
    "    \n",
    "    Scaled_Train_Test_Split=experim.X_Y_scaler_train_test_Split(X_threshold,dependent_variable,Z,random=rs)\n",
    "\n",
    "    X_train = Scaled_Train_Test_Split[0]\n",
    "    X_test = Scaled_Train_Test_Split[1]\n",
    "    y_train = Scaled_Train_Test_Split[2]\n",
    "    y_test = Scaled_Train_Test_Split[3]\n",
    "    scaler_X = Scaled_Train_Test_Split[4]  \n",
    "    scaler_y = Scaled_Train_Test_Split[5]\n",
    "    scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "    scaled_value_y=Scaled_Train_Test_Split[7]\n",
    "     \n",
    "    \n",
    "    for tune in tune_options:\n",
    "    \n",
    "            if tune=='Not_Tuned':\n",
    "                \n",
    "                results_exp[str(tune)] =experim.experiment_NN(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype)[1] \n",
    "                        \n",
    "            elif tune=='Tuned':\n",
    "                \n",
    "                results_exp[str(tune)] =experim.experiment_NN(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',dependenttype=dependenttype,\n",
    "                  activ=activ,alph=alph,max_iteration=max_iteration, slv=slv, hidden_layer=hidden_layer)[1] \n",
    "              \n",
    "    results=pd.concat([results,results_exp])\n",
    "    \n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"NN-Box Plot for {}-{}, Before and After Tuning, {}solver, {}activ, {}alpha, {}max_ite, {}hiddenlayer \"\n",
    "          .format(Productname,MonthSeries,slv, activ, alph, max_iteration,hidden_layer))\n",
    "\n",
    "plt.savefig(\"NN-Box Plot for {}-{}, Before and After Tuning with different splits.png \"\n",
    "          .format(Productname,MonthSeries), format='png', dpi=300)\n",
    "\n",
    "tuned_results_mixed_split=[results['Tuned'].describe()[5],results['Tuned'].describe()[6]]\n",
    "results.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read from Excel Tuning paremeters\n",
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Learning_Prediction')\n",
    "Tuned_set = pd.ExcelFile('Tuned_Parameters.xlsx'.format(Exp_Country,Imp_Country,Product))\n",
    "Tuned_set_RF_all = Tuned_set.parse('RF', header=0,index_col=None, na_values=['NA'])\n",
    "Tuned_set_NN_all = Tuned_set.parse('NN', header=0,index_col=None, na_values=['NA'])\n",
    "\n",
    "# For this experiment \n",
    "tuned_results_NN=tuned_results_fixed_split+tuned_results_mixed_split\n",
    "\n",
    "Tuned_set_NN =  DataFrame(columns='Product Exp Imp Month dependenttype perc rs_split Solver Activity Alpha Hidden_layer Max_iteration Datetime fix_p50 fix_p75 mix_p50 mix_p75'.split())\n",
    "Tuned_set_NN.loc[0]= parameters + tuned_results_NN\n",
    "\n",
    "# Combine with the other experiment \n",
    "Tuned_set_NN_all= pd.concat([Tuned_set_NN_all,Tuned_set_NN])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF NN EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Learning_Prediction')\n",
    "# Write to Excel this and previous Tuning paremeters\n",
    "writer = pd.ExcelWriter('Tuned_Parameters.xlsx')\n",
    "Tuned_set_RF_all.to_excel(writer,'RF')\n",
    "Tuned_set_NN_all.to_excel(writer,'NN')\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Conclusion Of Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM EXPERIMENT (with fixed split set) SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Learning_Prediction/Plots_for_LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "\n",
    "repeats = 1\n",
    "e=500\n",
    "n=100\n",
    "lr=0.001\n",
    "b=50\n",
    "deney=experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)\n",
    "deney[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rs=29\n",
    "rs=42\n",
    "repeats = 1\n",
    "drop_rate=0.0\n",
    "do_batch='TRUE'\n",
    "do_model='B'\n",
    "random_split='TRUE'\n",
    "\n",
    "e=5\n",
    "n=300\n",
    "lr=0.01\n",
    "b=1\n",
    "\n",
    "# Set X train, X test, y train, y test\n",
    "rs=42\n",
    "Scaled_Train_Test_Split=X_Y_scaler_train_test_Split(X,dependent_variable,Z,random=rs)\n",
    "\n",
    "X_train = Scaled_Train_Test_Split[0].values\n",
    "X_test = Scaled_Train_Test_Split[1].values\n",
    "y_train = Scaled_Train_Test_Split[2].values\n",
    "y_test = Scaled_Train_Test_Split[3].values\n",
    "scaler_X = Scaled_Train_Test_Split[4]  \n",
    "scaler_y = Scaled_Train_Test_Split[5]\n",
    "scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "scaled_value_y=Scaled_Train_Test_Split[7]\n",
    "\n",
    "\n",
    "deney=experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,X_train, X_test, y_train, y_test,scaler_X,scaler_y)\n",
    "\n",
    "error_rmse=deney[0] \n",
    "error_r2=deney[1] \n",
    "error_r2hat=deney[2] \n",
    "train_y=deney[3]\n",
    "history=deney[4]\n",
    "print(error_r2)\n",
    "print(error_r2hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "repeats = 10\n",
    "e=100\n",
    "n=50\n",
    "lr=0.05\n",
    "b=50\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for b in batch_sizes:\n",
    "            results_exp[str(b)] = experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"LSTM-Box Plot for {}-{}, {} epochs,{} neurons,{} learning_rate {}batch size \"\n",
    "          .format(Productname,MonthSeries,e,n,lr,batch_sizes))\n",
    "plt.savefig('Data/LSTM-Box Plot for {}-{}, {} epochs,{} neurons{}lr,{}bsize.png'\n",
    "               .format(Productname,MonthSeries,e,n,lr,batch_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rs=29\n",
    "rs=42\n",
    "repeats = 1\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "e=200\n",
    "n=400\n",
    "lr=0.001\n",
    "b=30\n",
    "\n",
    "train_X=SplitData[0] \n",
    "test_X=SplitData[1] \n",
    "train_y=SplitData[2] \n",
    "test_y=SplitData[3]\n",
    "scaler_x=SplitData[4]\n",
    "scaler_y=SplitData[5]\n",
    "\n",
    "deney=experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)\n",
    "\n",
    "error_rmse=deney[0] \n",
    "error_r2=deney[1] \n",
    "error_r2hat=deney[2] \n",
    "train_y=deney[3]\n",
    "history=deney[4]\n",
    "print(error_r2)\n",
    "print(error_r2hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#repeats=5\n",
    "e=2000\n",
    "n=100\n",
    "lr=0.05\n",
    "b=50\n",
    "\n",
    "neurons = [5, 50, 100]\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for n in neurons:\n",
    "            results_exp[str(n)] = experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"LSTM-Box Plot for {}-{}, {} epochs,{} neurons,{} learning_rate {}batch size\"\n",
    "          .format(Productname,MonthSeries,e,neurons,lr,b))\n",
    "plt.savefig('Data/LSTM-Box Plot for {}-{}, {} epochs,{} neurons{},lr{}, b.png'\n",
    "               .format(Productname,MonthSeries,e,neurons,lr,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LSTM EXPERIMENT\n",
    "\n",
    "#def experiment(repeats,n_epochs,n_neurons,learning_rate,bs,rs,X,y,date):\n",
    "def experiment_LSTM(repeats,n_epochs,n_neurons,learning_rate,bs,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y):\n",
    "    K.clear_session()\n",
    "\n",
    "#    print(type(train_X))\n",
    "    train_X =train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "#    train_X =train_X.reshape((train_X.shape[0], train_X.shape[1],1))\n",
    "#    test_X = test_X.reshape((test_X.shape[0], test_X.shape[1],1))\n",
    "#    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    " \n",
    "    \n",
    "    error_rmse = list()\n",
    "    error_r2hat = list()\n",
    "    error_r2 = list()\n",
    "    for r in range(repeats):\n",
    "        \n",
    "        print('Shape of X Train',train_X.shape[1],train_X.shape[2])\n",
    "    \n",
    "\n",
    "        if do_model=='A':\n",
    "            model = Sequential() \n",
    "            model.add(LSTM(n_neurons,input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "            model.add(Dropout(drop_rate))\n",
    "            \n",
    "            model.add(Dense(n_neurons))\n",
    "            model.add(Dropout(drop_rate))\n",
    "            \n",
    "            model.add(Dense(1))\n",
    "#            model.add(Activation('sigmoid'))\n",
    "            model.add(Activation('linear'))\n",
    "        \n",
    "        elif do_model=='B':   \n",
    "            input_layer=Input(shape=(train_X.shape[1], train_X.shape[2]),dtype='float32')\n",
    "            lstm_layer1=LSTM(n_neurons,input_shape=(train_X.shape[1],train_X.shape[2]),\n",
    "                         dropout=drop_rate, \n",
    "                         recurrent_dropout=drop_rate,\n",
    "                         return_sequences=True)(input_layer)\n",
    "            lstm_layer2=LSTM(n_neurons,input_shape=(train_X.shape[1],n_neurons),\n",
    "                         dropout=drop_rate, \n",
    "                         recurrent_dropout=drop_rate,\n",
    "                         return_sequences=False)(lstm_layer1)\n",
    "            dropout_layer=Dropout(drop_rate)(lstm_layer2)\n",
    "\n",
    "            output_layer=Dense(1,activation=\"linear\")(dropout_layer)\n",
    "#            output_layer=Dense(1,activation=\"linear\")(lstm_layer2)\n",
    "         \n",
    "\n",
    "        #ix layerlarda Activation için RELU Output için linear uygun oluyor. Kaynak Siraj Raval\n",
    "        \n",
    "            model=Model(inputs=input_layer, outputs=output_layer)\n",
    "        \n",
    "        \n",
    "        #decay_rate = learning_rate / n_epochs\n",
    "        \n",
    "        decay_rate = 0.8\n",
    "        momentum = 0.9\n",
    "         \n",
    "        sgd = optimizers.SGD(lr=learning_rate, clipvalue=0.3,momentum=momentum, decay=decay_rate,nesterov=True)\n",
    "        adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\n",
    "\n",
    "        #model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        \n",
    "        \n",
    "#        model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "        model.compile(loss='mean_squared_error', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "#        model=load_model(os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(Productname,n_neurons)))\n",
    "#        model=load_model(os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(Productname,n_neurons)))\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "        save_weights_at=os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(Productname,n_neurons))\n",
    "\n",
    "        save_best=ModelCheckpoint(save_weights_at, monitor='val_loss', verbose=0,\n",
    "                                 save_best_only=True, save_weights_only=False, mode='min',\n",
    "                                 period=1)\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.00001)\n",
    "        early_stop = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "        \n",
    "        history = model.fit(train_X, train_y, epochs=n_epochs, batch_size=bs, \n",
    "\n",
    "                            validation_data=(test_X, test_y), verbose=1, \n",
    "#                            callbacks=[reduce_lr],\n",
    "                           # callbacks=[save_best],\n",
    "\n",
    "                           # callbacks=[early_stop],\n",
    "                            shuffle=False)\n",
    "\n",
    "#        best_model=load_model(os.path.join('Data','train_dataset.hdf5')\n",
    "#        model=load_model(os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(Productname,n_neurons)))\n",
    "\n",
    "        #model=best_model\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # summarize history for loss\n",
    "        plt.gcf().clear()\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        # summarize history for accuracy\n",
    "#        plt.plot(history.history['acc'])\n",
    "#        plt.plot(history.history['val_acc'])\n",
    "#        plt.title('model accuracy')\n",
    "#        plt.ylabel('accuracy')\n",
    "#        plt.xlabel('epoch')\n",
    "#        plt.legend(['train', 'test'], loc='upper left')\n",
    "#        plt.show()\n",
    "\n",
    "\n",
    "#        test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[1]))\n",
    "\n",
    "        test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "        inv_x_test = scaler_x.inverse_transform(test_X_reshaped)\n",
    "        inv_x_test = pd.DataFrame(data=inv_x_test[:,:])\n",
    "\n",
    "        # make a prediction\n",
    "        y_predict_test = model.predict(test_X)\n",
    "        y_predict_train = model.predict(train_X)\n",
    "\n",
    "        # invert scaling for forecast\n",
    "        inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "        inv_y_predict_test = inv_y_predict_test[:,0]\n",
    "        inv_y_predict_train = scaler_y.inverse_transform(y_predict_train)\n",
    "        inv_y_predict_train = inv_y_predict_train[:,0]\n",
    "\n",
    "        # invert scaling for actual\n",
    "        y_test = test_y.reshape((len(test_y), 1))\n",
    "        inv_y_test = scaler_y.inverse_transform(test_y)\n",
    "        inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "        y_train = train_y.reshape((len(train_y), 1))\n",
    "        inv_y_train = scaler_y.inverse_transform(train_y)\n",
    "        inv_y_train = inv_y_train[:,0]\n",
    "\n",
    "        # calculate RMSE for DIFFERENCE\n",
    "        rmse_test = sqrt(mean_squared_error(inv_y_test, inv_y_predict_test))\n",
    "        print('Test RMSE: %.3f' % rmse_test)\n",
    "        R2_test=int(1000*(metrics.r2_score(inv_y_test, inv_y_predict_test)))/1000\n",
    "        print('R2_test: %.3f' % R2_test)\n",
    "\n",
    "        rmse_train = sqrt(mean_squared_error(inv_y_train, inv_y_predict_train))\n",
    "        print('Train RMSE: %.3f' % rmse_train)\n",
    "        R2_train=int(1000*(metrics.r2_score(inv_y_train, inv_y_predict_train)))/1000\n",
    "        print('R2_train: %.3f' % R2_train)\n",
    "\n",
    "        # calculate RMSE for REAL VALUE\n",
    "\n",
    "        real_y_test= inv_x_test.iloc[:,0]+inv_y_test\n",
    "        real_y_predict_test=inv_x_test.iloc[:,0]+inv_y_predict_test\n",
    "        \n",
    "        real_rmse_test = sqrt(mean_squared_error(real_y_test, real_y_predict_test))\n",
    "        print('Test RMSE: %.3f' % real_rmse_test)\n",
    "        real_R2_test=int(1000*(metrics.r2_score(real_y_test, real_y_predict_test)))/1000\n",
    "        print('R2_test: %.3f' % real_R2_test)\n",
    "        \n",
    "        error_rmse.append(real_rmse_test)\n",
    "        error_r2hat.append(real_R2_test)\n",
    "        error_r2.append(R2_test)\n",
    "        \n",
    "        \n",
    "        plt.gcf().clear()\n",
    "        plt.figure(figsize=(5.5, 5.5))\n",
    "        plt.plot(range(len(inv_y_test)), inv_y_test, linestyle='-', marker='*', color='r')\n",
    "        plt.plot(range(len(inv_y_predict_test)), inv_y_predict_test, linestyle='-', marker='.', color='b')\n",
    "        plt.legend(['Actual','Predicted'], loc=2)\n",
    "        plt.title('Actual vs Predicted for {}'.format(Productname))\n",
    "        plt.ylabel('Trade Value')\n",
    "        plt.xlabel('Index')\n",
    "        plt.savefig('LSTM-LinePlt{} ,{} epochs,{} neurons,{} learning_rate,{} batch size, {} random, {} R2.png'.format(Productname,\n",
    "                                n_epochs,n_neurons,learning_rate,bs,rs,R2_test), format='png', dpi=300)\n",
    "       \n",
    "\n",
    "        \n",
    "        \n",
    "    return error_rmse,error_r2,error_r2hat,train_y,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "\n",
    "repeats = 1\n",
    "\n",
    "# vary training epochs\"\n",
    "epochs = [50, 500, 1000,2000]\n",
    "neurons = [5, 50,100]\n",
    "learning_rates= [0.001, 0.01, 0.05, 0.1]\n",
    "batch_sizes=[5, 12, 24,50,100]\n",
    "\n",
    "\n",
    "e=3000\n",
    "n=200\n",
    "lr=0.02\n",
    "b=50\n",
    "\n",
    "\n",
    "e=500\n",
    "n=100\n",
    "lr=0.05\n",
    "b=50\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "\n",
    "        for e in epochs:\n",
    "            results_exp[str(e)] = experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "#print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "\n",
    "results.boxplot()\n",
    "plt.title(\"LSTM-Box Plot for {}-{}, {} epochs,{} neurons,{} learning_rate, {}batch size \"\n",
    "          .format(Productname,MonthSeries,epochs,n,lr,b))\n",
    "plt.savefig('Data/LSTM-Box Plot for {}-{}, {} epochs,{} neurons {}lr,{}b.png'\n",
    "               .format(Productname,MonthSeries,epochs,n,lr,b))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
