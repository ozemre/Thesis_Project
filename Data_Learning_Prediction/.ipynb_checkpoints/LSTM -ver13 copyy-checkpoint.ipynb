{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murat.ozemre\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\murat.ozemre\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "C:\\Users\\murat.ozemre\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.layers import Dense,Input, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from random import gauss\n",
    "from random import seed\n",
    "#from pandas import Series\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from random import randrange\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12-27 08:51'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAska bir dosyadan funksiyon cagırmak için\n",
    "\n",
    "import X_Y_Split as fl\n",
    "fl.X_Y_scaler_train_test_Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\murat.ozemre\\\\Desktop\\\\Thesis_Project\\\\Data_Sources_and_Preparation'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Sources_and_Preparation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Product_Type_Options = [841810,841840,841850]\n",
    "Product=Product_Type_Options[0] #841810\n",
    "Exp_Country='TUR' # 'CHN'\n",
    "Imp_Country='GBR'\n",
    "\n",
    "if Exp_Country=='CHN':\n",
    "    Currency='CNY'\n",
    "    EXP0='TUR'   \n",
    "elif Exp_Country=='TUR':\n",
    "    Currency='TRY'\n",
    "    EXP0='CHN'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841810 MaxAbsScaler\n"
     ]
    }
   ],
   "source": [
    "Scaler_Type_Options = ['Normalizer', 'MinMaxScaler','MaxAbsScaler','RobustScaler','StandardScaler' ]\n",
    "ScalerType=Scaler_Type_Options[2]\n",
    "print(Product,ScalerType)\n",
    "\n",
    "MonthSeries=\"3\"\n",
    "MonthSeries_option=[\"1\",\"2\",\"3\",\"6\",\"12\"]\n",
    "#MonthSeries_option=[\"12\",\"123\",\"1236\",\"1236_12\",\"__12\",\"__126\",\"__1263\",\"__12632\"]\n",
    "#MonthSeries_option=[\"12\",\"123\",\"1236\",\"1236_12\",\"__12\"]\n",
    "#X1hat.iloc[3:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_Core1 = pd.ExcelFile('Data_{}_{}_{}.xlsx'.format(Exp_Country,Imp_Country,Product))\n",
    "y = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])['{}_{}_{}'.format(Exp_Country,Imp_Country,Product)]\n",
    "Z = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])[['Date','Year','Month']]\n",
    "\n",
    "X = Data_Core1.parse('X{}'.format(MonthSeries), header=0,index_col=None, na_values=['NA'])\n",
    "X.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "X_Column_Names=list(X.columns.values)\n",
    "n_feature=X.shape[1]\n",
    "\n",
    "Xhat = Data_Core1.parse('Xhat', header=0,index_col=None, na_values=['NA'])\n",
    "Xhat.drop(['Date','Year','Month'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def X_Y_scaler_train_test_Split(X,y,Z,random=42):\n",
    "\n",
    "    values = X.values\n",
    "    values = values.astype('float32')\n",
    "    X_Column_X_Column_Names=X.columns\n",
    "    \n",
    "    scaler_X= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_X = scaler_X.fit_transform(values)\n",
    "    scaled_value_X = pd.DataFrame(data=scaled_value_X[:,:])\n",
    "    scaled_value_X.columns=X_Column_X_Column_Names\n",
    "    \n",
    "    values = y.values\n",
    "    values = values.astype('float32')\n",
    "    values = values.reshape(-1, 1)\n",
    "    \n",
    "    scaler_y= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_y = scaler_y.fit_transform(values)\n",
    "    scaled_value_y = pd.DataFrame(data=scaled_value_y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_value_X,scaled_value_y,test_size=0.2,random_state=42,stratify=Z['Month'])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler_X, scaler_y, scaled_value_X, scaled_value_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set X train, X test, y train, y test\n",
    "rs=42\n",
    "Scaled_Train_Test_Split=X_Y_scaler_train_test_Split(X,y,Z,random=rs)\n",
    "\n",
    "X_train = Scaled_Train_Test_Split[0]\n",
    "X_test = Scaled_Train_Test_Split[1]\n",
    "y_train = Scaled_Train_Test_Split[2]\n",
    "y_test = Scaled_Train_Test_Split[3]\n",
    "scaler_X = Scaled_Train_Test_Split[4]  \n",
    "scaler_y = Scaled_Train_Test_Split[5]\n",
    "scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "scaled_value_y=Scaled_Train_Test_Split[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest(X_train, X_test, y_train, y_test,scaler_y,rand=50,is_random_fixed='TRUE',est=10,min_leaf=1,feat='auto',max_leaf=None,min_weight=0.0,min_impurity=1e-07):\n",
    "    from sklearn.model_selection import cross_val_score   \n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    \n",
    "    if is_random_fixed == 'TRUE': \n",
    "        rs=rand\n",
    "    else :\n",
    "        rs=random.randint(1,100)\n",
    "    print('randomforest rs=',rs)\n",
    "    rfc=RandomForestRegressor(n_estimators=est,\n",
    "                              min_samples_leaf=min_leaf,\n",
    "                              random_state =rs,\n",
    "                              max_features=feat,\n",
    "                              max_leaf_nodes=max_leaf,\n",
    "                              min_weight_fraction_leaf =min_weight,\n",
    "                              min_impurity_decrease=min_impurity\n",
    "                            )\n",
    "   \n",
    "    RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "    \n",
    "    y_predict_test = rfc.predict(X_test)\n",
    "    y_predict_train = rfc.predict(X_train)\n",
    "    \n",
    "    result_test=inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'NO')\n",
    "    result_train=inverse_scale_and_graph_Y_predict_and_test(y_predict_train,y_train,scaler_y,'NO')\n",
    "    \n",
    "    return result_test, result_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,plot_on):\n",
    "\n",
    "    y_predict_test=y_predict_test.reshape(-1, 1)\n",
    "    inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "    predictions=inv_y_predict_test\n",
    "\n",
    "  \n",
    "    inv_y_test = scaler_y.inverse_transform(y_test)\n",
    "    inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "    MAE=int(metrics.mean_absolute_error(inv_y_test, predictions))\n",
    "    MSE=int(sqrt(metrics.mean_squared_error(inv_y_test, predictions)))\n",
    "    R2=int(1000*(metrics.r2_score(inv_y_test, predictions)))/1000\n",
    "    \n",
    "    \n",
    "    print('MAE',MAE, 'MSE',MSE, 'R2',R2 )\n",
    "    \n",
    "    if plot_on =='YES':\n",
    "        plt.scatter(inv_y_test,predictions)\n",
    "    \n",
    "    return MAE,MSE,R2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 1834 MSE 2354 R2 0.752\n",
      "MAE 704 MSE 899 R2 0.953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1834, 2354, 0.752), (704, 899, 0.953))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest(X_train, X_test, y_train, y_test,scaler_y,est=100,rand=20,is_random_fixed='FALSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 1731 MSE 2141 R2 0.794\n",
      "MAE 716 MSE 1019 R2 0.94\n",
      "MAE 1980 MSE 2683 R2 0.677\n",
      "MAE 784 MSE 1060 R2 0.935\n",
      "MAE 1944 MSE 2521 R2 0.715\n",
      "MAE 856 MSE 1118 R2 0.928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2141, 2683, 2521], [0.794, 0.677, 0.715])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_RandomForest(3,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,rand=20,is_random_fixed='FALSE')\n",
    "#,est=3000,random=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 1789 MSE 2295 R2 0.764\n",
      "MAE 701 MSE 883 R2 0.955\n",
      "MAE 1789 MSE 2295 R2 0.764\n",
      "MAE 701 MSE 883 R2 0.955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2295, 2295], [0.764, 0.764])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_RandomForest(2,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,est=3000,rand=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def experiment_RandomForest(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=50,is_random_fixed='TRUE',\n",
    "                  est=10,min_leaf=1,feat='auto',max_leaf=None,min_weight=0.0,min_impurity=1e-07):\n",
    "    \n",
    "    error_rmse = list()\n",
    "    error_R2 = list()\n",
    "    \n",
    "    for r in range(repeats):\n",
    "\n",
    "        result=randomforest(X_train, X_test, y_train, y_test,scaler_y,\n",
    "                            rand=rand,is_random_fixed=is_random_fixed,\n",
    "                            est=est,min_leaf=min_leaf,feat=feat,max_leaf=max_leaf,\n",
    "                            min_weight=min_weight,min_impurity=min_impurity)\n",
    "\n",
    "    \n",
    "      \n",
    "        rmse_test=result[0][1]\n",
    "        R2_test=result[0][2]\n",
    "        \n",
    "        rmse_train=result[1][0]\n",
    "        R2_train=result[1][1]\n",
    "        \n",
    "        error_rmse.append(rmse_test)\n",
    "        error_R2.append(R2_test)\n",
    "    \n",
    "    return error_rmse, error_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split rs= 11\n",
      "randomforest rs= 24\n",
      "MAE 1975 MSE 2518 R2 0.716\n",
      "MAE 1553 MSE 1876 R2 0.798\n",
      "randomforest rs= 83\n",
      "MAE 1973 MSE 2481 R2 0.724\n",
      "MAE 1549 MSE 1875 R2 0.798\n",
      "randomforest rs= 51\n",
      "MAE 1968 MSE 2484 R2 0.723\n",
      "MAE 1568 MSE 1894 R2 0.794\n",
      "randomforest rs= 18\n",
      "MAE 2120 MSE 2619 R2 0.692\n",
      "MAE 1608 MSE 1988 R2 0.773\n",
      "randomforest rs= 49\n",
      "MAE 2111 MSE 2633 R2 0.689\n",
      "MAE 1619 MSE 1990 R2 0.773\n",
      "randomforest rs= 17\n",
      "MAE 2100 MSE 2589 R2 0.7\n",
      "MAE 1607 MSE 1986 R2 0.774\n",
      "randomforest rs= 62\n",
      "MAE 2091 MSE 2590 R2 0.699\n",
      "MAE 1596 MSE 1969 R2 0.778\n",
      "randomforest rs= 70\n",
      "MAE 2117 MSE 2625 R2 0.691\n",
      "MAE 1598 MSE 1969 R2 0.778\n",
      "randomforest rs= 57\n",
      "MAE 2106 MSE 2622 R2 0.692\n",
      "MAE 1596 MSE 1970 R2 0.777\n",
      "randomforest rs= 20\n",
      "MAE 1976 MSE 2476 R2 0.725\n",
      "MAE 1499 MSE 1826 R2 0.809\n",
      "randomforest rs= 6\n",
      "MAE 1927 MSE 2435 R2 0.734\n",
      "MAE 1504 MSE 1812 R2 0.812\n",
      "randomforest rs= 33\n",
      "MAE 1968 MSE 2494 R2 0.721\n",
      "MAE 1525 MSE 1856 R2 0.802\n",
      "Size: 12\n",
      "                10         log2         sqrt         auto\n",
      "count     3.000000     3.000000     3.000000     3.000000\n",
      "mean   2494.333333  2613.666667  2612.333333  2468.333333\n",
      "std      20.550750    22.479620    19.399313    30.237945\n",
      "min    2481.000000  2589.000000  2590.000000  2435.000000\n",
      "25%    2482.500000  2604.000000  2606.000000  2455.500000\n",
      "50%    2484.000000  2619.000000  2622.000000  2476.000000\n",
      "75%    2501.000000  2626.000000  2623.500000  2485.000000\n",
      "max    2518.000000  2633.000000  2625.000000  2494.000000\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: \"Data/15 Mayıs/RF-Box Plot for TUR_GBR_841810-3, 200 est,5 min_leaf,[10, 'log2', 'sqrt', 'auto'] feat,100 max_leaf, 1e-05 min_weight,0.001min_impurity.png\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-435f657e2f2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m           .format(y.name,MonthSeries,  est, min_leaf,rs,max_features_options,max_leaf,min_weight,min_impurity))\n\u001b[0;32m     65\u001b[0m plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n\u001b[1;32m---> 66\u001b[1;33m                .format(y.name,MonthSeries,est,min_leaf,max_features_options,max_leaf,min_weight,min_impurity))\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1571\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1573\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1575\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[0;32m   2250\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2251\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2252\u001b[1;33m                 **kwargs)\n\u001b[0m\u001b[0;32m   2253\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2254\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mfilename_or_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: \"Data/15 Mayıs/RF-Box Plot for TUR_GBR_841810-3, 200 est,5 min_leaf,[10, 'log2', 'sqrt', 'auto'] feat,100 max_leaf, 1e-05 min_weight,0.001min_impurity.png\""
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA50AAAEICAYAAADcGJCTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2015fa3b9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MAIN for Random Forest Experiments\n",
    "repeats=3\n",
    "random_range_for_split=1\n",
    "rs=random.randint(1,100)\n",
    "#rs=12\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "estimator_options = [100,200,500,1000,5000,10000,20000]\n",
    "min_sample_leaf_options = [1,2,5,20,30]\n",
    "#random_state_options =[10]\n",
    "max_features_options=[10,\"log2\",\"sqrt\",\"auto\"]\n",
    "max_leaf_nodes_options=[2,5,10,100,200,300] \n",
    "min_weight_fraction_leaf_options=[0.00001,0.0001,0.001,0.01,0.1] \n",
    "min_impurity_decrease_options =[0.0000001,0.000001,0.001,0.01,0.05]\n",
    "\n",
    "\n",
    "\n",
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "\n",
    "param='TRUE'\n",
    "\n",
    "for r in range (random_range_for_split):\n",
    "\n",
    "\n",
    "    rs=random.randint(1,100)\n",
    "\n",
    "    print('split rs=',rs)\n",
    "    \n",
    "    Scaled_Train_Test_Split=X_Y_scaler_train_test_Split(X,y,Z,random=rs)\n",
    "\n",
    "    X_train = Scaled_Train_Test_Split[0]\n",
    "    X_test = Scaled_Train_Test_Split[1]\n",
    "    y_train = Scaled_Train_Test_Split[2]\n",
    "    y_test = Scaled_Train_Test_Split[3]\n",
    "    scaler_X = Scaled_Train_Test_Split[4]  \n",
    "    scaler_y = Scaled_Train_Test_Split[5]\n",
    "    scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "    scaled_value_y=Scaled_Train_Test_Split[7]\n",
    "    \n",
    "    \n",
    "    for feat in max_features_options:\n",
    "        results_exp[str(feat)] =experiment_RandomForest(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',\n",
    "                  est=est,min_leaf=min_leaf,feat=feat,max_leaf=max_leaf,min_weight=min_weight,min_impurity=min_impurity)[0] \n",
    "    \n",
    "    results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc=results.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'boxplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-eb5277a1092b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n\u001b[0;32m      4\u001b[0m           .format(y.name,MonthSeries,  est, min_leaf,rs,max_features_options,max_leaf,min_weight,min_impurity))\n\u001b[0;32m      5\u001b[0m plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3081\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'boxplot'"
     ]
    }
   ],
   "source": [
    "abc.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Product in Product_Type_Options:\n",
    "    \n",
    "    print(Product)\n",
    "    if Product==841810 :\n",
    "        Data_Core1 = pd.ExcelFile('Data_{}_{}_{}.xlsx'.format(Exp_Country,Imp_Country,Product))\n",
    "        y1 = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])['{}_{}_{}'.format(Exp_Country,Imp_Country,Product)]\n",
    "        z1 = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])[['Date','Year','Month']]\n",
    "\n",
    "        X1 = Data_Core1.parse('X{}'.format(MonthSeries), header=0,index_col=None, na_values=['NA'])\n",
    "        X1.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "        X1_Column_Names=list(X1.columns.values)\n",
    "        n_feature=X1.shape[1]\n",
    "\n",
    "        X1hat = Data_Core1.parse('Xhat', header=0,index_col=None, na_values=['NA'])\n",
    "        X1hat.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "        \n",
    "        print('X1',X1.shape, y1.shape,'X1hat', X1hat.shape)\n",
    "        \n",
    "    elif Product==841840 :\n",
    "\n",
    "        Data_Core1 = pd.ExcelFile('Data_{}_{}_{}.xlsx'.format(Exp_Country,Imp_Country,Product))\n",
    "        y2 = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])['{}_{}_{}'.format(Exp_Country,Imp_Country,Product)]\n",
    "        z2 = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])[['Date','Year','Month']]\n",
    "\n",
    "        X2 = Data_Core1.parse('X{}'.format(MonthSeries), header=0,index_col=None, na_values=['NA'])\n",
    "        X2.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "        X2_Column_Names=list(X2.columns.values)\n",
    "        n_feature=X2.shape[1]\n",
    "\n",
    "        X2hat = Data_Core1.parse('Xhat', header=0,index_col=None, na_values=['NA'])\n",
    "        X2hat.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "        \n",
    "        print('X2',X2.shape, y2.shape,'X2hat', X2hat.shape)\n",
    "    elif Product==841850 :\n",
    "        Data_Core1 = pd.ExcelFile('Data_{}_{}_{}.xlsx'.format(Exp_Country,Imp_Country,Product))\n",
    "        y3 = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])['{}_{}_{}'.format(Exp_Country,Imp_Country,Product)]\n",
    "        z3 = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])[['Date','Year','Month']]\n",
    "\n",
    "        X3 = Data_Core1.parse('X{}'.format(MonthSeries), header=0,index_col=None, na_values=['NA'])\n",
    "        X3.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "        X3_Column_Names=list(X3.columns.values)\n",
    "        n_feature=X3.shape[1]\n",
    "\n",
    "        X3hat = Data_Core1.parse('Xhat', header=0,index_col=None, na_values=['NA'])\n",
    "        X3hat.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "        \n",
    "        print('X3',X3.shape, y3.shape,'X3hat', X3hat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def X_Y_scaler_train_test_Split(X,y,Z,random=42):\n",
    "\n",
    "    values = X.values\n",
    "    values = values.astype('float32')\n",
    "    X_Column_X_Column_Names=X.columns\n",
    "    \n",
    "    scaler_X= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_X = scaler_X.fit_transform(values)\n",
    "    scaled_value_X = pd.DataFrame(data=scaled_value_X[:,:])\n",
    "    scaled_value_X.columns=X_Column_X_Column_Names\n",
    "    \n",
    "    values = y.values\n",
    "    values = values.astype('float32')\n",
    "    values = values.reshape(-1, 1)\n",
    "    \n",
    "    scaler_y= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_y = scaler_y.fit_transform(values)\n",
    "    scaled_value_y = pd.DataFrame(data=scaled_value_y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_value_X,scaled_value_y,test_size=0.2,random_state=42,stratify=Z['Month'])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler_X, scaler_y, scaled_value_X, scaled_value_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Scaled_Train_Test_Split=X_Y_scaler_train_test_Split(X,y,Z)\n",
    "Scaled_Train_Test_Split=X_Y_scaler_train_test_Split(X,y,date)\n",
    "\n",
    "X_train = Scaled_Train_Test_Split[0]\n",
    "X_test = Scaled_Train_Test_Split[1]\n",
    "y_train = Scaled_Train_Test_Split[2]\n",
    "y_test = Scaled_Train_Test_Split[3]\n",
    "scaler_X = Scaled_Train_Test_Split[4]  \n",
    "scaler_y = Scaled_Train_Test_Split[5]\n",
    "scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "scaled_value_y=Scaled_Train_Test_Split[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def TrainTestSplit(rs,X,y,date,th,random_split):\n",
    "    split_succesfull='TRUE'\n",
    "    values = X.values\n",
    "    values = values.astype('float32')\n",
    "    scaler_x= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_x = scaler_x.fit_transform(values)\n",
    "    scaled_value_x = pd.DataFrame(data=scaled_value_x[:,:])\n",
    "\n",
    "    values = y.values\n",
    "    values = values.astype('float32')\n",
    "    values = values.reshape(-1, 1)\n",
    "    \n",
    "    scaler_y= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_y = scaler_y.fit_transform(values)\n",
    "    scaled_value_y = pd.DataFrame(data=scaled_value_y)\n",
    "\n",
    "    if random_split =='TRUE':\n",
    "        train_X, test_X, train_y, test_y = train_test_split(scaled_value_x.values,scaled_value_y.values,\n",
    "                                                        test_size=0.2,random_state=rs, \n",
    "                                                        stratify=date['Month']\n",
    "                                                       )\n",
    "\n",
    "    elif random_split =='FALSE':\n",
    "        train_lenght=int(len(X)*0.8)\n",
    "        test_lenght=len(X)-train_lenght\n",
    "        \n",
    "        train_X=scaled_value_x.iloc[0:train_lenght,:].values\n",
    "        test_X=scaled_value_x.iloc[train_lenght:len(X),:].values \n",
    "        \n",
    "        train_y=scaled_value_y.iloc[0:train_lenght].values \n",
    "        test_y=scaled_value_y.iloc[train_lenght:len(X)].values\n",
    "        \n",
    "#        train_y_Analiz= train_y\n",
    "#        test_y_Analiz=test_y\n",
    "  \n",
    "    train_y_Analiz=pd.DataFrame(data=train_y[:,:])\n",
    "    test_y_Analiz=pd.DataFrame(data=test_y[:,:])\n",
    "    \n",
    "#    Analiz(scaled_value_y)\n",
    "#    Analiz(train_y_Analiz)\n",
    "#    Analiz(test_y_Analiz)\n",
    "    mean_scaled_y=scaled_value_y.describe().iloc[1].values\n",
    "    mean_train_y=train_y_Analiz.describe().iloc[1].values\n",
    "    mean_test_y=test_y_Analiz.describe().iloc[1].values\n",
    "    \n",
    "    perc=abs((mean_train_y-mean_scaled_y)/mean_scaled_y)*100\n",
    "    \n",
    "    if perc > th:\n",
    "    \n",
    "#        print('Split is not succesfull') \n",
    "        split_succesfull='FALSE'\n",
    "    \n",
    "#    print('mean=', mean_scaled_y,'mean_train_y=',mean_train_y, 'perc=', perc)\n",
    "#    print('diffence=', (mean_train_y-mean_scaled_y))\n",
    "    \n",
    "#    print('mean=', scaled_value_y.describe().iloc[1])\n",
    "    #print(scaled_value_y.describe()) #,train_y_Analiz.describe(),test_y_Analiz.describe()[1])\n",
    "    \n",
    "    #a.to_excel('Dagılım_Kontrolu_icin.xlsx',index = False)\n",
    "    \n",
    "    return train_X, test_X, train_y, test_y, scaler_x, scaler_y,scaled_value_y.describe(),split_succesfull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "y=y1\n",
    "X=X1\n",
    "date=z1\n",
    "repeats=1\n",
    "rs=random.randint(1,100)\n",
    "rs=42\n",
    "print(rs)\n",
    "#Threshold Setting for warning\n",
    "th=2.5\n",
    "random_split='FALSE'\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "for r in range(repeats):\n",
    "    rs=random.randint(1,100)\n",
    "    print(rs)\n",
    "    SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "    \n",
    "#Feature Reduction için % oran %0 hepisini alıyor.    \n",
    "#percentile=50\n",
    "percentile=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X.to_excel('X2Split.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest(train_X,test_X, train_y, test_y,scaler_y,est=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X_train\n",
    "test_X = X_test\n",
    "train_y = y_train \n",
    "test_y = y_test\n",
    "scaler_y = scaler_y\n",
    "\n",
    "# Random Foest Regressor model\n",
    "rfc=RandomForestRegressor(n_estimators=3000)\n",
    "\n",
    "# Random Foest Regressor model train\n",
    "RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "\n",
    "# Random Foest Regressor mode predict\n",
    "y_predict_test = rfc.predict(X_test)\n",
    "\n",
    "# Compare predicted Y and real Y \n",
    "inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Orjinal EXPERİMENT\n",
    "def experiment_RF(repeats,param,est,min_leaf,random,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y):\n",
    "\n",
    "    \n",
    "    error_rmse = list()\n",
    "    error_r2hat = list()\n",
    "    error_r2 = list()\n",
    "    for r in range(repeats):\n",
    "        \n",
    "        if param== 'TRUE':\n",
    "            rfc_model=RandomForestRegressor(n_estimators=est,\n",
    "                              min_samples_leaf=min_leaf,\n",
    "                          #    random_state =random,\n",
    "                              max_features=feat,\n",
    "                              max_leaf_nodes=max_leaf,\n",
    "                              min_weight_fraction_leaf =min_weight,\n",
    "                              min_impurity_split=min_impurity\n",
    "                             )\n",
    "        elif param== 'FALSE':\n",
    "            rfc_model=RandomForestRegressor()\n",
    "\n",
    "        RandomForestRegressor.fit(rfc_model,train_X,train_y)\n",
    "        \n",
    "        # make a prediction\n",
    "        y_predict_test = rfc_model.predict(test_X)\n",
    "        y_predict_train = rfc_model.predict(train_X)\n",
    "        \n",
    "        y_predict_test=y_predict_test.reshape(-1, 1)\n",
    "        y_predict_train=y_predict_train.reshape(-1, 1)\n",
    "        \n",
    "        inv_x_test = scaler_x.inverse_transform(test_X)\n",
    "        inv_x_test = pd.DataFrame(data=inv_x_test[:,:])\n",
    "\n",
    "\n",
    "        # invert scaling for forecast\n",
    "         \n",
    "        inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "        \n",
    "        inv_y_predict_train = scaler_y.inverse_transform(y_predict_train)\n",
    "\n",
    "        # invert scaling for actual\n",
    "        y_test = test_y.reshape((len(test_y), 1))\n",
    "        y_test = test_y.reshape(-1, 1)\n",
    "        inv_y_test = scaler_y.inverse_transform(test_y)\n",
    "        inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "        y_train = train_y.reshape((len(train_y), 1))\n",
    "        inv_y_train = scaler_y.inverse_transform(train_y)\n",
    "        inv_y_train = inv_y_train[:,0]\n",
    "\n",
    "        # calculate RMSE for DIFFERENCE\n",
    "        rmse_test = sqrt(mean_squared_error(inv_y_test, inv_y_predict_test))\n",
    "        print('Test RMSE: %.3f' % rmse_test)\n",
    "        R2_test=int(1000*(metrics.r2_score(inv_y_test, inv_y_predict_test)))/1000\n",
    "        print('R2_test: %.3f' % R2_test)\n",
    "\n",
    "        rmse_train = sqrt(mean_squared_error(inv_y_train, inv_y_predict_train))\n",
    "        print('Train RMSE: %.3f' % rmse_train)\n",
    "        R2_train=int(1000*(metrics.r2_score(inv_y_train, inv_y_predict_train)))/1000\n",
    "        print('R2_train: %.3f' % R2_train)\n",
    "\n",
    "        # calculate RMSE for REAL VALUE\n",
    "        \n",
    "#        print ('inv_x_test', type(inv_x_test.iloc[:,0]), inv_x_test.iloc[:,0].shape)\n",
    "#        print ('inv_y_test', type(inv_y_test.shape),inv_y_test.shape)\n",
    "#        print ('inv_x_test', type(inv_x_test.iloc[:,0]),inv_x_test.iloc[:,0].shape)\n",
    "#        print ('inv_y_predict_test', type(inv_y_predict_test),inv_y_predict_test)\n",
    "        \n",
    "        real_y_test= inv_x_test.iloc[:,0] # +inv_y_test\n",
    "        real_y_predict_test=inv_x_test.iloc[:,0] # +inv_y_predict_test\n",
    "        \n",
    "        real_rmse_test = sqrt(mean_squared_error(real_y_test, real_y_predict_test))\n",
    "#        print('Test RMSE: %.3f' % real_rmse_test)\n",
    "        real_R2_test=int(1000*(metrics.r2_score(real_y_test, real_y_predict_test)))/1000\n",
    "#        print('R2_test: %.3f' % real_R2_test)\n",
    "        \n",
    "        error_rmse.append(real_rmse_test)\n",
    "        error_r2hat.append(real_R2_test)\n",
    "        error_r2.append(R2_test)\n",
    "        \n",
    "#        plt.gcf().clear()\n",
    "#        plt.figure(figsize=(5.5, 5.5))\n",
    "#        plt.plot(range(len(inv_y_test)), inv_y_test, linestyle='-', marker='*', color='r')\n",
    "#        plt.plot(range(len(inv_y_predict_test)), inv_y_predict_test, linestyle='-', marker='.', color='b')\n",
    "#        plt.legend(['Actual','Predicted'], loc=2)\n",
    "#        plt.title('Actual vs Predicted for {}'.format(y.name))\n",
    "#        plt.ylabel('Trade Value')\n",
    "#        plt.xlabel('Index')\n",
    "#        plt.savefig('Data/RF-LinePlt{} ,{} est,{} min_leaf,{} rs_for split,{} max_leaf, {} min_weight,{}min_impurity, {} R2.png'.format(y.name,\n",
    "#                                est,min_leaf,random,feat,max_leaf,min_weight,min_impurity,R2_test), format='png', dpi=300)\n",
    "       \n",
    "\n",
    "        \n",
    "        \n",
    "    return error_rmse,error_r2,error_r2hat,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (real_y_test.shape)\n",
    "print (results_exp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIC AYAR YAPMADAN FARKLI SPLIT YAPARAK RF CALISMASI\n",
    "Dort Farklı Calısma Yapıldı\n",
    "1. Aylık Stratify olmadan her 3 urun kodu için çalıştırıldı\n",
    "2. Aylık Stratify yapılarak her 3 ürün kodu için çalıştırıldı\n",
    "3. Aylık Stratify yapılarak aylık fark verisi üzerinden (Xhat) her 3 ürün kodu için çalıştırıldı \n",
    "    R2 gercek değeri alındı.\n",
    "4. Aylık Stratify yapılarak aylık fark verisi üzerinden (Xhat) her 3 ürün kodu için çalıştırıldı \n",
    "    R2 o ayın gerçek değerine göre ayarlanarak alındı.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repeats=1\n",
    "random_range_for_split=5\n",
    "rs=random.randint(1,100)\n",
    "#rs=12\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "est=500\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "\n",
    "param='TRUE'\n",
    "\n",
    "for r in range (random_range_for_split):\n",
    "\n",
    "#for r in range(repeats):\n",
    "    rs=random.randint(1,100)\n",
    "#    rs=42\n",
    "    print(rs)\n",
    "    SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "    \n",
    "    train_X=SplitData[0] \n",
    "    test_X=SplitData[1] \n",
    "    train_y=SplitData[2] \n",
    "    test_y=SplitData[3]\n",
    "    scaler_x=SplitData[4]\n",
    "    scaler_y=SplitData[5]\n",
    "    split_succesfull=SplitData[7]\n",
    "    print(split_succesfull)\n",
    "\n",
    "    experiment_result=experiment_RF(repeats,param,est,min_leaf,rs,\n",
    "                                    feat,max_leaf,min_weight,min_impurity,\n",
    "                                    train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "    \n",
    "#Xhat için analiz yapıldığı ve Adjusted R2 hesaplandığı zaman [2] nolu output kullanılıyor \n",
    "#                                    train_X, test_X, train_y, test_y,scaler_x,scaler_y)[2]\n",
    "\n",
    "    results[str(r)]= experiment_result\n",
    "    results_exp[split_succesfull]= experiment_result\n",
    "    results_split=pd.concat([results_split,results_exp])\n",
    "    print ('results split',results_split)\n",
    "\n",
    "results_randomnumber_bins=results\n",
    "resultvalues=results.values\n",
    "results_all=resultvalues.reshape((random_range_for_split*repeats,1))\n",
    "results_all=pd.DataFrame(data=results_all[:,:])\n",
    "\n",
    "#max_R2=results_all.describe().iloc[7,:]\n",
    "#std=results_all.describe().iloc[2,:]\n",
    "#mean=results_all.describe().iloc[1,:]\n",
    "\n",
    "mean=results_all.describe().values[1]\n",
    "std=results_all.describe().values[2]\n",
    "max_R2=results_all.describe().values[7]\n",
    "\n",
    "results_all.hist()\n",
    "plt.title('{} and with split threshold {} for {} different run'.format(y.name,th,random_range_for_split))\n",
    "plt.axis([0, 1, 0, 400])\n",
    "plt.xlabel('mean {}, std {}, max_value{}'.format(mean,std,max_R2))\n",
    "#plt.savefig('Distiribution_without_Tuning\\Histogram Plot R2 for {} and with (non stratify) split threshold {} for {} different run.png'.format(y.name,th,random_range_for_split))\n",
    "plt.savefig('Distiribution_without_Tuning\\Histogram Plot R2 for {} and with (rs=random) split threshold {} and {} param for {} different run.png'.format(y.name,th,param,random_range_for_split))\n",
    "\n",
    "pyplot.show()\n",
    "\n",
    "plt.gcf().clear()\n",
    "plt.title('{} and with split threshold {}'.format(y.name,th))\n",
    "\n",
    "results_split.boxplot()\n",
    "#plt.savefig('Distiribution_without_Tuning\\Box Plot R2 for {} and with (non stratify) split threshold {} for {} different run.png'.format(y.name,th,random_range_for_split), format='png', dpi=300)\n",
    "plt.savefig('Distiribution_without_Tuning\\Box Plot R2 for {} and with (rs=random)split threshold {} for {} different run.png'.format(y.name,th,random_range_for_split), format='png', dpi=300)\n",
    "\n",
    "pyplot.show()                                   \n",
    "\n",
    "      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ince Ayar Yapılmadan once (Spilt için RS sabit) ve tuning sonrasındaki karşılaştırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repeats=3\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "\n",
    "#RS =42ye gore bulunan Tuning sonucları: \n",
    "\n",
    "#841840 Parametre seti\n",
    "est=5000\n",
    "min_leaf=1\n",
    "feat=\"log2\"\n",
    "max_leaf=10\n",
    "min_weight=0.001\n",
    "min_impurity=0.0000001\n",
    "\n",
    "#841810 Parametre seti\n",
    "est=10000\n",
    "min_leaf=2\n",
    "feat=\"sqrt\"\n",
    "max_leaf=150\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "#841850  Parametre seti\n",
    "est=2000\n",
    "min_leaf=20\n",
    "feat=10\n",
    "max_leaf=50\n",
    "min_weight=0.1\n",
    "min_impurity=0.01\n",
    "\n",
    "\n",
    "#RS =42ye gore bulunan Tuning sonucları: \n",
    "#RS =Randoma gore bulunan Tuning sonucları: \n",
    "\n",
    "est=10000\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "\n",
    "#Etkin olan parametre seti\n",
    "\n",
    "est=10000\n",
    "min_leaf=2\n",
    "feat=\"sqrt\"\n",
    "max_leaf=150\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "#NN için parametreler\n",
    "alph= 1e-12\n",
    "max_iteration= 50000\n",
    "slv= \"adam\"\n",
    "hidden_layer= (30, 30)\n",
    "\n",
    "\n",
    "\n",
    "param_options=[\"FALSE\",\"TRUE\"]\n",
    "\n",
    "#Farklı RAndom Seed Splitler\n",
    "rs=random.randint(1,100)\n",
    "#Tek bir Random Seed Split\n",
    "rs=42\n",
    "\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "train_X=SplitData[0] \n",
    "test_X=SplitData[1] \n",
    "train_y=SplitData[2] \n",
    "test_y=SplitData[3]\n",
    "scaler_x=SplitData[4]\n",
    "scaler_y=SplitData[5]\n",
    "split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "experiment=\"NN\" #or RF\n",
    "first_loop_range=50\n",
    "second_loop_range=2\n",
    "for r in range (0,first_loop_range):\n",
    "    rs=random.randint(1,100)\n",
    "   \n",
    "    SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "    print(rs)\n",
    "    train_X=SplitData[0] \n",
    "    test_X=SplitData[1] \n",
    "    train_y=SplitData[2] \n",
    "    test_y=SplitData[3]\n",
    "    scaler_x=SplitData[4]\n",
    "    scaler_y=SplitData[5]\n",
    "    split_succesfull=SplitData[7]\n",
    "    \n",
    "    \n",
    "    for p in range (0, second_loop_range):\n",
    "        \n",
    "        param=param_options[p]\n",
    "        \n",
    "        if experiment==\"RF\":\n",
    "            experiment_result=experiment_RF(repeats,param,est,min_leaf,rs,\n",
    "                                    feat,max_leaf,min_weight,min_impurity,\n",
    "                                    train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        elif experiment==\"NN\":\n",
    "             experiment_result=experiment_NN(repeats,param,alph,max_iteration,slv,rseed,hidden_layer,\n",
    "                          train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        \n",
    "        results_exp[param]= experiment_result\n",
    "        \n",
    "#    results_split[split_succesfull]= experiment_result\n",
    "    results=pd.concat([results,results_exp])\n",
    "\n",
    "results_randomnumber_bins=results\n",
    "resultvalues=results.values\n",
    "results_all=resultvalues.reshape((first_loop_range*second_loop_range*repeats,1))\n",
    "results_all=pd.DataFrame(data=results_all[:,:])\n",
    "\n",
    "mean=results_all.describe().values[1]\n",
    "std=results_all.describe().values[2]\n",
    "max_R2=results_all.describe().values[7]\n",
    "\n",
    "plt.gcf().clear()\n",
    "plt.title('{} with (according rs=42 Tuned and split general) before Tuning and (trained rs=90) after Tuning'.format(y.name))\n",
    "plt.xlabel('mean {}, std {}, max_value{}'.format(mean,std,max_R2))\n",
    "results.boxplot()\n",
    "plt.savefig('Distiribution_without_Tuning\\Box Plot R2 for {} and (tuned rs =42)(split=general){} (trained rs=90) different run.png'.format(y.name,repeats), \n",
    "            format='png', dpi=300)\n",
    "\n",
    "pyplot.show()                                   \n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sonuc=pd.concat([sonuc,calıstır_randomforest(X_train, X_test, y_train, y_test,scaler_y,Product,MonthSerie,ScalerType)])\n",
    "\n",
    "#max_R2=int((sonuc['R2'].max())*1000)/1000\n",
    "#filename='Out_Random_Predict_Results_{one}_Product{two}_{four}perc_with max{tre}'.format(one=datetime.now().strftime('Date_%m-%d_Time%H_%M'),\n",
    "#                                                                                      two=Product,tre=max_R2,four=percentile)\n",
    "#sonuc.to_excel('{}.xlsx'.format(filename),index = False)      \n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#def experiment(repeats,n_epochs,n_neurons,learning_rate,bs,rs,X,y,date):\n",
    "def experiment_LSTM(repeats,n_epochs,n_neurons,learning_rate,bs,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y):\n",
    "    K.clear_session()\n",
    "\n",
    "#    print(type(train_X))\n",
    "    train_X =train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "#    train_X =train_X.reshape((train_X.shape[0], train_X.shape[1],1))\n",
    "#    test_X = test_X.reshape((test_X.shape[0], test_X.shape[1],1))\n",
    "#    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    " \n",
    "    \n",
    "    error_rmse = list()\n",
    "    error_r2hat = list()\n",
    "    error_r2 = list()\n",
    "    for r in range(repeats):\n",
    "        \n",
    "        print('Shape of X Train',train_X.shape[1],train_X.shape[2])\n",
    "    \n",
    "\n",
    "        if do_model=='A':\n",
    "            model = Sequential() \n",
    "            model.add(LSTM(n_neurons,input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "            model.add(Dropout(drop_rate))\n",
    "            \n",
    "            model.add(Dense(n_neurons))\n",
    "            model.add(Dropout(drop_rate))\n",
    "            \n",
    "            model.add(Dense(1))\n",
    "#            model.add(Activation('sigmoid'))\n",
    "            model.add(Activation('linear'))\n",
    "        \n",
    "        elif do_model=='B':   \n",
    "            input_layer=Input(shape=(train_X.shape[1], train_X.shape[2]),dtype='float32')\n",
    "            lstm_layer1=LSTM(n_neurons,input_shape=(train_X.shape[1],train_X.shape[2]),\n",
    "                         dropout=drop_rate, \n",
    "                         recurrent_dropout=drop_rate,\n",
    "                         return_sequences=True)(input_layer)\n",
    "            lstm_layer2=LSTM(n_neurons,input_shape=(train_X.shape[1],n_neurons),\n",
    "                         dropout=drop_rate, \n",
    "                         recurrent_dropout=drop_rate,\n",
    "                         return_sequences=False)(lstm_layer1)\n",
    "            dropout_layer=Dropout(drop_rate)(lstm_layer2)\n",
    "\n",
    "            output_layer=Dense(1,activation=\"linear\")(dropout_layer)\n",
    "#            output_layer=Dense(1,activation=\"linear\")(lstm_layer2)\n",
    "         \n",
    "\n",
    "        #ix layerlarda Activation için RELU Output için linear uygun oluyor. Kaynak Siraj Raval\n",
    "        \n",
    "            model=Model(inputs=input_layer, outputs=output_layer)\n",
    "        \n",
    "        \n",
    "        #decay_rate = learning_rate / n_epochs\n",
    "        \n",
    "        decay_rate = 0.8\n",
    "        momentum = 0.9\n",
    "         \n",
    "        sgd = optimizers.SGD(lr=learning_rate, clipvalue=0.3,momentum=momentum, decay=decay_rate,nesterov=True)\n",
    "        adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\n",
    "\n",
    "        #model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        \n",
    "        \n",
    "#        model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "        model.compile(loss='mean_squared_error', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "#        model=load_model(os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(y.name,n_neurons)))\n",
    "#        model=load_model(os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(y.name,n_neurons)))\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "        save_weights_at=os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(y.name,n_neurons))\n",
    "\n",
    "        save_best=ModelCheckpoint(save_weights_at, monitor='val_loss', verbose=0,\n",
    "                                 save_best_only=True, save_weights_only=False, mode='min',\n",
    "                                 period=1)\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.00001)\n",
    "        early_stop = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "        \n",
    "        history = model.fit(train_X, train_y, epochs=n_epochs, batch_size=bs, \n",
    "\n",
    "                            validation_data=(test_X, test_y), verbose=1, \n",
    "#                            callbacks=[reduce_lr],\n",
    "                           # callbacks=[save_best],\n",
    "\n",
    "                           # callbacks=[early_stop],\n",
    "                            shuffle=False)\n",
    "\n",
    "#        best_model=load_model(os.path.join('Data','train_dataset.hdf5')\n",
    "#        model=load_model(os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(y.name,n_neurons)))\n",
    "\n",
    "        #model=best_model\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # summarize history for loss\n",
    "        plt.gcf().clear()\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        # summarize history for accuracy\n",
    "#        plt.plot(history.history['acc'])\n",
    "#        plt.plot(history.history['val_acc'])\n",
    "#        plt.title('model accuracy')\n",
    "#        plt.ylabel('accuracy')\n",
    "#        plt.xlabel('epoch')\n",
    "#        plt.legend(['train', 'test'], loc='upper left')\n",
    "#        plt.show()\n",
    "\n",
    "\n",
    "#        test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[1]))\n",
    "\n",
    "        test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "        inv_x_test = scaler_x.inverse_transform(test_X_reshaped)\n",
    "        inv_x_test = pd.DataFrame(data=inv_x_test[:,:])\n",
    "\n",
    "        # make a prediction\n",
    "        y_predict_test = model.predict(test_X)\n",
    "        y_predict_train = model.predict(train_X)\n",
    "\n",
    "        # invert scaling for forecast\n",
    "        inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "        inv_y_predict_test = inv_y_predict_test[:,0]\n",
    "        inv_y_predict_train = scaler_y.inverse_transform(y_predict_train)\n",
    "        inv_y_predict_train = inv_y_predict_train[:,0]\n",
    "\n",
    "        # invert scaling for actual\n",
    "        y_test = test_y.reshape((len(test_y), 1))\n",
    "        inv_y_test = scaler_y.inverse_transform(test_y)\n",
    "        inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "        y_train = train_y.reshape((len(train_y), 1))\n",
    "        inv_y_train = scaler_y.inverse_transform(train_y)\n",
    "        inv_y_train = inv_y_train[:,0]\n",
    "\n",
    "        # calculate RMSE for DIFFERENCE\n",
    "        rmse_test = sqrt(mean_squared_error(inv_y_test, inv_y_predict_test))\n",
    "        print('Test RMSE: %.3f' % rmse_test)\n",
    "        R2_test=int(1000*(metrics.r2_score(inv_y_test, inv_y_predict_test)))/1000\n",
    "        print('R2_test: %.3f' % R2_test)\n",
    "\n",
    "        rmse_train = sqrt(mean_squared_error(inv_y_train, inv_y_predict_train))\n",
    "        print('Train RMSE: %.3f' % rmse_train)\n",
    "        R2_train=int(1000*(metrics.r2_score(inv_y_train, inv_y_predict_train)))/1000\n",
    "        print('R2_train: %.3f' % R2_train)\n",
    "\n",
    "        # calculate RMSE for REAL VALUE\n",
    "\n",
    "        real_y_test= inv_x_test.iloc[:,0]+inv_y_test\n",
    "        real_y_predict_test=inv_x_test.iloc[:,0]+inv_y_predict_test\n",
    "        \n",
    "        real_rmse_test = sqrt(mean_squared_error(real_y_test, real_y_predict_test))\n",
    "        print('Test RMSE: %.3f' % real_rmse_test)\n",
    "        real_R2_test=int(1000*(metrics.r2_score(real_y_test, real_y_predict_test)))/1000\n",
    "        print('R2_test: %.3f' % real_R2_test)\n",
    "        \n",
    "        error_rmse.append(real_rmse_test)\n",
    "        error_r2hat.append(real_R2_test)\n",
    "        error_r2.append(R2_test)\n",
    "        \n",
    "        \n",
    "        plt.gcf().clear()\n",
    "        plt.figure(figsize=(5.5, 5.5))\n",
    "        plt.plot(range(len(inv_y_test)), inv_y_test, linestyle='-', marker='*', color='r')\n",
    "        plt.plot(range(len(inv_y_predict_test)), inv_y_predict_test, linestyle='-', marker='.', color='b')\n",
    "        plt.legend(['Actual','Predicted'], loc=2)\n",
    "        plt.title('Actual vs Predicted for {}'.format(y.name))\n",
    "        plt.ylabel('Trade Value')\n",
    "        plt.xlabel('Index')\n",
    "        plt.savefig('Data/LSTM-LinePlt{} ,{} epochs,{} neurons,{} learning_rate,{} batch size, {} random, {} R2.png'.format(y.name,\n",
    "                                n_epochs,n_neurons,learning_rate,bs,rs,R2_test), format='png', dpi=300)\n",
    "       \n",
    "\n",
    "        \n",
    "        \n",
    "    return error_rmse,error_r2,error_r2hat,train_y,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rs=29\n",
    "rs=42\n",
    "repeats = 1\n",
    "drop_rate=0.0\n",
    "do_batch='TRUE'\n",
    "do_model='B'\n",
    "random_split='TRUE'\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "e=30\n",
    "n=300\n",
    "lr=0.01\n",
    "b=1\n",
    "\n",
    "train_X=SplitData[0] \n",
    "test_X=SplitData[1] \n",
    "train_y=SplitData[2] \n",
    "test_y=SplitData[3]\n",
    "scaler_x=SplitData[4]\n",
    "scaler_y=SplitData[5]\n",
    "\n",
    "deney=experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)\n",
    "\n",
    "error_rmse=deney[0] \n",
    "error_r2=deney[1] \n",
    "error_r2hat=deney[2] \n",
    "train_y=deney[3]\n",
    "history=deney[4]\n",
    "print(error_r2)\n",
    "print(error_r2hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rs=29\n",
    "rs=42\n",
    "repeats = 1\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "e=200\n",
    "n=400\n",
    "lr=0.001\n",
    "b=30\n",
    "\n",
    "train_X=SplitData[0] \n",
    "test_X=SplitData[1] \n",
    "train_y=SplitData[2] \n",
    "test_y=SplitData[3]\n",
    "scaler_x=SplitData[4]\n",
    "scaler_y=SplitData[5]\n",
    "\n",
    "deney=experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)\n",
    "\n",
    "error_rmse=deney[0] \n",
    "error_r2=deney[1] \n",
    "error_r2hat=deney[2] \n",
    "train_y=deney[3]\n",
    "history=deney[4]\n",
    "print(error_r2)\n",
    "print(error_r2hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#X2 ve X3 için denemelerde kullanılan parametreler\n",
    "estimator_options = [100,1000,2000,5000]\n",
    "min_sample_leaf_options = [1,2,5,20,30]\n",
    "#random_state_options =[10]\n",
    "max_features_options=[10,\"log2\",\"sqrt\",\"auto\"]\n",
    "max_leaf_nodes_options=[2,5,10,50,100] \n",
    "min_weight_fraction_leaf_options=[0.0001,0.001,0.01,0.1] \n",
    "min_impurity_decrease_options =[0.0000001,0.000001,0.001,0.01]\n",
    "\n",
    "est=estimator_options[2]\n",
    "min_leaf=min_sample_leaf_options[0]\n",
    "feat=max_features_options[0]\n",
    "max_leaf=max_leaf_nodes_options[1]\n",
    "min_weight=min_weight_fraction_leaf_options[0]\n",
    "min_impurity=min_impurity_decrease_options[3]\n",
    "\n",
    "Start Set\n",
    "est=2000\n",
    "min_leaf=1\n",
    "feat=max_10\n",
    "max_leaf=5\n",
    "min_weight=0.0001\n",
    "min_impurity=0.001\n",
    "\n",
    "RS =42Ye gore bulunan Tuning sonucları:\n",
    "841840 için:\n",
    "est=5000\n",
    "min_leaf=1\n",
    "feat=\"log2\"\n",
    "max_leaf=10\n",
    "min_weight=0.001\n",
    "min_impurity=0.0000001\n",
    "\n",
    "841850 için:\n",
    "est=2000\n",
    "min_leaf=20\n",
    "feat=10\n",
    "max_leaf=50\n",
    "min_weight=0.1\n",
    "min_impurity=0.01\n",
    "\n",
    "841810 icin\n",
    "est=10000\n",
    "min_leaf=2\n",
    "feat=\"sqrt\"\n",
    "max_leaf=150\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "GENEL RS farklı oldugundaki Tuning sonucları\n",
    "841850 için:\n",
    "\n",
    "\n",
    "841840 için\n",
    "est=10000\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "\n",
    "\n",
    "NN 841850 için: ve RS=42 Splite göre yaıplan Tuning\n",
    "\n",
    "alph= 1e-12\n",
    "max_iteration= 50000\n",
    "slv= \"adam\"\n",
    "hidden_layer= (30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rs=42\n",
    "repeats = 3\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "results = DataFrame()\n",
    "\n",
    "\n",
    "estimator_options = [100,200,500,1000,5000,10000,20000]\n",
    "min_sample_leaf_options = [1,2,5,20,30]\n",
    "#random_state_options =[10]\n",
    "max_features_options=[10,\"log2\",\"sqrt\",\"auto\"]\n",
    "max_leaf_nodes_options=[2,5,10,100,200,300] \n",
    "min_weight_fraction_leaf_options=[0.00001,0.0001,0.001,0.01,0.1] \n",
    "min_impurity_decrease_options =[0.0000001,0.000001,0.001,0.01,0.05]\n",
    "\n",
    "param='TRUE'\n",
    "est=estimator_options[2]\n",
    "min_leaf=min_sample_leaf_options[0]\n",
    "feat=max_features_options[2]\n",
    "max_leaf=max_leaf_nodes_options[3]\n",
    "min_weight=min_weight_fraction_leaf_options[1]\n",
    "min_impurity=min_impurity_decrease_options[3]\n",
    "\n",
    "\n",
    "est=200\n",
    "min_leaf=2\n",
    "feat=\"log2\"\n",
    "max_leaf=5\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "print(\"parameter usage\", param)\n",
    "print(\"est=\", est)\n",
    "print(\"min_sample_leaf=\", min_leaf)\n",
    "print(\"max_features=\",feat)\n",
    "print(\"max_leaf_nodes=\", max_leaf)\n",
    "print(\"min_weight_fraction_leaf=\", min_weight)\n",
    "print(\"min_impurity_decrease=\", min_impurity)\n",
    "\n",
    "results=experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "print(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "\n",
    "for r in range (0,100):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for min_leaf in min_sample_leaf_options:\n",
    "            results_exp[str(min_leaf)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "\n",
    "\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_sample_leaf_options,rs,feat,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(y.name,MonthSeries,est,min_sample_leaf_options,feat,max_leaf,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"log2\"\n",
    "max_leaf=5\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "for r in range (0,20):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "        \n",
    "        for feat in max_features_options:\n",
    "            results_exp[str(feat)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        \n",
    "        \n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=5\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "print(\"est=\", est)\n",
    "print(\"min_sample_leaf=\", min_leaf)\n",
    "print(\"max_features=\",feat)\n",
    "print(\"max_leaf_nodes=\", max_leaf)\n",
    "print(\"min_weight_fraction_leaf=\", min_weight)\n",
    "print(\"min_impurity_decrease=\", min_impurity)\n",
    "\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "\n",
    "for r in range (0,30):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for max_leaf in max_leaf_nodes_options:\n",
    "            results_exp[str(max_leaf)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        \n",
    "        results=pd.concat([results,results_exp])\n",
    "            \n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,feat,max_leaf_nodes_options,min_weight,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,feat,max_leaf_nodes_options,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "\n",
    "print(\"est=\", est)\n",
    "print(\"min_sample_leaf=\", min_leaf)\n",
    "print(\"max_features=\",feat)\n",
    "print(\"max_leaf_nodes=\", max_leaf)\n",
    "print(\"min_weight_fraction_leaf=\", min_weight)\n",
    "print(\"min_impurity_decrease=\", min_impurity)\n",
    "\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "        for min_weight in min_weight_fraction_leaf_options:\n",
    "            results_exp[str(min_weight)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        \n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,feat,max_leaf,min_weight_fraction_leaf_options,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for{}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weig,{}min_imp.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,feat,max_leaf,min_weight_fraction_leaf_options,min_impurity))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.000001\n",
    "print(\"est=\", est)\n",
    "print(\"min_sample_leaf=\", min_leaf)\n",
    "print(\"max_features=\",feat)\n",
    "print(\"max_leaf_nodes=\", max_leaf)\n",
    "print(\"min_weight_fraction_leaf=\", min_weight)\n",
    "print(\"min_impurity_decrease=\", min_impurity)\n",
    "\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "\n",
    "        for min_impurity in min_impurity_decrease_options:\n",
    "            results_exp[str(min_impurity)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,feat,max_leaf,min_weight,min_impurity_decrease_options))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weig,{}min_impu.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,feat,max_leaf,min_weight,min_impurity_decrease_options))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator_options = [100,200,500,1000,5000,10000]\n",
    "\n",
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "\n",
    "        for est in estimator_options:\n",
    "            results_exp[str(est)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  estimator_options, min_leaf,rs,feat,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-BoxP for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} minweig,{}minimp.png'\n",
    "               .format(y.name,MonthSeries,estimator_options,min_leaf,feat,max_leaf,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM ICIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "\n",
    "repeats = 1\n",
    "\n",
    "# vary training epochs\"\n",
    "epochs = [50, 500, 1000,2000]\n",
    "neurons = [5, 50,100]\n",
    "learning_rates= [0.001, 0.01, 0.05, 0.1]\n",
    "batch_sizes=[5, 12, 24,50,100]\n",
    "\n",
    "\n",
    "e=3000\n",
    "n=200\n",
    "lr=0.02\n",
    "b=50\n",
    "\n",
    "\n",
    "e=500\n",
    "n=100\n",
    "lr=0.05\n",
    "b=50\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "\n",
    "        for e in epochs:\n",
    "            results_exp[str(e)] = experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "\n",
    "results.boxplot()\n",
    "plt.title(\"LSTM-Box Plot for {}-{}, {} epochs,{} neurons,{} learning_rate, {}batch size \"\n",
    "          .format(y.name,MonthSeries,epochs,n,lr,b))\n",
    "plt.savefig('Data/LSTM-Box Plot for {}-{}, {} epochs,{} neurons {}lr,{}b.png'\n",
    "               .format(y.name,MonthSeries,epochs,n,lr,b))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "\n",
    "repeats = 1\n",
    "e=500\n",
    "n=100\n",
    "lr=0.001\n",
    "b=50\n",
    "deney=experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)\n",
    "deney[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#repeats=10\n",
    "e=2000\n",
    "n=100\n",
    "lr=0.05\n",
    "b=50\n",
    "\n",
    "neurons = [5, 50, 100]\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for n in neurons:\n",
    "            results_exp[str(n)] = experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"LSTM-Box Plot for {}-{}, {} epochs,{} neurons,{} learning_rate {}batch size\"\n",
    "          .format(y.name,MonthSeries,e,neurons,lr,b))\n",
    "plt.savefig('Data/LSTM-Box Plot for {}-{}, {} epochs,{} neurons{},lr{}, b.png'\n",
    "               .format(y.name,MonthSeries,e,neurons,lr,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "repeats = 10\n",
    "e=100\n",
    "n=50\n",
    "lr=0.05\n",
    "b=50\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for b in batch_sizes:\n",
    "            results_exp[str(b)] = experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"LSTM-Box Plot for {}-{}, {} epochs,{} neurons,{} learning_rate {}batch size \"\n",
    "          .format(y.name,MonthSeries,e,n,lr,batch_sizes))\n",
    "plt.savefig('Data/LSTM-Box Plot for {}-{}, {} epochs,{} neurons{}lr,{}bsize.png'\n",
    "               .format(y.name,MonthSeries,e,n,lr,batch_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "LSTM SONU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN BASLANGICI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def experiment_NN(repeats,param,alph,max_iteration,slv,rs,hidden_layer,train_X, test_X, train_y, test_y,scaler_x,scaler_y):\n",
    "\n",
    "#    rs=90\n",
    "    error_rmse = list()\n",
    "    error_r2hat = list()\n",
    "    error_r2 = list()\n",
    "    for r in range(repeats):\n",
    "        \n",
    "        if param== 'TRUE':\n",
    "            MLP = MLPRegressor(\n",
    "                              alpha = alph,\n",
    "                              solver=slv ,\n",
    "                              max_iter=max_iteration,\n",
    "       #                       random_state =rs,\n",
    "                              hidden_layer_sizes=hidden_layer\n",
    "                        )\n",
    "        \n",
    "        elif param== 'FALSE':\n",
    "             MLP = MLPRegressor()\n",
    "            \n",
    "        \n",
    "        MLPRegressor.fit(MLP,train_X,train_y)\n",
    "        \n",
    "        \n",
    "        # make a prediction\n",
    "        y_predict_test = MLP.predict(test_X)\n",
    "        y_predict_train = MLP.predict(train_X)\n",
    "\n",
    "  \n",
    "        \n",
    "        #test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "#        test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "        inv_x_test = scaler_x.inverse_transform(test_X)\n",
    "        inv_x_test = pd.DataFrame(data=inv_x_test[:,:])\n",
    "\n",
    "\n",
    "        # invert scaling for forecast\n",
    "        inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "#        inv_y_predict_test = inv_y_predict_test[:,0]\n",
    "        inv_y_predict_train = scaler_y.inverse_transform(y_predict_train)\n",
    "#        inv_y_predict_train = inv_y_predict_train[:,0]\n",
    "\n",
    "        # invert scaling for actual\n",
    "        y_test = test_y.reshape((len(test_y), 1))\n",
    "        inv_y_test = scaler_y.inverse_transform(test_y)\n",
    "        inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "        y_train = train_y.reshape((len(train_y), 1))\n",
    "        inv_y_train = scaler_y.inverse_transform(train_y)\n",
    "        inv_y_train = inv_y_train[:,0]\n",
    "\n",
    "        # calculate RMSE for DIFFERENCE\n",
    "        rmse_test = sqrt(mean_squared_error(inv_y_test, inv_y_predict_test))\n",
    "#        print('Test RMSE: %.3f' % rmse_test)\n",
    "        R2_test=int(1000*(metrics.r2_score(inv_y_test, inv_y_predict_test)))/1000\n",
    "#        print('R2_test: %.3f' % R2_test)\n",
    "\n",
    "        rmse_train = sqrt(mean_squared_error(inv_y_train, inv_y_predict_train))\n",
    "#        print('Train RMSE: %.3f' % rmse_train)\n",
    "        R2_train=int(1000*(metrics.r2_score(inv_y_train, inv_y_predict_train)))/1000\n",
    "#        print('R2_train: %.3f' % R2_train)\n",
    "\n",
    "        # calculate RMSE for REAL VALUE\n",
    "\n",
    "        real_y_test= inv_x_test.iloc[:,0]+inv_y_test\n",
    "        real_y_predict_test=inv_x_test.iloc[:,0]+inv_y_predict_test\n",
    "        \n",
    "        real_rmse_test = sqrt(mean_squared_error(real_y_test, real_y_predict_test))\n",
    "#        print('Test RMSE: %.3f' % real_rmse_test)\n",
    "        real_R2_test=int(1000*(metrics.r2_score(real_y_test, real_y_predict_test)))/1000\n",
    "#        print('R2_test: %.3f' % real_R2_test)\n",
    "        \n",
    "        error_rmse.append(real_rmse_test)\n",
    "        error_r2hat.append(real_R2_test)\n",
    "        error_r2.append(R2_test)\n",
    "        \n",
    "#        plt.gcf().clear()\n",
    "#        plt.figure(figsize=(5.5, 5.5))\n",
    "#        plt.plot(range(len(inv_y_test)), inv_y_test, linestyle='-', marker='*', color='r')\n",
    "#        plt.plot(range(len(inv_y_predict_test)), inv_y_predict_test, linestyle='-', marker='.', color='b')\n",
    "#        plt.legend(['Actual','Predicted'], loc=2)\n",
    "#        plt.title('Actual vs Predicted for {}'.format(y.name))\n",
    "#        plt.ylabel('Trade Value')\n",
    "#        plt.xlabel('Index')\n",
    "#        plt.savefig('Data/RF-LinePlt{} ,{} est,{} min_leaf,{} rs_for split,{} max_leaf, {} min_weight,{}min_impurity, {} R2.png'.format(y.name,\n",
    "#                                est,min_leaf,random,feat,max_leaf,min_weight,min_impurity,R2_test), format='png', dpi=300)\n",
    "       \n",
    "\n",
    "        \n",
    "        \n",
    "    return error_rmse,error_r2,error_r2hat,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "param='TRUE'\n",
    "random_split='TRUE'\n",
    "alpha_options = [0.0001,0.00000001,0.0000000001, 0.000000000001]\n",
    "solver_options = ['lbfgs', 'adam' ] # sgd solver cok sapıttı\n",
    "max_iteration_options = [50000,60000,100000]\n",
    "#random_state_options =[1,10,50,75,200]\n",
    "#random_state_options =[10,50,90]\n",
    "random_state_options =[90]\n",
    "hidden_layer_sizes_options=[(30,100,10),(30,30),(100,100),(30,30,30)]\n",
    "\n",
    "alph=alpha_options[0]\n",
    "max_iteration=max_iteration_options[0]\n",
    "slv=solver_options[1]\n",
    "rseed=random_state_options[0]\n",
    "hidden_layer=hidden_layer_sizes_options[0]\n",
    "\n",
    "\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        rs=42\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for alph in alpha_options:\n",
    "            rseed=90\n",
    "            results_exp[str(alph)] = experiment_NN(repeats,param,alph,max_iteration,slv,rseed,hidden_layer,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "            \n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer \"\n",
    "          .format(y.name,MonthSeries,alpha_options,max_iteration,slv,hidden_layer))\n",
    "plt.savefig(\"Data/18Mayıs/NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer.png \"\n",
    "          .format(y.name,MonthSeries,alpha_options,max_iteration,slv,hidden_layer), format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "\n",
    "alph=alpha_options[3]\n",
    "max_iteration=max_iteration_options[0]\n",
    "slv=solver_options[1]\n",
    "rseed=random_state_options[0]\n",
    "hidden_layer=hidden_layer_sizes_options[1]\n",
    "\n",
    "\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        rs=42\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for max_iteration in max_iteration_options:\n",
    "            \n",
    "            results_exp[str(max_iteration)] = experiment_NN(repeats,param,alph,max_iteration,slv,rseed,hidden_layer,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "            \n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration_options,slv,hidden_layer))\n",
    "plt.savefig(\"Data/18Mayıs/NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer.png \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration_options,slv,hidden_layer), format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "\n",
    "alph=alpha_options[3]\n",
    "max_iteration=max_iteration_options[0]\n",
    "slv=solver_options[1]\n",
    "rseed=random_state_options[0]\n",
    "hidden_layer=hidden_layer_sizes_options[1]\n",
    "\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        rs=42\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for slv in solver_options:\n",
    "            \n",
    "            results_exp[str(slv)] = experiment_NN(repeats,param,alph,max_iteration,slv,rseed,hidden_layer,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "            \n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration,solver_options,hidden_layer))\n",
    "plt.savefig(\"Data/18Mayıs/NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer.png \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration,solver_options,hidden_layer), format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "\n",
    "alph=alpha_options[3]\n",
    "max_iteration=max_iteration_options[0]\n",
    "slv=solver_options[1]\n",
    "rseed=random_state_options[0]\n",
    "hidden_layer=hidden_layer_sizes_options[1]\n",
    "\n",
    "print('alph=',alph)\n",
    "print('max_iteration=',max_iteration)\n",
    "print('slv=',slv)\n",
    "print('hidden_layer=',hidden_layer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        rs=42\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for hidden_layer in hidden_layer_sizes_options:\n",
    "            \n",
    "            results_exp[str(hidden_layer)] = experiment_NN(repeats,param,alph,max_iteration,slv,rseed,hidden_layer,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "            \n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration,slv,hidden_layer_sizes_options))\n",
    "plt.savefig(\"Data/18Mayıs/NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer.png \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration,slv,hidden_layer_sizes_options), format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN DENEME VE KONTROL ICIN ESKI VERSIYONDAN GELEN KODLAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn (alph,max_iteration,slv,rseed,hidden_layer,X_train, X_test, y_train, y_test):\n",
    "    MLP = MLPRegressor(\n",
    "                              alpha = alph,\n",
    "                              solver=slv ,\n",
    "                              max_iter=max_iteration,\n",
    "                              random_state =rseed,\n",
    "                              hidden_layer_sizes=hidden_layer\n",
    "    )\n",
    "    MLPRegressor.fit(MLP,X_train,y_train)\n",
    "    \n",
    "    predictions = MLP.predict(X_test)\n",
    "    \n",
    "    MAE=int(metrics.mean_absolute_error(y_test, predictions))\n",
    "    MSE=int(sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "    R2=int(1000*(metrics.r2_score(y_test, predictions)))/1000\n",
    "    print('R2 nn icindeki',R2)\n",
    "    print(alph,max_iteration,slv,rseed,hidden_layer)\n",
    "    return MAE,MSE,R2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calıstır_nn(Product,MonthSeries,Scaler_Type,X_train, X_test, y_train, y_test):\n",
    "    estimation_method='nn'\n",
    "    alpha_options = [0.0001,0.00000001]\n",
    "    solver_options = [ 'adam']#,'lbfgs' ] # sgd solver cok sapıttı\n",
    "    max_iteration_options = [50000]#,60000,100000]\n",
    "    #random_state_options =[1,10,50,75,200]\n",
    "    #random_state_options =[10,50,90]\n",
    "    random_state_options =[90]\n",
    "    hidden_layer_sizes_options=[(30,100,10)]#,(30,30),(100,100),(30,30,30)]\n",
    "\n",
    "    sonuc = pd.DataFrame(columns='EstMethod Product Scaler MonthSeries alpha max_iteration slv hidden_layer random MAE MSE R2'.split())\n",
    "    i=0\n",
    "\n",
    "    for alpha in alpha_options:\n",
    "    \n",
    "        for max_iteration in max_iteration_options:\n",
    "\n",
    "            for slv in solver_options:\n",
    "        \n",
    "                for hidden_layer in hidden_layer_sizes_options:\n",
    "           \n",
    "                    for rseed in random_state_options:\n",
    "                \n",
    "                        estimate_metric=nn(alpha,max_iteration,slv,rseed,hidden_layer,X_train, X_test, y_train, y_test)\n",
    "                    \n",
    "                        MAE=estimate_metric[0]\n",
    "                        MSE=estimate_metric[1]\n",
    "                        R2=estimate_metric[2]\n",
    "                        print(R2)\n",
    "                        print('alpha',alpha,'iter:',max_iteration,'slvr:',slv,'random:',rseed,'layers:',hidden_layer,\n",
    "                          MAE,MSE,R2)\n",
    "                        sonuc.loc[i]=[estimation_method,Product,Scaler_Type,MonthSeries,alpha,max_iteration,slv,hidden_layer,random,MAE,MSE,R2]\n",
    "                        i=i+1\n",
    "    return sonuc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y=y3\n",
    "Z=z3\n",
    "X=X3\n",
    "\n",
    "values = X.values\n",
    "values = values.astype('float32')\n",
    "scaler_x= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaled_value_x = scaler_x.fit_transform(values)\n",
    "scaled_value_x = pd.DataFrame(data=scaled_value_x[:,:])\n",
    "\n",
    "values = y.values\n",
    "values = values.astype('float32')\n",
    "scaler_y= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaled_value_y = scaler_y.fit_transform(values)\n",
    "scaled_value_y = pd.DataFrame(data=scaled_value_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_value_x,scaled_value_y,test_size=0.2,random_state=42,stratify=Z['Month'])\n",
    "\n",
    "\n",
    "random_split='TRUE'\n",
    "rs=42\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "X_train=SplitData[0] \n",
    "X_test=SplitData[1] \n",
    "y_train=SplitData[2] \n",
    "y_test=SplitData[3]\n",
    "scaler_x=SplitData[4]\n",
    "scaler_y=SplitData[5]\n",
    "split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sonuc=calıstır_nn(Product,MonthSeries,ScalerType,X_train, X_test, y_train, y_test)\n",
    "filename='Out_NN_Prediction_Results_{one}_Product{two}'.format(one=datetime.now().strftime('Date_%m-%d_Time%H_%M'),two=Product)\n",
    "\n",
    "#sonuc.to_excel('{}.xlsx'.format(filename),index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN SONU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyDOE import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#fig, axs = plt.subplots(2, 3)\n",
    "\n",
    "\n",
    "results.boxplot()\n",
    "plt.title(\"Boxplot of Something\")\n",
    "\n",
    "#set_title('change outlier\\npoint symbols')\n",
    "\n",
    "\n",
    "plt.savefig('boxplot_epochs.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aşağıdaki Orjinal Kod Parçası"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    print(train_X.shape[1])\n",
    "    print(train_X.shape[2])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(300))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.15, clipvalue=0.3)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=800, batch_size=12, validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "#test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "inv_x_test = scaler_x.inverse_transform(test_X_reshaped)\n",
    "inv_x_test = pd.DataFrame(data=inv_x_test[:,:])\n",
    "\n",
    "# make a prediction\n",
    "y_predict_test = model.predict(test_X)\n",
    "y_predict_train = model.predict(train_X)\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "inv_y_predict_test = inv_y_predict_test[:,0]\n",
    "inv_y_predict_train = scaler_y.inverse_transform(y_predict_train)\n",
    "inv_y_predict_train = inv_y_predict_train[:,0]\n",
    "\n",
    "# invert scaling for actual\n",
    "y_test = test_y.reshape((len(test_y), 1))\n",
    "inv_y_test = scaler_y.inverse_transform(test_y)\n",
    "inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "y_train = train_y.reshape((len(train_y), 1))\n",
    "inv_y_train = scaler_y.inverse_transform(train_y)\n",
    "inv_y_train = inv_y_train[:,0]\n",
    "\n",
    "# calculate RMSE for DIFFERENCE\n",
    "rmse_test = sqrt(mean_squared_error(inv_y_test, inv_y_predict_test))\n",
    "print('Test RMSE: %.3f' % rmse_test)\n",
    "R2_test=int(1000*(metrics.r2_score(inv_y_test, inv_y_predict_test)))/1000\n",
    "print('R2_test: %.3f' % R2_test)\n",
    "\n",
    "rmse_train = sqrt(mean_squared_error(inv_y_train, inv_y_predict_train))\n",
    "print('Train RMSE: %.3f' % rmse_train)\n",
    "R2_train=int(1000*(metrics.r2_score(inv_y_train, inv_y_predict_train)))/1000\n",
    "print('R2_train: %.3f' % R2_train)\n",
    "\n",
    "# calculate RMSE for REAL VALUE\n",
    "\n",
    "real_y_test= inv_x_test.iloc[:,0]+inv_y_test\n",
    "real_y_predict_test=inv_x_test.iloc[:,0]+inv_y_predict_test\n",
    "\n",
    "rmse_test = sqrt(mean_squared_error(real_y_test, real_y_predict_test))\n",
    "print('Test RMSE: %.3f' % rmse_test)\n",
    "R2_test=int(1000*(metrics.r2_score(real_y_test, real_y_predict_test)))/1000\n",
    "print('R2_test: %.3f' % R2_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=pd.DataFrame(columns=['inv_y_test'],data=inv_y_test)\n",
    "b=pd.DataFrame(columns=['inv_y_predict_test'],data=inv_y_predict_test)\n",
    "c=pd.concat([a, b], axis=1)\n",
    "\n",
    "sns.pairplot(c[['inv_y_test','inv_y_predict_test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(inv_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=pd.DataFrame(columns=['inv_y_train'],data=inv_y_train)\n",
    "b=pd.DataFrame(columns=['inv_y_predict_train'],data=inv_y_predict_train)\n",
    "\n",
    "c=pd.concat([a, b], axis=1)\n",
    "\n",
    "sns.pairplot(c[['inv_y_train','inv_y_predict_train']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_y_predict_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_y_predict_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
