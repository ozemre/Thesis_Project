{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murat.ozemre\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\murat.ozemre\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "C:\\Users\\murat.ozemre\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.layers import Dense,Input, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from random import gauss\n",
    "from random import seed\n",
    "#from pandas import Series\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from random import randrange\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import gauss\n",
    "from random import seed\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "from scipy.stats.stats import pearsonr    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12-27 20:37'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Experiment_Ready as exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\murat.ozemre\\\\Desktop\\\\Thesis_Project\\\\Data_Learning_Prediction'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Sources_and_Preparation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Product_Type_Options = [841810,841840,841850]\n",
    "Product=Product_Type_Options[0] #841810\n",
    "Exp_Country='TUR' # 'CHN'\n",
    "Imp_Country='GBR'\n",
    "\n",
    "if Exp_Country=='CHN':\n",
    "    Currency='CNY'\n",
    "    EXP0='TUR'   \n",
    "elif Exp_Country=='TUR':\n",
    "    Currency='TRY'\n",
    "    EXP0='CHN'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841810 MaxAbsScaler\n"
     ]
    }
   ],
   "source": [
    "Scaler_Type_Options = ['Normalizer', 'MinMaxScaler','MaxAbsScaler','RobustScaler','StandardScaler' ]\n",
    "ScalerType=Scaler_Type_Options[2]\n",
    "print(Product,ScalerType)\n",
    "\n",
    "MonthSeries=\"3\"\n",
    "MonthSeries_option=[\"1\",\"2\",\"3\",\"6\",\"12\"]\n",
    "#MonthSeries_option=[\"12\",\"123\",\"1236\",\"1236_12\",\"__12\",\"__126\",\"__1263\",\"__12632\"]\n",
    "#MonthSeries_option=[\"12\",\"123\",\"1236\",\"1236_12\",\"__12\"]\n",
    "#X1hat.iloc[3:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_Core1 = pd.ExcelFile('Data_{}_{}_{}.xlsx'.format(Exp_Country,Imp_Country,Product))\n",
    "y = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])['{}_{}_{}'.format(Exp_Country,Imp_Country,Product)]\n",
    "Z = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])[['Date','Year','Month']]\n",
    "\n",
    "X = Data_Core1.parse('X{}'.format(MonthSeries), header=0,index_col=None, na_values=['NA'])\n",
    "X.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "X_Column_Names=list(X.columns.values)\n",
    "n_feature=X.shape[1]\n",
    "\n",
    "Xhat = Data_Core1.parse('Xhat', header=0,index_col=None, na_values=['NA'])\n",
    "Xhat.drop(['Date','Year','Month'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set X train, X test, y train, y test\n",
    "rs=42\n",
    "Scaled_Train_Test_Split=exp.X_Y_scaler_train_test_Split(X,y,Z,random=rs)\n",
    "\n",
    "X_train = Scaled_Train_Test_Split[0]\n",
    "X_test = Scaled_Train_Test_Split[1]\n",
    "y_train = Scaled_Train_Test_Split[2]\n",
    "y_test = Scaled_Train_Test_Split[3]\n",
    "scaler_X = Scaled_Train_Test_Split[4]  \n",
    "scaler_y = Scaled_Train_Test_Split[5]\n",
    "scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "scaled_value_y=Scaled_Train_Test_Split[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomforest rs= 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1753, 2307, 0.762), (710, 897, 0.96))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.randomforest(X_train, X_test, y_train, y_test,scaler_y,est=100,rand=20,is_random_fixed='FALSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomforest rs= 93\n",
      "randomforest rs= 51\n",
      "randomforest rs= 76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2527, 2432, 2701], [0.717, 0.739, 0.673])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.experiment_RandomForest(3,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,rand=20,is_random_fixed='FALSE')\n",
    "#,est=3000,random=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomforest rs= 50\n",
      "randomforest rs= 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2295, 2295], [0.764, 0.764])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.experiment_RandomForest(2,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,est=3000,rand=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Learning_Prediction/Box_Plots_For_RandomForest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split rs= 3\n",
      "randomforest rs= 2\n",
      "randomforest rs= 45\n",
      "randomforest rs= 34\n",
      "randomforest rs= 41\n",
      "randomforest rs= 3\n",
      "randomforest rs= 30\n",
      "randomforest rs= 89\n",
      "randomforest rs= 72\n",
      "randomforest rs= 46\n",
      "randomforest rs= 46\n",
      "randomforest rs= 96\n",
      "randomforest rs= 79\n",
      "Size: 12\n",
      "             10      log2      sqrt      auto\n",
      "count  3.000000  3.000000  3.000000  3.000000\n",
      "mean   0.737333  0.714000  0.723000  0.739000\n",
      "std    0.004041  0.001732  0.002646  0.003606\n",
      "min    0.733000  0.712000  0.720000  0.736000\n",
      "25%    0.735500  0.713500  0.722000  0.737000\n",
      "50%    0.738000  0.715000  0.724000  0.738000\n",
      "75%    0.739500  0.715000  0.724500  0.740500\n",
      "max    0.741000  0.715000  0.725000  0.743000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5YAAAEICAYAAAAk+GtkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLCVJkiRJrRhYSpIkSZJa+f9Jz7HIFVgRVQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c845da57f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MAIN for Random Forest Experiments\n",
    "repeats=3\n",
    "random_range_for_split=1\n",
    "rs=random.randint(1,100)\n",
    "#rs=12\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "estimator_options = [100,200,500,1000,5000,10000,20000]\n",
    "min_sample_leaf_options = [1,2,5,20,30]\n",
    "#random_state_options =[10]\n",
    "max_features_options=[10,\"log2\",\"sqrt\",\"auto\"]\n",
    "max_leaf_nodes_options=[2,5,10,100,200,300] \n",
    "min_weight_fraction_leaf_options=[0.00001,0.0001,0.001,0.01,0.1] \n",
    "min_impurity_decrease_options =[0.0000001,0.000001,0.001,0.01,0.05]\n",
    "\n",
    "\n",
    "\n",
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "\n",
    "param='TRUE'\n",
    "\n",
    "for r in range (random_range_for_split):\n",
    "\n",
    "\n",
    "    rs=random.randint(1,100)\n",
    "\n",
    "    print('split rs=',rs)\n",
    "    \n",
    "    Scaled_Train_Test_Split=exp.X_Y_scaler_train_test_Split(X,y,Z,random=rs)\n",
    "\n",
    "    X_train = Scaled_Train_Test_Split[0]\n",
    "    X_test = Scaled_Train_Test_Split[1]\n",
    "    y_train = Scaled_Train_Test_Split[2]\n",
    "    y_test = Scaled_Train_Test_Split[3]\n",
    "    scaler_X = Scaled_Train_Test_Split[4]  \n",
    "    scaler_y = Scaled_Train_Test_Split[5]\n",
    "    scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "    scaled_value_y=Scaled_Train_Test_Split[7]\n",
    "    \n",
    "    \n",
    "    for feat in max_features_options:\n",
    "        results_exp[str(feat)] =exp.experiment_RandomForest(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',\n",
    "                  est=est,min_leaf=min_leaf,feat=feat,max_leaf=max_leaf,min_weight=min_weight,min_impurity=min_impurity)[1] \n",
    "    \n",
    "    results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1816, 2337, 0.756)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4+RgZmY5/x8kVZ5uBD+v+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c845d97400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X = X_train\n",
    "test_X = X_test\n",
    "train_y = y_train \n",
    "test_y = y_test\n",
    "scaler_y = scaler_y\n",
    "\n",
    "# Random Foest Regressor model\n",
    "rfc=RandomForestRegressor(n_estimators=3000)\n",
    "\n",
    "# Random Foest Regressor model train\n",
    "RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "\n",
    "# Random Foest Regressor mode predict\n",
    "y_predict_test = rfc.predict(X_test)\n",
    "\n",
    "# Compare predicted Y and real Y \n",
    "exp.inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'YES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIC AYAR YAPMADAN FARKLI SPLIT YAPARAK RF CALISMASI\n",
    "Dort Farklı Calısma Yapıldı\n",
    "1. Aylık Stratify olmadan her 3 urun kodu için çalıştırıldı\n",
    "2. Aylık Stratify yapılarak her 3 ürün kodu için çalıştırıldı\n",
    "3. Aylık Stratify yapılarak aylık fark verisi üzerinden (Xhat) her 3 ürün kodu için çalıştırıldı \n",
    "    R2 gercek değeri alındı.\n",
    "4. Aylık Stratify yapılarak aylık fark verisi üzerinden (Xhat) her 3 ürün kodu için çalıştırıldı \n",
    "    R2 o ayın gerçek değerine göre ayarlanarak alındı.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repeats=1\n",
    "random_range_for_split=5\n",
    "rs=random.randint(1,100)\n",
    "#rs=12\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "est=500\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "\n",
    "param='TRUE'\n",
    "\n",
    "for r in range (random_range_for_split):\n",
    "\n",
    "#for r in range(repeats):\n",
    "    rs=random.randint(1,100)\n",
    "#    rs=42\n",
    "    print(rs)\n",
    "    SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "    \n",
    "    train_X=SplitData[0] \n",
    "    test_X=SplitData[1] \n",
    "    train_y=SplitData[2] \n",
    "    test_y=SplitData[3]\n",
    "    scaler_x=SplitData[4]\n",
    "    scaler_y=SplitData[5]\n",
    "    split_succesfull=SplitData[7]\n",
    "    print(split_succesfull)\n",
    "\n",
    "    experiment_result=experiment_RF(repeats,param,est,min_leaf,rs,\n",
    "                                    feat,max_leaf,min_weight,min_impurity,\n",
    "                                    train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "    \n",
    "#Xhat için analiz yapıldığı ve Adjusted R2 hesaplandığı zaman [2] nolu output kullanılıyor \n",
    "#                                    train_X, test_X, train_y, test_y,scaler_x,scaler_y)[2]\n",
    "\n",
    "    results[str(r)]= experiment_result\n",
    "    results_exp[split_succesfull]= experiment_result\n",
    "    results_split=pd.concat([results_split,results_exp])\n",
    "    print ('results split',results_split)\n",
    "\n",
    "results_randomnumber_bins=results\n",
    "resultvalues=results.values\n",
    "results_all=resultvalues.reshape((random_range_for_split*repeats,1))\n",
    "results_all=pd.DataFrame(data=results_all[:,:])\n",
    "\n",
    "#max_R2=results_all.describe().iloc[7,:]\n",
    "#std=results_all.describe().iloc[2,:]\n",
    "#mean=results_all.describe().iloc[1,:]\n",
    "\n",
    "mean=results_all.describe().values[1]\n",
    "std=results_all.describe().values[2]\n",
    "max_R2=results_all.describe().values[7]\n",
    "\n",
    "results_all.hist()\n",
    "plt.title('{} and with split threshold {} for {} different run'.format(y.name,th,random_range_for_split))\n",
    "plt.axis([0, 1, 0, 400])\n",
    "plt.xlabel('mean {}, std {}, max_value{}'.format(mean,std,max_R2))\n",
    "#plt.savefig('Distiribution_without_Tuning\\Histogram Plot R2 for {} and with (non stratify) split threshold {} for {} different run.png'.format(y.name,th,random_range_for_split))\n",
    "plt.savefig('Distiribution_without_Tuning\\Histogram Plot R2 for {} and with (rs=random) split threshold {} and {} param for {} different run.png'.format(y.name,th,param,random_range_for_split))\n",
    "\n",
    "pyplot.show()\n",
    "\n",
    "plt.gcf().clear()\n",
    "plt.title('{} and with split threshold {}'.format(y.name,th))\n",
    "\n",
    "results_split.boxplot()\n",
    "#plt.savefig('Distiribution_without_Tuning\\Box Plot R2 for {} and with (non stratify) split threshold {} for {} different run.png'.format(y.name,th,random_range_for_split), format='png', dpi=300)\n",
    "plt.savefig('Distiribution_without_Tuning\\Box Plot R2 for {} and with (rs=random)split threshold {} for {} different run.png'.format(y.name,th,random_range_for_split), format='png', dpi=300)\n",
    "\n",
    "pyplot.show()                                   \n",
    "\n",
    "      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ince Ayar Yapılmadan once (Spilt için RS sabit) ve tuning sonrasındaki karşılaştırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repeats=3\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "\n",
    "#RS =42ye gore bulunan Tuning sonucları: \n",
    "\n",
    "#841840 Parametre seti\n",
    "est=5000\n",
    "min_leaf=1\n",
    "feat=\"log2\"\n",
    "max_leaf=10\n",
    "min_weight=0.001\n",
    "min_impurity=0.0000001\n",
    "\n",
    "#841810 Parametre seti\n",
    "est=10000\n",
    "min_leaf=2\n",
    "feat=\"sqrt\"\n",
    "max_leaf=150\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "#841850  Parametre seti\n",
    "est=2000\n",
    "min_leaf=20\n",
    "feat=10\n",
    "max_leaf=50\n",
    "min_weight=0.1\n",
    "min_impurity=0.01\n",
    "\n",
    "\n",
    "#RS =42ye gore bulunan Tuning sonucları: \n",
    "#RS =Randoma gore bulunan Tuning sonucları: \n",
    "\n",
    "est=10000\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "\n",
    "#Etkin olan parametre seti\n",
    "\n",
    "est=10000\n",
    "min_leaf=2\n",
    "feat=\"sqrt\"\n",
    "max_leaf=150\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "#NN için parametreler\n",
    "alph= 1e-12\n",
    "max_iteration= 50000\n",
    "slv= \"adam\"\n",
    "hidden_layer= (30, 30)\n",
    "\n",
    "\n",
    "\n",
    "param_options=[\"FALSE\",\"TRUE\"]\n",
    "\n",
    "#Farklı RAndom Seed Splitler\n",
    "rs=random.randint(1,100)\n",
    "#Tek bir Random Seed Split\n",
    "rs=42\n",
    "\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "train_X=SplitData[0] \n",
    "test_X=SplitData[1] \n",
    "train_y=SplitData[2] \n",
    "test_y=SplitData[3]\n",
    "scaler_x=SplitData[4]\n",
    "scaler_y=SplitData[5]\n",
    "split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "experiment=\"NN\" #or RF\n",
    "first_loop_range=50\n",
    "second_loop_range=2\n",
    "for r in range (0,first_loop_range):\n",
    "    rs=random.randint(1,100)\n",
    "   \n",
    "    SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "    print(rs)\n",
    "    train_X=SplitData[0] \n",
    "    test_X=SplitData[1] \n",
    "    train_y=SplitData[2] \n",
    "    test_y=SplitData[3]\n",
    "    scaler_x=SplitData[4]\n",
    "    scaler_y=SplitData[5]\n",
    "    split_succesfull=SplitData[7]\n",
    "    \n",
    "    \n",
    "    for p in range (0, second_loop_range):\n",
    "        \n",
    "        param=param_options[p]\n",
    "        \n",
    "        if experiment==\"RF\":\n",
    "            experiment_result=experiment_RF(repeats,param,est,min_leaf,rs,\n",
    "                                    feat,max_leaf,min_weight,min_impurity,\n",
    "                                    train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        elif experiment==\"NN\":\n",
    "             experiment_result=experiment_NN(repeats,param,alph,max_iteration,slv,rseed,hidden_layer,\n",
    "                          train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        \n",
    "        results_exp[param]= experiment_result\n",
    "        \n",
    "#    results_split[split_succesfull]= experiment_result\n",
    "    results=pd.concat([results,results_exp])\n",
    "\n",
    "results_randomnumber_bins=results\n",
    "resultvalues=results.values\n",
    "results_all=resultvalues.reshape((first_loop_range*second_loop_range*repeats,1))\n",
    "results_all=pd.DataFrame(data=results_all[:,:])\n",
    "\n",
    "mean=results_all.describe().values[1]\n",
    "std=results_all.describe().values[2]\n",
    "max_R2=results_all.describe().values[7]\n",
    "\n",
    "plt.gcf().clear()\n",
    "plt.title('{} with (according rs=42 Tuned and split general) before Tuning and (trained rs=90) after Tuning'.format(y.name))\n",
    "plt.xlabel('mean {}, std {}, max_value{}'.format(mean,std,max_R2))\n",
    "results.boxplot()\n",
    "plt.savefig('Distiribution_without_Tuning\\Box Plot R2 for {} and (tuned rs =42)(split=general){} (trained rs=90) different run.png'.format(y.name,repeats), \n",
    "            format='png', dpi=300)\n",
    "\n",
    "pyplot.show()                                   \n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sonuc=pd.concat([sonuc,calıstır_randomforest(X_train, X_test, y_train, y_test,scaler_y,Product,MonthSerie,ScalerType)])\n",
    "\n",
    "#max_R2=int((sonuc['R2'].max())*1000)/1000\n",
    "#filename='Out_Random_Predict_Results_{one}_Product{two}_{four}perc_with max{tre}'.format(one=datetime.now().strftime('Date_%m-%d_Time%H_%M'),\n",
    "#                                                                                      two=Product,tre=max_R2,four=percentile)\n",
    "#sonuc.to_excel('{}.xlsx'.format(filename),index = False)      \n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LSTM EXPERIMENT\n",
    "\n",
    "#def experiment(repeats,n_epochs,n_neurons,learning_rate,bs,rs,X,y,date):\n",
    "def experiment_LSTM(repeats,n_epochs,n_neurons,learning_rate,bs,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y):\n",
    "    K.clear_session()\n",
    "\n",
    "#    print(type(train_X))\n",
    "    train_X =train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "#    train_X =train_X.reshape((train_X.shape[0], train_X.shape[1],1))\n",
    "#    test_X = test_X.reshape((test_X.shape[0], test_X.shape[1],1))\n",
    "#    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    " \n",
    "    \n",
    "    error_rmse = list()\n",
    "    error_r2hat = list()\n",
    "    error_r2 = list()\n",
    "    for r in range(repeats):\n",
    "        \n",
    "        print('Shape of X Train',train_X.shape[1],train_X.shape[2])\n",
    "    \n",
    "\n",
    "        if do_model=='A':\n",
    "            model = Sequential() \n",
    "            model.add(LSTM(n_neurons,input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "            model.add(Dropout(drop_rate))\n",
    "            \n",
    "            model.add(Dense(n_neurons))\n",
    "            model.add(Dropout(drop_rate))\n",
    "            \n",
    "            model.add(Dense(1))\n",
    "#            model.add(Activation('sigmoid'))\n",
    "            model.add(Activation('linear'))\n",
    "        \n",
    "        elif do_model=='B':   \n",
    "            input_layer=Input(shape=(train_X.shape[1], train_X.shape[2]),dtype='float32')\n",
    "            lstm_layer1=LSTM(n_neurons,input_shape=(train_X.shape[1],train_X.shape[2]),\n",
    "                         dropout=drop_rate, \n",
    "                         recurrent_dropout=drop_rate,\n",
    "                         return_sequences=True)(input_layer)\n",
    "            lstm_layer2=LSTM(n_neurons,input_shape=(train_X.shape[1],n_neurons),\n",
    "                         dropout=drop_rate, \n",
    "                         recurrent_dropout=drop_rate,\n",
    "                         return_sequences=False)(lstm_layer1)\n",
    "            dropout_layer=Dropout(drop_rate)(lstm_layer2)\n",
    "\n",
    "            output_layer=Dense(1,activation=\"linear\")(dropout_layer)\n",
    "#            output_layer=Dense(1,activation=\"linear\")(lstm_layer2)\n",
    "         \n",
    "\n",
    "        #ix layerlarda Activation için RELU Output için linear uygun oluyor. Kaynak Siraj Raval\n",
    "        \n",
    "            model=Model(inputs=input_layer, outputs=output_layer)\n",
    "        \n",
    "        \n",
    "        #decay_rate = learning_rate / n_epochs\n",
    "        \n",
    "        decay_rate = 0.8\n",
    "        momentum = 0.9\n",
    "         \n",
    "        sgd = optimizers.SGD(lr=learning_rate, clipvalue=0.3,momentum=momentum, decay=decay_rate,nesterov=True)\n",
    "        adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\n",
    "\n",
    "        #model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        \n",
    "        \n",
    "#        model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "        model.compile(loss='mean_squared_error', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "#        model=load_model(os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(y.name,n_neurons)))\n",
    "#        model=load_model(os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(y.name,n_neurons)))\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "        save_weights_at=os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(y.name,n_neurons))\n",
    "\n",
    "        save_best=ModelCheckpoint(save_weights_at, monitor='val_loss', verbose=0,\n",
    "                                 save_best_only=True, save_weights_only=False, mode='min',\n",
    "                                 period=1)\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.00001)\n",
    "        early_stop = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "        \n",
    "        history = model.fit(train_X, train_y, epochs=n_epochs, batch_size=bs, \n",
    "\n",
    "                            validation_data=(test_X, test_y), verbose=1, \n",
    "#                            callbacks=[reduce_lr],\n",
    "                           # callbacks=[save_best],\n",
    "\n",
    "                           # callbacks=[early_stop],\n",
    "                            shuffle=False)\n",
    "\n",
    "#        best_model=load_model(os.path.join('Data','train_dataset.hdf5')\n",
    "#        model=load_model(os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(y.name,n_neurons)))\n",
    "\n",
    "        #model=best_model\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # summarize history for loss\n",
    "        plt.gcf().clear()\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        # summarize history for accuracy\n",
    "#        plt.plot(history.history['acc'])\n",
    "#        plt.plot(history.history['val_acc'])\n",
    "#        plt.title('model accuracy')\n",
    "#        plt.ylabel('accuracy')\n",
    "#        plt.xlabel('epoch')\n",
    "#        plt.legend(['train', 'test'], loc='upper left')\n",
    "#        plt.show()\n",
    "\n",
    "\n",
    "#        test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[1]))\n",
    "\n",
    "        test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "        inv_x_test = scaler_x.inverse_transform(test_X_reshaped)\n",
    "        inv_x_test = pd.DataFrame(data=inv_x_test[:,:])\n",
    "\n",
    "        # make a prediction\n",
    "        y_predict_test = model.predict(test_X)\n",
    "        y_predict_train = model.predict(train_X)\n",
    "\n",
    "        # invert scaling for forecast\n",
    "        inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "        inv_y_predict_test = inv_y_predict_test[:,0]\n",
    "        inv_y_predict_train = scaler_y.inverse_transform(y_predict_train)\n",
    "        inv_y_predict_train = inv_y_predict_train[:,0]\n",
    "\n",
    "        # invert scaling for actual\n",
    "        y_test = test_y.reshape((len(test_y), 1))\n",
    "        inv_y_test = scaler_y.inverse_transform(test_y)\n",
    "        inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "        y_train = train_y.reshape((len(train_y), 1))\n",
    "        inv_y_train = scaler_y.inverse_transform(train_y)\n",
    "        inv_y_train = inv_y_train[:,0]\n",
    "\n",
    "        # calculate RMSE for DIFFERENCE\n",
    "        rmse_test = sqrt(mean_squared_error(inv_y_test, inv_y_predict_test))\n",
    "        print('Test RMSE: %.3f' % rmse_test)\n",
    "        R2_test=int(1000*(metrics.r2_score(inv_y_test, inv_y_predict_test)))/1000\n",
    "        print('R2_test: %.3f' % R2_test)\n",
    "\n",
    "        rmse_train = sqrt(mean_squared_error(inv_y_train, inv_y_predict_train))\n",
    "        print('Train RMSE: %.3f' % rmse_train)\n",
    "        R2_train=int(1000*(metrics.r2_score(inv_y_train, inv_y_predict_train)))/1000\n",
    "        print('R2_train: %.3f' % R2_train)\n",
    "\n",
    "        # calculate RMSE for REAL VALUE\n",
    "\n",
    "        real_y_test= inv_x_test.iloc[:,0]+inv_y_test\n",
    "        real_y_predict_test=inv_x_test.iloc[:,0]+inv_y_predict_test\n",
    "        \n",
    "        real_rmse_test = sqrt(mean_squared_error(real_y_test, real_y_predict_test))\n",
    "        print('Test RMSE: %.3f' % real_rmse_test)\n",
    "        real_R2_test=int(1000*(metrics.r2_score(real_y_test, real_y_predict_test)))/1000\n",
    "        print('R2_test: %.3f' % real_R2_test)\n",
    "        \n",
    "        error_rmse.append(real_rmse_test)\n",
    "        error_r2hat.append(real_R2_test)\n",
    "        error_r2.append(R2_test)\n",
    "        \n",
    "        \n",
    "        plt.gcf().clear()\n",
    "        plt.figure(figsize=(5.5, 5.5))\n",
    "        plt.plot(range(len(inv_y_test)), inv_y_test, linestyle='-', marker='*', color='r')\n",
    "        plt.plot(range(len(inv_y_predict_test)), inv_y_predict_test, linestyle='-', marker='.', color='b')\n",
    "        plt.legend(['Actual','Predicted'], loc=2)\n",
    "        plt.title('Actual vs Predicted for {}'.format(y.name))\n",
    "        plt.ylabel('Trade Value')\n",
    "        plt.xlabel('Index')\n",
    "        plt.savefig('LSTM-LinePlt{} ,{} epochs,{} neurons,{} learning_rate,{} batch size, {} random, {} R2.png'.format(y.name,\n",
    "                                n_epochs,n_neurons,learning_rate,bs,rs,R2_test), format='png', dpi=300)\n",
    "       \n",
    "\n",
    "        \n",
    "        \n",
    "    return error_rmse,error_r2,error_r2hat,train_y,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Learning_Prediction/Plots_for_LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rs=29\n",
    "rs=42\n",
    "repeats = 1\n",
    "drop_rate=0.0\n",
    "do_batch='TRUE'\n",
    "do_model='B'\n",
    "random_split='TRUE'\n",
    "\n",
    "e=5\n",
    "n=300\n",
    "lr=0.01\n",
    "b=1\n",
    "\n",
    "# Set X train, X test, y train, y test\n",
    "rs=42\n",
    "Scaled_Train_Test_Split=X_Y_scaler_train_test_Split(X,y,Z,random=rs)\n",
    "\n",
    "X_train = Scaled_Train_Test_Split[0].values\n",
    "X_test = Scaled_Train_Test_Split[1].values\n",
    "y_train = Scaled_Train_Test_Split[2].values\n",
    "y_test = Scaled_Train_Test_Split[3].values\n",
    "scaler_X = Scaled_Train_Test_Split[4]  \n",
    "scaler_y = Scaled_Train_Test_Split[5]\n",
    "scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "scaled_value_y=Scaled_Train_Test_Split[7]\n",
    "\n",
    "\n",
    "deney=experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,X_train, X_test, y_train, y_test,scaler_X,scaler_y)\n",
    "\n",
    "error_rmse=deney[0] \n",
    "error_r2=deney[1] \n",
    "error_r2hat=deney[2] \n",
    "train_y=deney[3]\n",
    "history=deney[4]\n",
    "print(error_r2)\n",
    "print(error_r2hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rs=29\n",
    "rs=42\n",
    "repeats = 1\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "e=200\n",
    "n=400\n",
    "lr=0.001\n",
    "b=30\n",
    "\n",
    "train_X=SplitData[0] \n",
    "test_X=SplitData[1] \n",
    "train_y=SplitData[2] \n",
    "test_y=SplitData[3]\n",
    "scaler_x=SplitData[4]\n",
    "scaler_y=SplitData[5]\n",
    "\n",
    "deney=experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)\n",
    "\n",
    "error_rmse=deney[0] \n",
    "error_r2=deney[1] \n",
    "error_r2hat=deney[2] \n",
    "train_y=deney[3]\n",
    "history=deney[4]\n",
    "print(error_r2)\n",
    "print(error_r2hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#X2 ve X3 için denemelerde kullanılan parametreler\n",
    "estimator_options = [100,1000,2000,5000]\n",
    "min_sample_leaf_options = [1,2,5,20,30]\n",
    "#random_state_options =[10]\n",
    "max_features_options=[10,\"log2\",\"sqrt\",\"auto\"]\n",
    "max_leaf_nodes_options=[2,5,10,50,100] \n",
    "min_weight_fraction_leaf_options=[0.0001,0.001,0.01,0.1] \n",
    "min_impurity_decrease_options =[0.0000001,0.000001,0.001,0.01]\n",
    "\n",
    "est=estimator_options[2]\n",
    "min_leaf=min_sample_leaf_options[0]\n",
    "feat=max_features_options[0]\n",
    "max_leaf=max_leaf_nodes_options[1]\n",
    "min_weight=min_weight_fraction_leaf_options[0]\n",
    "min_impurity=min_impurity_decrease_options[3]\n",
    "\n",
    "Start Set\n",
    "est=2000\n",
    "min_leaf=1\n",
    "feat=max_10\n",
    "max_leaf=5\n",
    "min_weight=0.0001\n",
    "min_impurity=0.001\n",
    "\n",
    "RS =42Ye gore bulunan Tuning sonucları:\n",
    "841840 için:\n",
    "est=5000\n",
    "min_leaf=1\n",
    "feat=\"log2\"\n",
    "max_leaf=10\n",
    "min_weight=0.001\n",
    "min_impurity=0.0000001\n",
    "\n",
    "841850 için:\n",
    "est=2000\n",
    "min_leaf=20\n",
    "feat=10\n",
    "max_leaf=50\n",
    "min_weight=0.1\n",
    "min_impurity=0.01\n",
    "\n",
    "841810 icin\n",
    "est=10000\n",
    "min_leaf=2\n",
    "feat=\"sqrt\"\n",
    "max_leaf=150\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "GENEL RS farklı oldugundaki Tuning sonucları\n",
    "841850 için:\n",
    "\n",
    "\n",
    "841840 için\n",
    "est=10000\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "\n",
    "\n",
    "NN 841850 için: ve RS=42 Splite göre yaıplan Tuning\n",
    "\n",
    "alph= 1e-12\n",
    "max_iteration= 50000\n",
    "slv= \"adam\"\n",
    "hidden_layer= (30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rs=42\n",
    "repeats = 3\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "results = DataFrame()\n",
    "\n",
    "\n",
    "estimator_options = [100,200,500,1000,5000,10000,20000]\n",
    "min_sample_leaf_options = [1,2,5,20,30]\n",
    "#random_state_options =[10]\n",
    "max_features_options=[10,\"log2\",\"sqrt\",\"auto\"]\n",
    "max_leaf_nodes_options=[2,5,10,100,200,300] \n",
    "min_weight_fraction_leaf_options=[0.00001,0.0001,0.001,0.01,0.1] \n",
    "min_impurity_decrease_options =[0.0000001,0.000001,0.001,0.01,0.05]\n",
    "\n",
    "param='TRUE'\n",
    "est=estimator_options[2]\n",
    "min_leaf=min_sample_leaf_options[0]\n",
    "feat=max_features_options[2]\n",
    "max_leaf=max_leaf_nodes_options[3]\n",
    "min_weight=min_weight_fraction_leaf_options[1]\n",
    "min_impurity=min_impurity_decrease_options[3]\n",
    "\n",
    "\n",
    "est=200\n",
    "min_leaf=2\n",
    "feat=\"log2\"\n",
    "max_leaf=5\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "print(\"parameter usage\", param)\n",
    "print(\"est=\", est)\n",
    "print(\"min_sample_leaf=\", min_leaf)\n",
    "print(\"max_features=\",feat)\n",
    "print(\"max_leaf_nodes=\", max_leaf)\n",
    "print(\"min_weight_fraction_leaf=\", min_weight)\n",
    "print(\"min_impurity_decrease=\", min_impurity)\n",
    "\n",
    "results=experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "print(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "\n",
    "for r in range (0,100):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for min_leaf in min_sample_leaf_options:\n",
    "            results_exp[str(min_leaf)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "\n",
    "\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_sample_leaf_options,rs,feat,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(y.name,MonthSeries,est,min_sample_leaf_options,feat,max_leaf,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"log2\"\n",
    "max_leaf=5\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "for r in range (0,20):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "        \n",
    "        for feat in max_features_options:\n",
    "            results_exp[str(feat)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        \n",
    "        \n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=5\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "print(\"est=\", est)\n",
    "print(\"min_sample_leaf=\", min_leaf)\n",
    "print(\"max_features=\",feat)\n",
    "print(\"max_leaf_nodes=\", max_leaf)\n",
    "print(\"min_weight_fraction_leaf=\", min_weight)\n",
    "print(\"min_impurity_decrease=\", min_impurity)\n",
    "\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "\n",
    "for r in range (0,30):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for max_leaf in max_leaf_nodes_options:\n",
    "            results_exp[str(max_leaf)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        \n",
    "        results=pd.concat([results,results_exp])\n",
    "            \n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,feat,max_leaf_nodes_options,min_weight,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,feat,max_leaf_nodes_options,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "\n",
    "print(\"est=\", est)\n",
    "print(\"min_sample_leaf=\", min_leaf)\n",
    "print(\"max_features=\",feat)\n",
    "print(\"max_leaf_nodes=\", max_leaf)\n",
    "print(\"min_weight_fraction_leaf=\", min_weight)\n",
    "print(\"min_impurity_decrease=\", min_impurity)\n",
    "\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "        for min_weight in min_weight_fraction_leaf_options:\n",
    "            results_exp[str(min_weight)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        \n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,feat,max_leaf,min_weight_fraction_leaf_options,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for{}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weig,{}min_imp.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,feat,max_leaf,min_weight_fraction_leaf_options,min_impurity))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.000001\n",
    "print(\"est=\", est)\n",
    "print(\"min_sample_leaf=\", min_leaf)\n",
    "print(\"max_features=\",feat)\n",
    "print(\"max_leaf_nodes=\", max_leaf)\n",
    "print(\"min_weight_fraction_leaf=\", min_weight)\n",
    "print(\"min_impurity_decrease=\", min_impurity)\n",
    "\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "\n",
    "        for min_impurity in min_impurity_decrease_options:\n",
    "            results_exp[str(min_impurity)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,feat,max_leaf,min_weight,min_impurity_decrease_options))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weig,{}min_impu.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,feat,max_leaf,min_weight,min_impurity_decrease_options))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator_options = [100,200,500,1000,5000,10000]\n",
    "\n",
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "\n",
    "        for est in estimator_options:\n",
    "            results_exp[str(est)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  estimator_options, min_leaf,rs,feat,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-BoxP for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} minweig,{}minimp.png'\n",
    "               .format(y.name,MonthSeries,estimator_options,min_leaf,feat,max_leaf,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM ICIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "\n",
    "repeats = 1\n",
    "\n",
    "# vary training epochs\"\n",
    "epochs = [50, 500, 1000,2000]\n",
    "neurons = [5, 50,100]\n",
    "learning_rates= [0.001, 0.01, 0.05, 0.1]\n",
    "batch_sizes=[5, 12, 24,50,100]\n",
    "\n",
    "\n",
    "e=3000\n",
    "n=200\n",
    "lr=0.02\n",
    "b=50\n",
    "\n",
    "\n",
    "e=500\n",
    "n=100\n",
    "lr=0.05\n",
    "b=50\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "\n",
    "        for e in epochs:\n",
    "            results_exp[str(e)] = experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "\n",
    "results.boxplot()\n",
    "plt.title(\"LSTM-Box Plot for {}-{}, {} epochs,{} neurons,{} learning_rate, {}batch size \"\n",
    "          .format(y.name,MonthSeries,epochs,n,lr,b))\n",
    "plt.savefig('Data/LSTM-Box Plot for {}-{}, {} epochs,{} neurons {}lr,{}b.png'\n",
    "               .format(y.name,MonthSeries,epochs,n,lr,b))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "\n",
    "repeats = 1\n",
    "e=500\n",
    "n=100\n",
    "lr=0.001\n",
    "b=50\n",
    "deney=experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)\n",
    "deney[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#repeats=10\n",
    "e=2000\n",
    "n=100\n",
    "lr=0.05\n",
    "b=50\n",
    "\n",
    "neurons = [5, 50, 100]\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for n in neurons:\n",
    "            results_exp[str(n)] = experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"LSTM-Box Plot for {}-{}, {} epochs,{} neurons,{} learning_rate {}batch size\"\n",
    "          .format(y.name,MonthSeries,e,neurons,lr,b))\n",
    "plt.savefig('Data/LSTM-Box Plot for {}-{}, {} epochs,{} neurons{},lr{}, b.png'\n",
    "               .format(y.name,MonthSeries,e,neurons,lr,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "repeats = 10\n",
    "e=100\n",
    "n=50\n",
    "lr=0.05\n",
    "b=50\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for b in batch_sizes:\n",
    "            results_exp[str(b)] = experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"LSTM-Box Plot for {}-{}, {} epochs,{} neurons,{} learning_rate {}batch size \"\n",
    "          .format(y.name,MonthSeries,e,n,lr,batch_sizes))\n",
    "plt.savefig('Data/LSTM-Box Plot for {}-{}, {} epochs,{} neurons{}lr,{}bsize.png'\n",
    "               .format(y.name,MonthSeries,e,n,lr,batch_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "LSTM SONU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN BASLANGICI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuralNetwork(X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=50,is_random_fixed='TRUE',\n",
    "                  alph=0.0001, slv='adam', max_iteration=200,  hidden_layer=(30,30)):\n",
    "    \n",
    "    \n",
    "    if is_random_fixed == 'TRUE': \n",
    "        rs=rand\n",
    "    else :\n",
    "        rs=random.randint(1,100)\n",
    "    print('neuralnetwork rs=',rs)   \n",
    "\n",
    "    MLP = MLPRegressor(\n",
    "                            random_state =rs,                      \n",
    "                            alpha = alph,\n",
    "                            solver=slv ,\n",
    "                            max_iter=max_iteration,  \n",
    "                            hidden_layer_sizes=hidden_layer\n",
    "                        )\n",
    "\n",
    "\n",
    "    MLPRegressor.fit(MLP,X_train,y_train)\n",
    "    \n",
    "    y_predict_test = MLP.predict(X_test)\n",
    "    y_predict_train = MLP.predict(X_train)\n",
    "    \n",
    "    result_test=exp.inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'NO')\n",
    "    result_train=exp.inverse_scale_and_graph_Y_predict_and_test(y_predict_train,y_train,scaler_y,'NO')\n",
    "    \n",
    "    return result_test, result_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def experiment_NN(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=50,is_random_fixed='TRUE',\n",
    "                  alph=0.0001, max_iteration=200, slv='adam',  hidden_layer=(30,30)):\n",
    "\n",
    "\n",
    "    error_rmse = list()\n",
    "    error_R2 = list()\n",
    "    \n",
    "    for r in range(repeats):\n",
    "            \n",
    "        result = NeuralNetwork(X_train, X_test, y_train, y_test,scaler_y,\n",
    "                               rand=rand,is_random_fixed=is_random_fixed,\n",
    "                               alph=alph,max_iteration=max_iteration, slv=slv, hidden_layer=hidden_layer)\n",
    "        \n",
    "        \n",
    "        rmse_test=result[0][1]\n",
    "        R2_test=result[0][2]\n",
    "        \n",
    "        rmse_train=result[1][0]\n",
    "        R2_train=result[1][1]\n",
    "        \n",
    "        error_rmse.append(rmse_test)\n",
    "        error_R2.append(R2_test)\n",
    "    \n",
    "    return error_rmse, error_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuralnetwork rs= 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2601, 2990, 0.624), (2442, 3053, 0.477))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeuralNetwork(X_train, X_test, y_train, y_test,scaler_y,alph=0.0000001,max_iteration=20, slv='sgd')          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuralnetwork rs= 50\n",
      "neuralnetwork rs= 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2990, 2990], [0.624, 0.624])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_NN(2,X_train, X_test, y_train, y_test,scaler_y, alph=0.0000001,max_iteration=20, slv='sgd')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split rs= 55\n",
      "neuralnetwork rs= 20\n",
      "neuralnetwork rs= 50\n",
      "neuralnetwork rs= 23\n",
      "neuralnetwork rs= 26\n",
      "neuralnetwork rs= 77\n",
      "neuralnetwork rs= 32\n",
      "Size: 6\n",
      "          lbfgs      adam\n",
      "count  3.000000  3.000000\n",
      "mean   0.782333  0.420333\n",
      "std    0.012014  0.335774\n",
      "min    0.770000  0.077000\n",
      "25%    0.776500  0.256500\n",
      "50%    0.783000  0.436000\n",
      "75%    0.788500  0.592000\n",
      "max    0.794000  0.748000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA50AAAEICAYAAADcGJCTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1BMfiKJT+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c84a2da7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MAIN for Neural Network Experiments\n",
    "repeats=3\n",
    "random_range_for_split=1\n",
    "rs=random.randint(1,100)\n",
    "#rs=12\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "alpha_options = [0.0001,0.00000001]\n",
    "solver_options = ['lbfgs', 'adam' ] # sgd solver cok sapıttı\n",
    "max_iteration_options = [50000]#,60000,100000]\n",
    "hidden_layer_sizes_options=[(30,100,10),(30,30),(100,100),(30,30,30)]\n",
    "\n",
    "\n",
    "alph=0.0001 \n",
    "slv='adam' \n",
    "max_iteration=200  \n",
    "hidden_layer=(30,30)\n",
    "\n",
    "\n",
    "param='TRUE'\n",
    "\n",
    "for r in range (random_range_for_split):\n",
    "\n",
    "\n",
    "    rs=random.randint(1,100)\n",
    "\n",
    "    print('split rs=',rs)\n",
    "    \n",
    "    Scaled_Train_Test_Split=exp.X_Y_scaler_train_test_Split(X,y,Z,random=rs)\n",
    "\n",
    "    X_train = Scaled_Train_Test_Split[0]\n",
    "    X_test = Scaled_Train_Test_Split[1]\n",
    "    y_train = Scaled_Train_Test_Split[2]\n",
    "    y_test = Scaled_Train_Test_Split[3]\n",
    "    scaler_X = Scaled_Train_Test_Split[4]  \n",
    "    scaler_y = Scaled_Train_Test_Split[5]\n",
    "    scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "    scaled_value_y=Scaled_Train_Test_Split[7]\n",
    "    \n",
    "    \n",
    "    for slv in solver_options:\n",
    "        results_exp[str(slv)] =experiment_NN(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=20,is_random_fixed='FALSE',\n",
    "                  alph=alph,max_iteration=max_iteration, slv=slv, hidden_layer=hidden_layer)[1] \n",
    "    \n",
    "    results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "param='TRUE'\n",
    "random_split='TRUE'\n",
    "alpha_options = [0.0001,0.00000001,0.0000000001, 0.000000000001]\n",
    "solver_options = ['lbfgs', 'adam' ] # sgd solver cok sapıttı\n",
    "max_iteration_options = [50000,60000,100000]\n",
    "#random_state_options =[1,10,50,75,200]\n",
    "#random_state_options =[10,50,90]\n",
    "random_state_options =[90]\n",
    "hidden_layer_sizes_options=[(30,100,10),(30,30),(100,100),(30,30,30)]\n",
    "\n",
    "alph=alpha_options[0]\n",
    "max_iteration=max_iteration_options[0]\n",
    "slv=solver_options[1]\n",
    "rseed=random_state_options[0]\n",
    "hidden_layer=hidden_layer_sizes_options[0]\n",
    "\n",
    "\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        rs=42\n",
    "        \n",
    "        \n",
    "        rs=42\n",
    "        Scaled_Train_Test_Split=X_Y_scaler_train_test_Split(X,y,Z,random=rs)\n",
    "\n",
    "        train_X = Scaled_Train_Test_Split[0].values\n",
    "        test_X = Scaled_Train_Test_Split[1].values\n",
    "        train_y = Scaled_Train_Test_Split[2].values\n",
    "        test_y = Scaled_Train_Test_Split[3].values\n",
    "        scaler_X = Scaled_Train_Test_Split[4]  \n",
    "        scaler_y = Scaled_Train_Test_Split[5]\n",
    "        scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "        scaled_value_y=Scaled_Train_Test_Split[7]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for alph in alpha_options:\n",
    "            rseed=90\n",
    "            results_exp[str(alph)] = experiment_NN(repeats,param,alph,max_iteration,slv,rseed,hidden_layer,train_X, test_X, train_y, test_y,scaler_y)[1]\n",
    "            \n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer \"\n",
    "          .format(y.name,MonthSeries,alpha_options,max_iteration,slv,hidden_layer))\n",
    "plt.savefig(\"Data/18Mayıs/NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer.png \"\n",
    "          .format(y.name,MonthSeries,alpha_options,max_iteration,slv,hidden_layer), format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "\n",
    "alph=alpha_options[3]\n",
    "max_iteration=max_iteration_options[0]\n",
    "slv=solver_options[1]\n",
    "rseed=random_state_options[0]\n",
    "hidden_layer=hidden_layer_sizes_options[1]\n",
    "\n",
    "\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        rs=42\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for max_iteration in max_iteration_options:\n",
    "            \n",
    "            results_exp[str(max_iteration)] = experiment_NN(repeats,param,alph,max_iteration,slv,rseed,hidden_layer,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "            \n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration_options,slv,hidden_layer))\n",
    "plt.savefig(\"Data/18Mayıs/NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer.png \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration_options,slv,hidden_layer), format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "\n",
    "alph=alpha_options[3]\n",
    "max_iteration=max_iteration_options[0]\n",
    "slv=solver_options[1]\n",
    "rseed=random_state_options[0]\n",
    "hidden_layer=hidden_layer_sizes_options[1]\n",
    "\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        rs=42\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for slv in solver_options:\n",
    "            \n",
    "            results_exp[str(slv)] = experiment_NN(repeats,param,alph,max_iteration,slv,rseed,hidden_layer,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "            \n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration,solver_options,hidden_layer))\n",
    "plt.savefig(\"Data/18Mayıs/NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer.png \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration,solver_options,hidden_layer), format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "\n",
    "alph=alpha_options[3]\n",
    "max_iteration=max_iteration_options[0]\n",
    "slv=solver_options[1]\n",
    "rseed=random_state_options[0]\n",
    "hidden_layer=hidden_layer_sizes_options[1]\n",
    "\n",
    "print('alph=',alph)\n",
    "print('max_iteration=',max_iteration)\n",
    "print('slv=',slv)\n",
    "print('hidden_layer=',hidden_layer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        rs=42\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for hidden_layer in hidden_layer_sizes_options:\n",
    "            \n",
    "            results_exp[str(hidden_layer)] = experiment_NN(repeats,param,alph,max_iteration,slv,rseed,hidden_layer,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "            \n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration,slv,hidden_layer_sizes_options))\n",
    "plt.savefig(\"Data/18Mayıs/NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer.png \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration,slv,hidden_layer_sizes_options), format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN SONU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
