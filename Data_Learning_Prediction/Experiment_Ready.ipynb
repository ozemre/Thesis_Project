{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Sources_and_Preparation')\n",
    "#os.chdir('C:/Users/murat.ozemre/Documents/MOZEMRE-OZEL/Doktora/2017 Tez/Veri Analizi/Ver 3 Tez Izleme Calısmaları')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statsmodels: 0.8.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import statsmodels\n",
    "print('statsmodels: %s' % statsmodels.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12-27 13:40'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from math import log\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scaler_Type_Options = ['Normalizer', 'MinMaxScaler','MaxAbsScaler','RobustScaler','StandardScaler' ]\n",
    "Scaler_Type_Options = [ 'MinMaxScaler' ]\n",
    "Scalertype=Scaler_Type_Options[0]\n",
    "Product_Type_Options = [841810,841840,841850]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MinMaxScaler'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scalertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Product=Product_Type_Options[0] #841810\n",
    "Exp_Country='TUR' # 'CHN'\n",
    "Imp_Country='GBR'\n",
    "\n",
    "if Exp_Country=='CHN':\n",
    "    Currency='CNY'\n",
    "    EXP0='TUR'   \n",
    "elif Exp_Country=='TUR':\n",
    "    Currency='TRY'\n",
    "    EXP0='CHN'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841810"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MonthSeries=\"3\"\n",
    "MonthSeries_option=[\"1\",\"2\",\"3\",\"6\",\"12\"]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Core1 = pd.ExcelFile('Data_{}_{}_{}.xlsx'.format(Exp_Country,Imp_Country,Product))\n",
    "y = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])['{}_{}_{}'.format(Exp_Country,Imp_Country,Product)]\n",
    "Z = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])[['Date','Year','Month']]\n",
    "\n",
    "X = Data_Core1.parse('X{}'.format(MonthSeries), header=0,index_col=None, na_values=['NA'])\n",
    "X.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "X_Column_Names=list(X.columns.values)\n",
    "n_feature=X.shape[1]\n",
    "\n",
    "Xhat = Data_Core1.parse('Xhat', header=0,index_col=None, na_values=['NA'])\n",
    "Xhat.drop(['Date','Year','Month'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Xscaler(X,y,scalertype):\n",
    "\n",
    "    if scalertype==\"Normalizer\":\n",
    "        X=pd.DataFrame(Normalizer().fit_transform(X,y))\n",
    "        print(\"normalize\")\n",
    "    elif scalertype==\"MinMaxScaler\":\n",
    "        X=pd.DataFrame(MinMaxScaler().fit_transform(X,y))\n",
    "        print(\"minmax\")\n",
    "    elif scalertype==\"MaxAbsScaler\":\n",
    "        X=pd.DataFrame(MaxAbsScaler().fit_transform(X,y))\n",
    "        print(\"maxabs\")\n",
    "    elif scalertype==\"RobustScaler\":\n",
    "        X=pd.DataFrame(RobustScaler().fit_transform(X,y))\n",
    "    elif scalertype==\"StandardScaler\":\n",
    "        X=pd.DataFrame(StandardScaler().fit_transform(X,y))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling Min Max and then spilt test and train according stratify to month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def X_Y_scaler_train_test_Split(X,y,Z,random=42):\n",
    "\n",
    "    values = X.values\n",
    "    values = values.astype('float32')\n",
    "    X_Column_X_Column_Names=X.columns\n",
    "    \n",
    "    scaler_X= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_X = scaler_X.fit_transform(values)\n",
    "    scaled_value_X = pd.DataFrame(data=scaled_value_X[:,:])\n",
    "    scaled_value_X.columns=X_Column_X_Column_Names\n",
    "    \n",
    "    values = y.values\n",
    "    values = values.astype('float32')\n",
    "    values = values.reshape(-1, 1)\n",
    "    \n",
    "    scaler_y= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_y = scaler_y.fit_transform(values)\n",
    "    scaled_value_y = pd.DataFrame(data=scaled_value_y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_value_X,scaled_value_y,test_size=0.2,random_state=42,stratify=Z['Month'])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler_X, scaler_y, scaled_value_X, scaled_value_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,plot_on):\n",
    "\n",
    "    y_predict_test=y_predict_test.reshape(-1, 1)\n",
    "    inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "    predictions=inv_y_predict_test\n",
    "\n",
    "  \n",
    "    inv_y_test = scaler_y.inverse_transform(y_test)\n",
    "    inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "    MAE=int(metrics.mean_absolute_error(inv_y_test, predictions))\n",
    "    MSE=int(sqrt(metrics.mean_squared_error(inv_y_test, predictions)))\n",
    "    R2=int(1000*(metrics.r2_score(inv_y_test, predictions)))/1000\n",
    "    \n",
    "    \n",
    "    print('MAE',MAE, 'MSE',MSE, 'R2',R2 )\n",
    "    \n",
    "    if plot_on =='YES':\n",
    "        plt.scatter(inv_y_test,predictions)\n",
    "    \n",
    "    return MAE,MSE,R2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.216"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3,4,5]\n",
    "b=[2,2,2,2,2]\n",
    "\n",
    "a=np.log(a)\n",
    "b=np.log(b)\n",
    "R2=int(1000*(metrics.r2_score(a , b )))/1000\n",
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Scaled_Train_Test_Split=X_Y_scaler_train_test_Split(X,y,Z)\n",
    "\n",
    "X_train = Scaled_Train_Test_Split[0]\n",
    "X_test = Scaled_Train_Test_Split[1]\n",
    "y_train = Scaled_Train_Test_Split[2]\n",
    "y_test = Scaled_Train_Test_Split[3]\n",
    "scaler_X = Scaled_Train_Test_Split[4]  \n",
    "scaler_y = Scaled_Train_Test_Split[5]\n",
    "scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "scaled_value_y=Scaled_Train_Test_Split[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For Random Forest with variable tuning \n",
    "\n",
    "def randomforest(X_train, X_test, y_train, y_test,scaler_y,est=10,min_leaf=1,random=50,feat='auto',max_leaf=None,min_weight=0.0,min_impurity=1e-07):\n",
    "    from sklearn.model_selection import cross_val_score   \n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    \n",
    "    rfc=RandomForestRegressor(n_estimators=est,\n",
    "                              min_samples_leaf=min_leaf,\n",
    "                              random_state =random,\n",
    "                              max_features=feat,\n",
    "                              max_leaf_nodes=max_leaf,\n",
    "                              min_weight_fraction_leaf =min_weight,\n",
    "                              min_impurity_decrease=min_impurity\n",
    "                            )\n",
    "   \n",
    "    RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "\n",
    "    y_predict_test = rfc.predict(X_test)\n",
    "    y_predict_train = rfc.predict(X_train)\n",
    "    \n",
    "    result_test=inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'NO')\n",
    "    result_train=inverse_scale_and_graph_Y_predict_and_test(y_predict_train,y_train,scaler_y,'NO')\n",
    "    \n",
    "    return result_test, result_train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 2569 MSE 3522 R2 0.444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2569, 3522, 0.444)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cbc0c359b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Decison tree regressor model\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# Decison tree regressor model train\n",
    "DecisionTreeRegressor.fit(dt,X_train,y_train)\n",
    "\n",
    "# Decison tree regressor model predict\n",
    "y_predict_test = dt.predict(X_test)\n",
    "\n",
    "# Compare predicted Y and real Y \n",
    "inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'YES')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Foest Regressor model\n",
    "rfc=RandomForestRegressor(n_estimators=3000)\n",
    "\n",
    "# Random Foest Regressor model train\n",
    "RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "\n",
    "# Random Foest Regressor mode predict\n",
    "y_predict_test = rfc.predict(X_test)\n",
    "\n",
    "# Compare predicted Y and real Y \n",
    "inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1 Version for Feature selection\n",
    "# Internetten bulunan kod blogu\n",
    "# Random Forest'a gore Feature Importance Hesaplama\n",
    "# Butun veri setinin girildiği ona göre önemli olan özelliklerin bulundugu kod parçası\n",
    "\n",
    "ScalerType = Scalertype=Scaler_Type_Options[0]\n",
    "n_sample=len(X)\n",
    "\n",
    "rfc=RandomForestRegressor(n_estimators=3000)\n",
    "RandomForestRegressor.fit(rfc,scaled_value_X,scaled_value_y)\n",
    "\n",
    "\n",
    "predictions = rfc.predict(X_test)\n",
    "print('MAE',int(metrics.mean_absolute_error(y_test, predictions)),\n",
    "      'MSE',int(sqrt(metrics.mean_squared_error(y_test, predictions))),\n",
    "      'R2',int(1000*(metrics.r2_score(y_test, predictions)))/1000\n",
    "     )\n",
    "\n",
    "\n",
    "importances = rfc.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rfc.estimators_],axis=0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(n_feature):\n",
    "    print(\"%d. feature %s %d (%f) %f\" % (f+1, X_Column_Names[indices[f]], indices[f], importances[indices[f]],std[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"{} and -{} Month Feature Importances and Standart Deviation of Features with 3000 Different Estimations\".format(Product,MonthSeries))\n",
    "plt.bar(range(n_feature), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(n_feature), indices,rotation=90)\n",
    "plt.xlim([-1, n_feature])\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 15\n",
    "fig_size[1] = 10\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.savefig(\"Plots_Feature_Selection/{} and -{} Month Feature Importances and Standart Deviation of Features with 3000 Different Estimations.png\".format(Product,MonthSeries), format='png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  2 Version for Feature selection \n",
    "# Internetten bulunan kod blogu http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "# Feature Importance Hesaplama\n",
    "# Burada asıl özellik bir veri seti yaratılıyor make_regression ile. Ve oaradakilere dogru çalışıp çalışmadığı test ediliyor.\n",
    "# Butun veri setinin girildiği ona göre önemli olan özelliklerin bulundugu kod parçası\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "\n",
    "n_sample=len(X)\n",
    "\n",
    "number_of_split=100\n",
    "number_of_row=29\n",
    "\n",
    "random_state_options = np.arange(0,number_of_split)\n",
    "y_predict= np.ones((number_of_row, number_of_split))\n",
    "\n",
    "feature_indices = np.ones((n_feature, number_of_split))\n",
    "feature_importances=np.ones((n_feature, number_of_split))\n",
    "feature_indices_score=np.ones((n_feature))\n",
    "feature_importances_score=np.ones((n_feature))\n",
    "j=0\n",
    "\n",
    "\n",
    "# For different split sets Random Forest Regressor runs.\n",
    "\n",
    "for random_state_i in random_state_options:\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_value_X,scaled_value_y,test_size=0.2,random_state=random_state_i,stratify=Z['Month'])\n",
    "\n",
    "    \n",
    "\n",
    "    rfc=RandomForestRegressor(n_estimators=30)\n",
    "    RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "\n",
    "    y_predict[:,j] = rfc.predict(X_test)\n",
    "    \n",
    "    result=inverse_scale_and_graph_Y_predict_and_test (y_predict[:,j],y_test,scaler_y,'NO')\n",
    "    \n",
    "    importances = rfc.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in rfc.estimators_],axis=0)\n",
    "\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    feature_indices[:,j]=indices\n",
    "    feature_importances[:,j]=importances\n",
    "    j=j+1\n",
    "    \n",
    "\n",
    "print (\"Features scores:\")    \n",
    "for i in range(n_feature):\n",
    "    feature_indices_score[i]=0\n",
    "    feature_importances_score[i]=0\n",
    "    for j in range(number_of_split):\n",
    "        \n",
    "        indice_coeff=feature_indices[i,j]\n",
    "        importances_coeff=feature_importances[i,j]\n",
    "        \n",
    "        feature_indices_score[i]=feature_indices_score[i]+(indice_coeff)\n",
    "        feature_importances_score[i]=feature_importances_score[i]+(importances_coeff)\n",
    "        \n",
    "#        print('feat=',i,'#ofsplit=',j,'tot_indice',feature_indices_score[i],\n",
    "#              'indice=',indice_coeff,'tot_importan=',feature_importances_score[i],'importan',importances_coeff )\n",
    "\n",
    "    print( i,X_Column_Names[i])#,feature_indices_score[i],'number_of_split',j+1) #,X_Column_Names[feature_indices[i,j]])\n",
    "    \n",
    "scored_feature_indices = np.argsort(feature_indices_score)\n",
    "scored_feature_importances = np.argsort(feature_importances_score)\n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "# Plot the feature importances of the forest\n",
    "plt.gcf().clear()\n",
    "plt.figure()\n",
    "plt.title(\"{} and -{} Month Cumulative Feature Importances with {} Different Splits.png\".format(Product,MonthSeries,number_of_split))\n",
    "plt.bar(range(n_feature), feature_importances_score[scored_feature_importances][::-1],\n",
    "       color=\"r\",  align=\"center\")\n",
    "plt.xticks(range(n_feature), scored_feature_importances[::-1],rotation=90)\n",
    "plt.xlim([-1, n_feature])\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 20\n",
    "fig_size[1] = 12\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.savefig(\"Plots_Feature_Selection/{} and -{} Month Cumulative Feature Importances with {} Different Splits.png\".format(Product,MonthSeries,number_of_split), format='png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3 Version for Train Test Split and Feature selection \n",
    "# http://blog.datadive.net/selecting-good-features-part-iii-random-forests/\n",
    "# Use both RF Importances and R2 Accuracy with different number of splits\n",
    "\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter, attrgetter\n",
    "\n",
    "def getKey(item):\n",
    "    return item[0]\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "\n",
    "number_of_split=100\n",
    "number_of_row=29\n",
    "\n",
    "\n",
    "\n",
    "random_state_options = np.arange(0,number_of_split)\n",
    "predictions= np.ones((number_of_row, number_of_split))\n",
    "y_predict= np.ones((number_of_row, number_of_split))\n",
    "\n",
    "feature_indices = np.ones((n_feature, number_of_split))\n",
    "feature_importances=np.ones((n_feature, number_of_split))\n",
    "feature_indices_score=np.ones((n_feature))\n",
    "feature_importances_score=np.ones((n_feature))\n",
    "\n",
    "scores = defaultdict(list)\n",
    "#feature_indices = \n",
    "feature_std = np.ones((n_feature, number_of_split))\n",
    "feature_score=np.zeros((n_feature))\n",
    "\n",
    "#R2=defaultdict(list)\n",
    "R2=np.ones(number_of_split)\n",
    "j=0\n",
    "\n",
    "sonuc =[]\n",
    "\n",
    "\n",
    "for random_state_i in random_state_options:\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size=0.2,random_state=random_state_i,stratify=Z['Month'])\n",
    "\n",
    "    RandomForestRegressor.fit(rf,X_train, Y_train)    \n",
    "\n",
    "    y_predict[:,j] = rf.predict(X_test)\n",
    "    \n",
    "    acc = int(1000*(r2_score(Y_test, rf.predict(X_test))))/1000\n",
    "    R2[j] = int(1000*(r2_score(Y_test, rf.predict(X_test))))/1000\n",
    "        \n",
    "    importances = rf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    std = np.std([tree.feature_importances_ for tree in rf.estimators_],axis=0)\n",
    "\n",
    "\n",
    "    feature_importances[:,j]=importances\n",
    "    feature_indices[:,j]=indices\n",
    "    feature_std [:,j]=std\n",
    "\n",
    "    j=j+1\n",
    "\n",
    "R2_Adj=1-R2\n",
    "score_coefficient=n_feature*(R2_Adj - np.max(R2_Adj))/-np.ptp(R2_Adj)\n",
    "\n",
    "    \n",
    "print (\"Features scores:\")    \n",
    "for i in range(n_feature):\n",
    "    feature_score[i]=0\n",
    "    feature_indices_score[i]=0\n",
    "    feature_importances_score[i]=0\n",
    "    \n",
    "    for j in range(number_of_split):\n",
    "        \n",
    "        indice_coeff=feature_indices[i,j]+1\n",
    "        importances_coeff=int((feature_importances[i,j]*10000))/10000\n",
    "        score_coeff=int((score_coefficient[j]+1)*10)/10\n",
    "\n",
    "        feature_indices_score[i]=feature_indices_score[i]+(indice_coeff)\n",
    "        feature_importances_score[i]=feature_importances_score[i]+(importances_coeff)\n",
    "\n",
    "        score=score_coeff*(importances_coeff)\n",
    "        feature_score[i]=feature_score[i]+score\n",
    "\n",
    "\n",
    "#    print( feature_score[i],'number_of_split',j+1) #,X_Column_Names[feature_indices[i,j]])\n",
    "    \n",
    "scored_feature_indices = (np.argsort(feature_score)[::-1])\n",
    "\n",
    "for f in range(n_feature):\n",
    "    print(\"%d. feature %s %d (%f) %f\" % (f+1, X_Column_Names[scored_feature_indices[f]], scored_feature_indices[f], importances[scored_feature_indices[f]],std[scored_feature_indices[f]]))\n",
    "\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.gcf().clear()\n",
    "plt.figure()\n",
    "plt.title(\"{} and {} Month Cumulative Feature and Score Importances with {} Different Splits\".format(Product,MonthSeries,number_of_split))\n",
    "plt.bar(range(n_feature), feature_score[scored_feature_indices],\n",
    "       color=\"r\",  align=\"center\")\n",
    "plt.xticks(range(n_feature), scored_feature_indices,rotation=90)\n",
    "plt.xlim([-1, n_feature])\n",
    "\n",
    "#fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "#fig_size[0] = 20\n",
    "#fig_size[1] = 12\n",
    "#plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "plt.savefig(\"Plots_Feature_Selection/{} and {} Month Cumulative Feature and Score Importances with {} Different Splits.png\".format(Product,MonthSeries,number_of_split), format='png', dpi=300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calling function by single parameter set \n",
    "a=randomforest(X_train, X_test, y_train, y_test,scaler_y,200,5,10,10,5,0.1,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# By using Ver 3 for Feature Selection results\n",
    "# Percentile variable takes the most important variables according to its feature score and omits the others.\n",
    "# ie.25 percentile takes %75 importance variables and omits %25 least important features\n",
    "\n",
    "percentile=25\n",
    "threshold_for_feature_selection=np.percentile(feature_score[scored_feature_indices], percentile)\n",
    "X_threshold=X.iloc[:,scored_feature_indices[feature_score[scored_feature_indices]>threshold_for_feature_selection]]\n",
    "\n",
    "# Train Test Split after percentile selection\n",
    "\n",
    "Scaled_Train_Test_Split=X_Y_scaler_train_test_Split(X_threshold,y,Z)\n",
    "\n",
    "X_train = Scaled_Train_Test_Split[0]\n",
    "X_test = Scaled_Train_Test_Split[1]\n",
    "y_train = Scaled_Train_Test_Split[2]\n",
    "y_test = Scaled_Train_Test_Split[3]\n",
    "scaler_X = Scaled_Train_Test_Split[4]  \n",
    "scaler_y = Scaled_Train_Test_Split[5]\n",
    "scaled_value_X=Scaled_Train_Test_Split[6]\n",
    "scaled_value_y=Scaled_Train_Test_Split[7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Foest Regressor model\n",
    "rfc=RandomForestRegressor(n_estimators=3000,random_state=50)\n",
    "\n",
    "# Random Foest Regressor model train\n",
    "RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "\n",
    "# Random Foest Regressor mode predict\n",
    "y_predict_test = rfc.predict(X_test)\n",
    "\n",
    "# Compare predicted Y and real Y \n",
    "inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest(X_train, X_test, y_train, y_test,scaler_y,est=3000,random=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
