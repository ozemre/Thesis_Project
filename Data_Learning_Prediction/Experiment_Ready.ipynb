{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murat.ozemre\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'01-08 14:30'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import statsmodels\n",
    "from math import sqrt\n",
    "from math import log\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from datetime import datetime\n",
    "\n",
    "import random\n",
    "from random import gauss\n",
    "from random import seed\n",
    "datetime.now().strftime('%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Xscaler(X,y,scalertype):\n",
    "\n",
    "    if scalertype==\"Normalizer\":\n",
    "        X=pd.DataFrame(Normalizer().fit_transform(X,y))\n",
    "        print(\"normalize\")\n",
    "    elif scalertype==\"MinMaxScaler\":\n",
    "        X=pd.DataFrame(MinMaxScaler().fit_transform(X,y))\n",
    "        print(\"minmax\")\n",
    "    elif scalertype==\"MaxAbsScaler\":\n",
    "        X=pd.DataFrame(MaxAbsScaler().fit_transform(X,y))\n",
    "        print(\"maxabs\")\n",
    "    elif scalertype==\"RobustScaler\":\n",
    "        X=pd.DataFrame(RobustScaler().fit_transform(X,y))\n",
    "    elif scalertype==\"StandardScaler\":\n",
    "        X=pd.DataFrame(StandardScaler().fit_transform(X,y))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def X_Y_scaler_train_test_Split(X,y,Z,random=42):\n",
    "\n",
    "    values = X.values\n",
    "    values = values.astype('float32')\n",
    "    X_Column_X_Column_Names=X.columns\n",
    "    \n",
    "    scaler_X= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_X = scaler_X.fit_transform(values)\n",
    "    scaled_value_X = pd.DataFrame(data=scaled_value_X[:,:])\n",
    "    scaled_value_X.columns=X_Column_X_Column_Names\n",
    "    \n",
    "    values = y.values\n",
    "    values = values.astype('float32')\n",
    "    values = values.reshape(-1, 1)\n",
    "    \n",
    "    scaler_y= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_y = scaler_y.fit_transform(values)\n",
    "    scaled_value_y = pd.DataFrame(data=scaled_value_y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_value_X,scaled_value_y,test_size=0.2,random_state=42,stratify=Z['Month'])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler_X, scaler_y, scaled_value_X, scaled_value_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For Random Forest with variable tuning \n",
    "\n",
    "def randomforest(X_train, X_test, y_train, y_test,scaler_y,rand=50,is_random_fixed='TRUE',est=10,min_leaf=1,feat='auto',max_leaf=None,min_weight=0.0,min_impurity=1e-07):\n",
    "    from sklearn.model_selection import cross_val_score   \n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    \n",
    "    if is_random_fixed == 'TRUE': \n",
    "        rs=rand\n",
    "    else :\n",
    "        rs=random.randint(1,100)\n",
    "    print('randomforest rs=',rs)\n",
    "    rfc=RandomForestRegressor(n_estimators=est,\n",
    "                              min_samples_leaf=min_leaf,\n",
    "                              random_state =rs,\n",
    "                              max_features=feat,\n",
    "                              max_leaf_nodes=max_leaf,\n",
    "                              min_weight_fraction_leaf =min_weight,\n",
    "                              min_impurity_decrease=min_impurity\n",
    "                            )\n",
    "   \n",
    "    RandomForestRegressor.fit(rfc,X_train,y_train)\n",
    "    \n",
    "    y_predict_test = rfc.predict(X_test)\n",
    "    y_predict_train = rfc.predict(X_train)\n",
    "    \n",
    "    result_test=inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'NO')\n",
    "    result_train=inverse_scale_and_graph_Y_predict_and_test(y_predict_train,y_train,scaler_y,'NO')\n",
    "    \n",
    "    return result_test, result_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,plot_on):\n",
    "\n",
    "    y_predict_test=y_predict_test.reshape(-1, 1)\n",
    "    inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "    predictions=inv_y_predict_test\n",
    "\n",
    "  \n",
    "    inv_y_test = scaler_y.inverse_transform(y_test)\n",
    "    inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "    MAE=int(metrics.mean_absolute_error(inv_y_test, predictions))\n",
    "    MSE=int(sqrt(metrics.mean_squared_error(inv_y_test, predictions)))\n",
    "    flatten=predictions.flatten()\n",
    "    R2=int(1000*pearsonr(inv_y_test,flatten )[0]**2)/1000\n",
    "#    R2=int(1000*(metrics.r2_score(inv_y_test, predictions)))/1000\n",
    "    \n",
    "    \n",
    "    if plot_on =='YES':\n",
    "        plt.scatter(inv_y_test,predictions)\n",
    "    \n",
    "    return MAE,MSE,R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experiment_RandomForest(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=50,is_random_fixed='TRUE',\n",
    "                  est=10,min_leaf=1,feat='auto',max_leaf=None,min_weight=0.0,min_impurity=1e-07):\n",
    "    \n",
    "    error_rmse = list()\n",
    "    error_R2 = list()\n",
    "    \n",
    "    for r in range(repeats):\n",
    "\n",
    "        result=randomforest(X_train, X_test, y_train, y_test,scaler_y,\n",
    "                            rand=rand,is_random_fixed=is_random_fixed,\n",
    "                            est=est,min_leaf=min_leaf,feat=feat,max_leaf=max_leaf,\n",
    "                            min_weight=min_weight,min_impurity=min_impurity)\n",
    "\n",
    "    \n",
    "      \n",
    "        rmse_test=result[0][1]\n",
    "        R2_test=result[0][2]\n",
    "        \n",
    "        rmse_train=result[1][0]\n",
    "        R2_train=result[1][1]\n",
    "        \n",
    "        error_rmse.append(rmse_test)\n",
    "        error_R2.append(R2_test)\n",
    "    \n",
    "    return error_rmse, error_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NeuralNetwork(X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=50,is_random_fixed='TRUE',\n",
    "                  activ='relu', alph=0.0001, slv='adam', max_iteration=200,  hidden_layer=(30,30)):\n",
    "    \n",
    "    \n",
    "    if is_random_fixed == 'TRUE': \n",
    "        rs=rand\n",
    "    else :\n",
    "        rs=random.randint(1,100)\n",
    "    print('neuralnetwork rs=',rs)   \n",
    "\n",
    "    MLP = MLPRegressor(\n",
    "                            activation=activ,\n",
    "                            random_state =rs,                      \n",
    "                            alpha = alph,\n",
    "                            solver=slv ,\n",
    "                            max_iter=max_iteration,  \n",
    "                            hidden_layer_sizes=hidden_layer\n",
    "                        )\n",
    "\n",
    "\n",
    "    MLPRegressor.fit(MLP,X_train,y_train)\n",
    "    \n",
    "    y_predict_test = MLP.predict(X_test)\n",
    "    y_predict_train = MLP.predict(X_train)\n",
    "    \n",
    "    result_test=inverse_scale_and_graph_Y_predict_and_test(y_predict_test,y_test,scaler_y,'NO')\n",
    "    result_train=inverse_scale_and_graph_Y_predict_and_test(y_predict_train,y_train,scaler_y,'NO')\n",
    "   \n",
    "    return result_test, result_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experiment_NN(repeats,\n",
    "                  X_train, X_test, y_train, y_test,scaler_y,\n",
    "                  rand=50,is_random_fixed='TRUE',\n",
    "                  activ='relu',alph=0.0001, max_iteration=200, slv='adam',  hidden_layer=(30,30)):\n",
    "\n",
    "\n",
    "    error_rmse = list()\n",
    "    error_R2 = list()\n",
    "    \n",
    "    for r in range(repeats):\n",
    "            \n",
    "        result = NeuralNetwork(X_train, X_test, y_train, y_test,scaler_y,\n",
    "                               rand=rand,is_random_fixed=is_random_fixed,\n",
    "                               activ=activ,alph=alph,max_iteration=max_iteration, slv=slv, hidden_layer=hidden_layer)\n",
    "        \n",
    "        \n",
    "        rmse_test=result[0][1]\n",
    "        R2_test=result[0][2]\n",
    "        \n",
    "        rmse_train=result[1][0]\n",
    "        R2_train=result[1][1]\n",
    "        \n",
    "        error_rmse.append(rmse_test)\n",
    "        error_R2.append(R2_test)\n",
    "    \n",
    "    return error_rmse, error_R2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
