{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murat.ozemre\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\murat.ozemre\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "C:\\Users\\murat.ozemre\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import datetime\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.layers import Dense,Input, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from random import gauss\n",
    "from random import seed\n",
    "from pandas import Series\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from random import randrange\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12-26 12:38'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/murat.ozemre/Desktop/Thesis_Project/Data_Sources_and_Preparation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Product_Type_Options = [841810,841840,841850]\n",
    "Product=Product_Type_Options[0] #841810\n",
    "Exp_Country='TUR' # 'CHN'\n",
    "Imp_Country='GBR'\n",
    "\n",
    "if Exp_Country=='CHN':\n",
    "    Currency='CNY'\n",
    "    EXP0='TUR'   \n",
    "elif Exp_Country=='TUR':\n",
    "    Currency='TRY'\n",
    "    EXP0='CHN'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841810 MaxAbsScaler\n"
     ]
    }
   ],
   "source": [
    "Scaler_Type_Options = ['Normalizer', 'MinMaxScaler','MaxAbsScaler','RobustScaler','StandardScaler' ]\n",
    "ScalerType=Scaler_Type_Options[2]\n",
    "print(Product,ScalerType)\n",
    "\n",
    "MonthSeries=\"12\"\n",
    "MonthSeries_option=[\"1\",\"2\",\"3\",\"6\",\"12\"]\n",
    "#MonthSeries_option=[\"12\",\"123\",\"1236\",\"1236_12\",\"__12\",\"__126\",\"__1263\",\"__12632\"]\n",
    "#MonthSeries_option=[\"12\",\"123\",\"1236\",\"1236_12\",\"__12\"]\n",
    "#X1hat.iloc[3:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841810\n",
      "X1 (144, 26) (144,) X1hat (144, 26)\n",
      "841840\n",
      "X2 (142, 26) (142,) X2hat (142, 26)\n",
      "841850\n",
      "X3 (144, 26) (144,) X3hat (144, 26)\n"
     ]
    }
   ],
   "source": [
    "for Product in Product_Type_Options:\n",
    "    \n",
    "    print(Product)\n",
    "    if Product==841810 :\n",
    "        Data_Core1 = pd.ExcelFile('Data_{}_{}_{}.xlsx'.format(Exp_Country,Imp_Country,Product))\n",
    "        y1 = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])['{}_{}_{}'.format(Exp_Country,Imp_Country,Product)]\n",
    "        z1 = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])[['Date','Year','Month']]\n",
    "\n",
    "        X1 = Data_Core1.parse('X{}'.format(MonthSeries), header=0,index_col=None, na_values=['NA'])\n",
    "        X1.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "        X1_Column_Names=list(X1.columns.values)\n",
    "        n_feature=X1.shape[1]\n",
    "\n",
    "        X1hat = Data_Core1.parse('Xhat', header=0,index_col=None, na_values=['NA'])\n",
    "        X1hat.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "        \n",
    "        print('X1',X1.shape, y1.shape,'X1hat', X1hat.shape)\n",
    "        \n",
    "    elif Product==841840 :\n",
    "\n",
    "        Data_Core1 = pd.ExcelFile('Data_{}_{}_{}.xlsx'.format(Exp_Country,Imp_Country,Product))\n",
    "        y2 = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])['{}_{}_{}'.format(Exp_Country,Imp_Country,Product)]\n",
    "        z2 = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])[['Date','Year','Month']]\n",
    "\n",
    "        X2 = Data_Core1.parse('X{}'.format(MonthSeries), header=0,index_col=None, na_values=['NA'])\n",
    "        X2.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "        X2_Column_Names=list(X2.columns.values)\n",
    "        n_feature=X2.shape[1]\n",
    "\n",
    "        X2hat = Data_Core1.parse('Xhat', header=0,index_col=None, na_values=['NA'])\n",
    "        X2hat.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "        \n",
    "        print('X2',X2.shape, y2.shape,'X2hat', X2hat.shape)\n",
    "    elif Product==841850 :\n",
    "        Data_Core1 = pd.ExcelFile('Data_{}_{}_{}.xlsx'.format(Exp_Country,Imp_Country,Product))\n",
    "        y3 = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])['{}_{}_{}'.format(Exp_Country,Imp_Country,Product)]\n",
    "        z3 = Data_Core1.parse('Y', header=0,index_col=None, na_values=['NA'])[['Date','Year','Month']]\n",
    "\n",
    "        X3 = Data_Core1.parse('X{}'.format(MonthSeries), header=0,index_col=None, na_values=['NA'])\n",
    "        X3.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "        X3_Column_Names=list(X3.columns.values)\n",
    "        n_feature=X3.shape[1]\n",
    "\n",
    "        X3hat = Data_Core1.parse('Xhat', header=0,index_col=None, na_values=['NA'])\n",
    "        X3hat.drop(['Date','Year','Month'], axis=1, inplace=True)\n",
    "        \n",
    "        print('X3',X3.shape, y3.shape,'X3hat', X3hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TrainTestSplit(rs,X,y,date,th,random_split):\n",
    "    split_succesfull='TRUE'\n",
    "    values = X.values\n",
    "    values = values.astype('float32')\n",
    "    scaler_x= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_x = scaler_x.fit_transform(values)\n",
    "    scaled_value_x = pd.DataFrame(data=scaled_value_x[:,:])\n",
    "\n",
    "    values = y.values\n",
    "    values = values.astype('float32')\n",
    "    values = values.reshape(-1, 1)\n",
    "    \n",
    "    scaler_y= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_y = scaler_y.fit_transform(values)\n",
    "    scaled_value_y = pd.DataFrame(data=scaled_value_y)\n",
    "\n",
    "    if random_split =='TRUE':\n",
    "        train_X, test_X, train_y, test_y = train_test_split(scaled_value_x.values,scaled_value_y.values,\n",
    "                                                        test_size=0.2,random_state=rs, \n",
    "                                                        stratify=date['Month']\n",
    "                                                       )\n",
    "\n",
    "    elif random_split =='FALSE':\n",
    "        train_lenght=int(len(X)*0.8)\n",
    "        test_lenght=len(X)-train_lenght\n",
    "        \n",
    "        train_X=scaled_value_x.iloc[0:train_lenght,:].values\n",
    "        test_X=scaled_value_x.iloc[train_lenght:len(X),:].values \n",
    "        \n",
    "        train_y=scaled_value_y.iloc[0:train_lenght].values \n",
    "        test_y=scaled_value_y.iloc[train_lenght:len(X)].values\n",
    "        \n",
    "#        train_y_Analiz= train_y\n",
    "#        test_y_Analiz=test_y\n",
    "  \n",
    "    train_y_Analiz=pd.DataFrame(data=train_y[:,:])\n",
    "    test_y_Analiz=pd.DataFrame(data=test_y[:,:])\n",
    "    \n",
    "#    Analiz(scaled_value_y)\n",
    "#    Analiz(train_y_Analiz)\n",
    "#    Analiz(test_y_Analiz)\n",
    "    mean_scaled_y=scaled_value_y.describe().iloc[1].values\n",
    "    mean_train_y=train_y_Analiz.describe().iloc[1].values\n",
    "    mean_test_y=test_y_Analiz.describe().iloc[1].values\n",
    "    \n",
    "    perc=abs((mean_train_y-mean_scaled_y)/mean_scaled_y)*100\n",
    "    \n",
    "    if perc > th:\n",
    "    \n",
    "#        print('Split is not succesfull') \n",
    "        split_succesfull='FALSE'\n",
    "    \n",
    "#    print('mean=', mean_scaled_y,'mean_train_y=',mean_train_y, 'perc=', perc)\n",
    "#    print('diffence=', (mean_train_y-mean_scaled_y))\n",
    "    \n",
    "#    print('mean=', scaled_value_y.describe().iloc[1])\n",
    "    #print(scaled_value_y.describe()) #,train_y_Analiz.describe(),test_y_Analiz.describe()[1])\n",
    "    \n",
    "    #a.to_excel('Dagılım_Kontrolu_icin.xlsx',index = False)\n",
    "    \n",
    "    return train_X, test_X, train_y, test_y, scaler_x, scaler_y,scaled_value_y.describe(),split_succesfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "y=y3\n",
    "X=X3\n",
    "date=z3\n",
    "repeats=1\n",
    "rs=random.randint(1,100)\n",
    "rs=42\n",
    "print(rs)\n",
    "#Threshold Setting for warning\n",
    "th=2.5\n",
    "random_split='FALSE'\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "for r in range(repeats):\n",
    "    rs=random.randint(1,100)\n",
    "    print(rs)\n",
    "    SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "    \n",
    "#Feature Reduction için % oran %0 hepisini alıyor.    \n",
    "#percentile=50\n",
    "percentile=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_excel('X2Split.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIC AYAR YAPMADAN FARKLI SPLIT YAPARAK RF CALISMASI\n",
    "Dort Farklı Calısma Yapıldı\n",
    "1. Aylık Stratify olmadan her 3 urun kodu için çalıştırıldı\n",
    "2. Aylık Stratify yapılarak her 3 ürün kodu için çalıştırıldı\n",
    "3. Aylık Stratify yapılarak aylık fark verisi üzerinden (Xhat) her 3 ürün kodu için çalıştırıldı \n",
    "    R2 gercek değeri alındı.\n",
    "4. Aylık Stratify yapılarak aylık fark verisi üzerinden (Xhat) her 3 ürün kodu için çalıştırıldı \n",
    "    R2 o ayın gerçek değerine göre ayarlanarak alındı.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "TRUE\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'experiment_RF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-45bcf84f0e90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_succesfull\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     experiment_result=experiment_RF(repeats,param,est,min_leaf,rs,\n\u001b[0m\u001b[0;32m     37\u001b[0m                                     \u001b[0mfeat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_leaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_impurity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                                     train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'experiment_RF' is not defined"
     ]
    }
   ],
   "source": [
    "repeats=1\n",
    "random_range_for_split=50\n",
    "rs=random.randint(1,100)\n",
    "#rs=12\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "est=10000\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "\n",
    "param='TRUE'\n",
    "\n",
    "for r in range (random_range_for_split):\n",
    "\n",
    "#for r in range(repeats):\n",
    "    rs=random.randint(1,100)\n",
    "#    rs=42\n",
    "    print(rs)\n",
    "    SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "    \n",
    "    train_X=SplitData[0] \n",
    "    test_X=SplitData[1] \n",
    "    train_y=SplitData[2] \n",
    "    test_y=SplitData[3]\n",
    "    scaler_x=SplitData[4]\n",
    "    scaler_y=SplitData[5]\n",
    "    split_succesfull=SplitData[7]\n",
    "    print(split_succesfull)\n",
    "\n",
    "    experiment_result=experiment_RF(repeats,param,est,min_leaf,rs,\n",
    "                                    feat,max_leaf,min_weight,min_impurity,\n",
    "                                    train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "    \n",
    "#Xhat için analiz yapıldığı ve Adjusted R2 hesaplandığı zaman [2] nolu output kullanılıyor \n",
    "#                                    train_X, test_X, train_y, test_y,scaler_x,scaler_y)[2]\n",
    "\n",
    "    results[str(r)]= experiment_result\n",
    "    results_exp[split_succesfull]= experiment_result\n",
    "    results_split=pd.concat([results_split,results_exp])\n",
    "    print ('results split',results_split)\n",
    "\n",
    "results_randomnumber_bins=results\n",
    "resultvalues=results.values\n",
    "results_all=resultvalues.reshape((random_range_for_split*repeats,1))\n",
    "results_all=pd.DataFrame(data=results_all[:,:])\n",
    "\n",
    "#max_R2=results_all.describe().iloc[7,:]\n",
    "#std=results_all.describe().iloc[2,:]\n",
    "#mean=results_all.describe().iloc[1,:]\n",
    "\n",
    "mean=results_all.describe().values[1]\n",
    "std=results_all.describe().values[2]\n",
    "max_R2=results_all.describe().values[7]\n",
    "\n",
    "results_all.hist()\n",
    "plt.title('{} and with split threshold {} for {} different run'.format(y.name,th,random_range_for_split))\n",
    "plt.axis([0, 1, 0, 400])\n",
    "plt.xlabel('mean {}, std {}, max_value{}'.format(mean,std,max_R2))\n",
    "#plt.savefig('Distiribution_without_Tuning\\Histogram Plot R2 for {} and with (non stratify) split threshold {} for {} different run.png'.format(y.name,th,random_range_for_split))\n",
    "plt.savefig('Distiribution_without_Tuning\\Histogram Plot R2 for {} and with (rs=random) split threshold {} and {} param for {} different run.png'.format(y.name,th,param,random_range_for_split))\n",
    "\n",
    "pyplot.show()\n",
    "\n",
    "plt.gcf().clear()\n",
    "plt.title('{} and with split threshold {}'.format(y.name,th))\n",
    "\n",
    "results_split.boxplot()\n",
    "#plt.savefig('Distiribution_without_Tuning\\Box Plot R2 for {} and with (non stratify) split threshold {} for {} different run.png'.format(y.name,th,random_range_for_split), format='png', dpi=300)\n",
    "plt.savefig('Distiribution_without_Tuning\\Box Plot R2 for {} and with (rs=random)split threshold {} for {} different run.png'.format(y.name,th,random_range_for_split), format='png', dpi=300)\n",
    "\n",
    "pyplot.show()                                   \n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sonuc=pd.concat([sonuc,calıstır_randomforest(X_train, X_test, y_train, y_test,scaler_y,Product,MonthSerie,ScalerType)])\n",
    "\n",
    "#max_R2=int((sonuc['R2'].max())*1000)/1000\n",
    "#filename='Out_Random_Predict_Results_{one}_Product{two}_{four}perc_with max{tre}'.format(one=datetime.now().strftime('Date_%m-%d_Time%H_%M'),\n",
    "#                                                                                      two=Product,tre=max_R2,four=percentile)\n",
    "#sonuc.to_excel('{}.xlsx'.format(filename),index = False)      \n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ince Ayar Yapılmadan once (Spilt için RS sabit) ve tuning sonrasındaki karşılaştırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repeats=3\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "\n",
    "#RS =42ye gore bulunan Tuning sonucları: \n",
    "\n",
    "#841840 Parametre seti\n",
    "est=5000\n",
    "min_leaf=1\n",
    "feat=\"log2\"\n",
    "max_leaf=10\n",
    "min_weight=0.001\n",
    "min_impurity=0.0000001\n",
    "\n",
    "#841810 Parametre seti\n",
    "est=10000\n",
    "min_leaf=2\n",
    "feat=\"sqrt\"\n",
    "max_leaf=150\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "#841850  Parametre seti\n",
    "est=2000\n",
    "min_leaf=20\n",
    "feat=10\n",
    "max_leaf=50\n",
    "min_weight=0.1\n",
    "min_impurity=0.01\n",
    "\n",
    "\n",
    "#RS =42ye gore bulunan Tuning sonucları: \n",
    "#RS =Randoma gore bulunan Tuning sonucları: \n",
    "\n",
    "est=10000\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "\n",
    "#Etkin olan parametre seti\n",
    "\n",
    "est=10000\n",
    "min_leaf=2\n",
    "feat=\"sqrt\"\n",
    "max_leaf=150\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "#NN için parametreler\n",
    "alph= 1e-12\n",
    "max_iteration= 50000\n",
    "slv= \"adam\"\n",
    "hidden_layer= (30, 30)\n",
    "\n",
    "\n",
    "\n",
    "param_options=[\"FALSE\",\"TRUE\"]\n",
    "\n",
    "#Farklı RAndom Seed Splitler\n",
    "rs=random.randint(1,100)\n",
    "#Tek bir Random Seed Split\n",
    "rs=42\n",
    "\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "train_X=SplitData[0] \n",
    "test_X=SplitData[1] \n",
    "train_y=SplitData[2] \n",
    "test_y=SplitData[3]\n",
    "scaler_x=SplitData[4]\n",
    "scaler_y=SplitData[5]\n",
    "split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "experiment=\"NN\" #or RF\n",
    "first_loop_range=50\n",
    "second_loop_range=2\n",
    "for r in range (0,first_loop_range):\n",
    "    rs=random.randint(1,100)\n",
    "   \n",
    "    SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "    print(rs)\n",
    "    train_X=SplitData[0] \n",
    "    test_X=SplitData[1] \n",
    "    train_y=SplitData[2] \n",
    "    test_y=SplitData[3]\n",
    "    scaler_x=SplitData[4]\n",
    "    scaler_y=SplitData[5]\n",
    "    split_succesfull=SplitData[7]\n",
    "    \n",
    "    \n",
    "    for p in range (0, second_loop_range):\n",
    "        \n",
    "        param=param_options[p]\n",
    "        \n",
    "        if experiment==\"RF\":\n",
    "            experiment_result=experiment_RF(repeats,param,est,min_leaf,rs,\n",
    "                                    feat,max_leaf,min_weight,min_impurity,\n",
    "                                    train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        elif experiment==\"NN\":\n",
    "             experiment_result=experiment_NN(repeats,param,alph,max_iteration,slv,rseed,hidden_layer,\n",
    "                          train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        \n",
    "        results_exp[param]= experiment_result\n",
    "        \n",
    "#    results_split[split_succesfull]= experiment_result\n",
    "    results=pd.concat([results,results_exp])\n",
    "\n",
    "results_randomnumber_bins=results\n",
    "resultvalues=results.values\n",
    "results_all=resultvalues.reshape((first_loop_range*second_loop_range*repeats,1))\n",
    "results_all=pd.DataFrame(data=results_all[:,:])\n",
    "\n",
    "mean=results_all.describe().values[1]\n",
    "std=results_all.describe().values[2]\n",
    "max_R2=results_all.describe().values[7]\n",
    "\n",
    "plt.gcf().clear()\n",
    "plt.title('{} with (according rs=42 Tuned and split general) before Tuning and (trained rs=90) after Tuning'.format(y.name))\n",
    "plt.xlabel('mean {}, std {}, max_value{}'.format(mean,std,max_R2))\n",
    "results.boxplot()\n",
    "plt.savefig('Distiribution_without_Tuning\\Box Plot R2 for {} and (tuned rs =42)(split=general){} (trained rs=90) different run.png'.format(y.name,repeats), \n",
    "            format='png', dpi=300)\n",
    "\n",
    "pyplot.show()                                   \n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sonuc=pd.concat([sonuc,calıstır_randomforest(X_train, X_test, y_train, y_test,scaler_y,Product,MonthSerie,ScalerType)])\n",
    "\n",
    "#max_R2=int((sonuc['R2'].max())*1000)/1000\n",
    "#filename='Out_Random_Predict_Results_{one}_Product{two}_{four}perc_with max{tre}'.format(one=datetime.now().strftime('Date_%m-%d_Time%H_%M'),\n",
    "#                                                                                      two=Product,tre=max_R2,four=percentile)\n",
    "#sonuc.to_excel('{}.xlsx'.format(filename),index = False)      \n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#def experiment(repeats,n_epochs,n_neurons,learning_rate,bs,rs,X,y,date):\n",
    "def experiment_LSTM(repeats,n_epochs,n_neurons,learning_rate,bs,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y):\n",
    "    K.clear_session()\n",
    "\n",
    "#    print(type(train_X))\n",
    "    train_X =train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "#    train_X =train_X.reshape((train_X.shape[0], train_X.shape[1],1))\n",
    "#    test_X = test_X.reshape((test_X.shape[0], test_X.shape[1],1))\n",
    "#    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    " \n",
    "    \n",
    "    error_rmse = list()\n",
    "    error_r2hat = list()\n",
    "    error_r2 = list()\n",
    "    for r in range(repeats):\n",
    "        \n",
    "        print('Shape of X Train',train_X.shape[1],train_X.shape[2])\n",
    "    \n",
    "\n",
    "        if do_model=='A':\n",
    "            model = Sequential() \n",
    "            model.add(LSTM(n_neurons,input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "            model.add(Dropout(drop_rate))\n",
    "            \n",
    "            model.add(Dense(n_neurons))\n",
    "            model.add(Dropout(drop_rate))\n",
    "            \n",
    "            model.add(Dense(1))\n",
    "#            model.add(Activation('sigmoid'))\n",
    "            model.add(Activation('linear'))\n",
    "        \n",
    "        elif do_model=='B':   \n",
    "            input_layer=Input(shape=(train_X.shape[1], train_X.shape[2]),dtype='float32')\n",
    "            lstm_layer1=LSTM(n_neurons,input_shape=(train_X.shape[1],train_X.shape[2]),\n",
    "                         dropout=drop_rate, \n",
    "                         recurrent_dropout=drop_rate,\n",
    "                         return_sequences=True)(input_layer)\n",
    "            lstm_layer2=LSTM(n_neurons,input_shape=(train_X.shape[1],n_neurons),\n",
    "                         dropout=drop_rate, \n",
    "                         recurrent_dropout=drop_rate,\n",
    "                         return_sequences=False)(lstm_layer1)\n",
    "            dropout_layer=Dropout(drop_rate)(lstm_layer2)\n",
    "\n",
    "            output_layer=Dense(1,activation=\"linear\")(dropout_layer)\n",
    "#            output_layer=Dense(1,activation=\"linear\")(lstm_layer2)\n",
    "         \n",
    "\n",
    "        #ix layerlarda Activation için RELU Output için linear uygun oluyor. Kaynak Siraj Raval\n",
    "        \n",
    "            model=Model(inputs=input_layer, outputs=output_layer)\n",
    "        \n",
    "        \n",
    "        #decay_rate = learning_rate / n_epochs\n",
    "        \n",
    "        decay_rate = 0.8\n",
    "        momentum = 0.9\n",
    "         \n",
    "        sgd = optimizers.SGD(lr=learning_rate, clipvalue=0.3,momentum=momentum, decay=decay_rate,nesterov=True)\n",
    "        adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)\n",
    "\n",
    "        #model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        \n",
    "        \n",
    "#        model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "        model.compile(loss='mean_squared_error', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "#        model=load_model(os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(y.name,n_neurons)))\n",
    "#        model=load_model(os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(y.name,n_neurons)))\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "        save_weights_at=os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(y.name,n_neurons))\n",
    "\n",
    "        save_best=ModelCheckpoint(save_weights_at, monitor='val_loss', verbose=0,\n",
    "                                 save_best_only=True, save_weights_only=False, mode='min',\n",
    "                                 period=1)\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.00001)\n",
    "        early_stop = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "        \n",
    "        history = model.fit(train_X, train_y, epochs=n_epochs, batch_size=bs, \n",
    "\n",
    "                            validation_data=(test_X, test_y), verbose=1, \n",
    "#                            callbacks=[reduce_lr],\n",
    "                           # callbacks=[save_best],\n",
    "\n",
    "                           # callbacks=[early_stop],\n",
    "                            shuffle=False)\n",
    "\n",
    "#        best_model=load_model(os.path.join('Data','train_dataset.hdf5')\n",
    "#        model=load_model(os.path.join('Data','train_dataset{}-{}neurons.hdf5'.format(y.name,n_neurons)))\n",
    "\n",
    "        #model=best_model\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # summarize history for loss\n",
    "        plt.gcf().clear()\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        # summarize history for accuracy\n",
    "#        plt.plot(history.history['acc'])\n",
    "#        plt.plot(history.history['val_acc'])\n",
    "#        plt.title('model accuracy')\n",
    "#        plt.ylabel('accuracy')\n",
    "#        plt.xlabel('epoch')\n",
    "#        plt.legend(['train', 'test'], loc='upper left')\n",
    "#        plt.show()\n",
    "\n",
    "\n",
    "#        test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[1]))\n",
    "\n",
    "        test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "        inv_x_test = scaler_x.inverse_transform(test_X_reshaped)\n",
    "        inv_x_test = pd.DataFrame(data=inv_x_test[:,:])\n",
    "\n",
    "        # make a prediction\n",
    "        y_predict_test = model.predict(test_X)\n",
    "        y_predict_train = model.predict(train_X)\n",
    "\n",
    "        # invert scaling for forecast\n",
    "        inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "        inv_y_predict_test = inv_y_predict_test[:,0]\n",
    "        inv_y_predict_train = scaler_y.inverse_transform(y_predict_train)\n",
    "        inv_y_predict_train = inv_y_predict_train[:,0]\n",
    "\n",
    "        # invert scaling for actual\n",
    "        y_test = test_y.reshape((len(test_y), 1))\n",
    "        inv_y_test = scaler_y.inverse_transform(test_y)\n",
    "        inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "        y_train = train_y.reshape((len(train_y), 1))\n",
    "        inv_y_train = scaler_y.inverse_transform(train_y)\n",
    "        inv_y_train = inv_y_train[:,0]\n",
    "\n",
    "        # calculate RMSE for DIFFERENCE\n",
    "        rmse_test = sqrt(mean_squared_error(inv_y_test, inv_y_predict_test))\n",
    "        print('Test RMSE: %.3f' % rmse_test)\n",
    "        R2_test=int(1000*(metrics.r2_score(inv_y_test, inv_y_predict_test)))/1000\n",
    "        print('R2_test: %.3f' % R2_test)\n",
    "\n",
    "        rmse_train = sqrt(mean_squared_error(inv_y_train, inv_y_predict_train))\n",
    "        print('Train RMSE: %.3f' % rmse_train)\n",
    "        R2_train=int(1000*(metrics.r2_score(inv_y_train, inv_y_predict_train)))/1000\n",
    "        print('R2_train: %.3f' % R2_train)\n",
    "\n",
    "        # calculate RMSE for REAL VALUE\n",
    "\n",
    "        real_y_test= inv_x_test.iloc[:,0]+inv_y_test\n",
    "        real_y_predict_test=inv_x_test.iloc[:,0]+inv_y_predict_test\n",
    "        \n",
    "        real_rmse_test = sqrt(mean_squared_error(real_y_test, real_y_predict_test))\n",
    "        print('Test RMSE: %.3f' % real_rmse_test)\n",
    "        real_R2_test=int(1000*(metrics.r2_score(real_y_test, real_y_predict_test)))/1000\n",
    "        print('R2_test: %.3f' % real_R2_test)\n",
    "        \n",
    "        error_rmse.append(real_rmse_test)\n",
    "        error_r2hat.append(real_R2_test)\n",
    "        error_r2.append(R2_test)\n",
    "        \n",
    "        \n",
    "        plt.gcf().clear()\n",
    "        plt.figure(figsize=(5.5, 5.5))\n",
    "        plt.plot(range(len(inv_y_test)), inv_y_test, linestyle='-', marker='*', color='r')\n",
    "        plt.plot(range(len(inv_y_predict_test)), inv_y_predict_test, linestyle='-', marker='.', color='b')\n",
    "        plt.legend(['Actual','Predicted'], loc=2)\n",
    "        plt.title('Actual vs Predicted for {}'.format(y.name))\n",
    "        plt.ylabel('Trade Value')\n",
    "        plt.xlabel('Index')\n",
    "        plt.savefig('Data/LSTM-LinePlt{} ,{} epochs,{} neurons,{} learning_rate,{} batch size, {} random, {} R2.png'.format(y.name,\n",
    "                                n_epochs,n_neurons,learning_rate,bs,rs,R2_test), format='png', dpi=300)\n",
    "       \n",
    "\n",
    "        \n",
    "        \n",
    "    return error_rmse,error_r2,error_r2hat,train_y,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rs=29\n",
    "rs=42\n",
    "repeats = 1\n",
    "drop_rate=0.0\n",
    "do_batch='TRUE'\n",
    "do_model='B'\n",
    "random_split='TRUE'\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "e=30\n",
    "n=300\n",
    "lr=0.01\n",
    "b=1\n",
    "\n",
    "train_X=SplitData[0] \n",
    "test_X=SplitData[1] \n",
    "train_y=SplitData[2] \n",
    "test_y=SplitData[3]\n",
    "scaler_x=SplitData[4]\n",
    "scaler_y=SplitData[5]\n",
    "\n",
    "deney=experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)\n",
    "\n",
    "error_rmse=deney[0] \n",
    "error_r2=deney[1] \n",
    "error_r2hat=deney[2] \n",
    "train_y=deney[3]\n",
    "history=deney[4]\n",
    "print(error_r2)\n",
    "print(error_r2hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rs=29\n",
    "rs=42\n",
    "repeats = 1\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "e=200\n",
    "n=400\n",
    "lr=0.001\n",
    "b=30\n",
    "\n",
    "train_X=SplitData[0] \n",
    "test_X=SplitData[1] \n",
    "train_y=SplitData[2] \n",
    "test_y=SplitData[3]\n",
    "scaler_x=SplitData[4]\n",
    "scaler_y=SplitData[5]\n",
    "\n",
    "deney=experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)\n",
    "\n",
    "error_rmse=deney[0] \n",
    "error_r2=deney[1] \n",
    "error_r2hat=deney[2] \n",
    "train_y=deney[3]\n",
    "history=deney[4]\n",
    "print(error_r2)\n",
    "print(error_r2hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def experiment_RF(repeats,param,est,min_leaf,random,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y):\n",
    "\n",
    "    \n",
    "    error_rmse = list()\n",
    "    error_r2hat = list()\n",
    "    error_r2 = list()\n",
    "    for r in range(repeats):\n",
    "        \n",
    "        if param== 'TRUE':\n",
    "            rfc_model=RandomForestRegressor(n_estimators=est,\n",
    "                              min_samples_leaf=min_leaf,\n",
    "                          #    random_state =random,\n",
    "                              max_features=feat,\n",
    "                              max_leaf_nodes=max_leaf,\n",
    "                              min_weight_fraction_leaf =min_weight,\n",
    "                              min_impurity_split=min_impurity\n",
    "                             )\n",
    "        elif param== 'FALSE':\n",
    "            rfc_model=RandomForestRegressor()\n",
    "\n",
    "        RandomForestRegressor.fit(rfc_model,train_X,train_y)\n",
    "        \n",
    "        # make a prediction\n",
    "        y_predict_test = rfc_model.predict(test_X)\n",
    "        y_predict_train = rfc_model.predict(train_X)\n",
    "\n",
    "\n",
    "        #test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "#        test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "        inv_x_test = scaler_x.inverse_transform(test_X)\n",
    "        inv_x_test = pd.DataFrame(data=inv_x_test[:,:])\n",
    "\n",
    "\n",
    "        # invert scaling for forecast\n",
    "        inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "#        inv_y_predict_test = inv_y_predict_test[:,0]\n",
    "        inv_y_predict_train = scaler_y.inverse_transform(y_predict_train)\n",
    "#        inv_y_predict_train = inv_y_predict_train[:,0]\n",
    "\n",
    "        # invert scaling for actual\n",
    "        y_test = test_y.reshape((len(test_y), 1))\n",
    "        inv_y_test = scaler_y.inverse_transform(test_y)\n",
    "        inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "        y_train = train_y.reshape((len(train_y), 1))\n",
    "        inv_y_train = scaler_y.inverse_transform(train_y)\n",
    "        inv_y_train = inv_y_train[:,0]\n",
    "\n",
    "        # calculate RMSE for DIFFERENCE\n",
    "        rmse_test = sqrt(mean_squared_error(inv_y_test, inv_y_predict_test))\n",
    "#        print('Test RMSE: %.3f' % rmse_test)\n",
    "        R2_test=int(1000*(metrics.r2_score(inv_y_test, inv_y_predict_test)))/1000\n",
    "#        print('R2_test: %.3f' % R2_test)\n",
    "\n",
    "        rmse_train = sqrt(mean_squared_error(inv_y_train, inv_y_predict_train))\n",
    "#        print('Train RMSE: %.3f' % rmse_train)\n",
    "        R2_train=int(1000*(metrics.r2_score(inv_y_train, inv_y_predict_train)))/1000\n",
    "#        print('R2_train: %.3f' % R2_train)\n",
    "\n",
    "        # calculate RMSE for REAL VALUE\n",
    "\n",
    "        real_y_test= inv_x_test.iloc[:,0]+inv_y_test\n",
    "        real_y_predict_test=inv_x_test.iloc[:,0]+inv_y_predict_test\n",
    "        \n",
    "        real_rmse_test = sqrt(mean_squared_error(real_y_test, real_y_predict_test))\n",
    "#        print('Test RMSE: %.3f' % real_rmse_test)\n",
    "        real_R2_test=int(1000*(metrics.r2_score(real_y_test, real_y_predict_test)))/1000\n",
    "#        print('R2_test: %.3f' % real_R2_test)\n",
    "        \n",
    "        error_rmse.append(real_rmse_test)\n",
    "        error_r2hat.append(real_R2_test)\n",
    "        error_r2.append(R2_test)\n",
    "        \n",
    "#        plt.gcf().clear()\n",
    "#        plt.figure(figsize=(5.5, 5.5))\n",
    "#        plt.plot(range(len(inv_y_test)), inv_y_test, linestyle='-', marker='*', color='r')\n",
    "#        plt.plot(range(len(inv_y_predict_test)), inv_y_predict_test, linestyle='-', marker='.', color='b')\n",
    "#        plt.legend(['Actual','Predicted'], loc=2)\n",
    "#        plt.title('Actual vs Predicted for {}'.format(y.name))\n",
    "#        plt.ylabel('Trade Value')\n",
    "#        plt.xlabel('Index')\n",
    "#        plt.savefig('Data/RF-LinePlt{} ,{} est,{} min_leaf,{} rs_for split,{} max_leaf, {} min_weight,{}min_impurity, {} R2.png'.format(y.name,\n",
    "#                                est,min_leaf,random,feat,max_leaf,min_weight,min_impurity,R2_test), format='png', dpi=300)\n",
    "       \n",
    "\n",
    "        \n",
    "        \n",
    "    return error_rmse,error_r2,error_r2hat,train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#X2 ve X3 için denemelerde kullanılan parametreler\n",
    "estimator_options = [100,1000,2000,5000]\n",
    "min_sample_leaf_options = [1,2,5,20,30]\n",
    "#random_state_options =[10]\n",
    "max_features_options=[10,\"log2\",\"sqrt\",\"auto\"]\n",
    "max_leaf_nodes_options=[2,5,10,50,100] \n",
    "min_weight_fraction_leaf_options=[0.0001,0.001,0.01,0.1] \n",
    "min_impurity_decrease_options =[0.0000001,0.000001,0.001,0.01]\n",
    "\n",
    "est=estimator_options[2]\n",
    "min_leaf=min_sample_leaf_options[0]\n",
    "feat=max_features_options[0]\n",
    "max_leaf=max_leaf_nodes_options[1]\n",
    "min_weight=min_weight_fraction_leaf_options[0]\n",
    "min_impurity=min_impurity_decrease_options[3]\n",
    "\n",
    "Start Set\n",
    "est=2000\n",
    "min_leaf=1\n",
    "feat=max_10\n",
    "max_leaf=5\n",
    "min_weight=0.0001\n",
    "min_impurity=0.001\n",
    "\n",
    "RS =42Ye gore bulunan Tuning sonucları:\n",
    "841840 için:\n",
    "est=5000\n",
    "min_leaf=1\n",
    "feat=\"log2\"\n",
    "max_leaf=10\n",
    "min_weight=0.001\n",
    "min_impurity=0.0000001\n",
    "\n",
    "841850 için:\n",
    "est=2000\n",
    "min_leaf=20\n",
    "feat=10\n",
    "max_leaf=50\n",
    "min_weight=0.1\n",
    "min_impurity=0.01\n",
    "\n",
    "841810 icin\n",
    "est=10000\n",
    "min_leaf=2\n",
    "feat=\"sqrt\"\n",
    "max_leaf=150\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "GENEL RS farklı oldugundaki Tuning sonucları\n",
    "841850 için:\n",
    "\n",
    "\n",
    "841840 için\n",
    "est=10000\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "\n",
    "\n",
    "NN 841850 için: ve RS=42 Splite göre yaıplan Tuning\n",
    "\n",
    "alph= 1e-12\n",
    "max_iteration= 50000\n",
    "slv= \"adam\"\n",
    "hidden_layer= (30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter usage TRUE\n",
      "est= 200\n",
      "min_sample_leaf= 2\n",
      "max_features= log2\n",
      "max_leaf_nodes= 5\n",
      "min_weight_fraction_leaf= 0.01\n",
      "min_impurity_decrease= 1e-06\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.33936217 0.33126877 0.31335274 0.33756125 0.32007488 0.33712314\n 0.34623056 0.37401899 0.34239561 0.33068446 0.26586132 0.29168653\n 0.31186799 0.32387878 0.33005449 0.35809981 0.35987033 0.34572868\n 0.34701502 0.40243664 0.35426892 0.37034756 0.32278517 0.33111088\n 0.33488242 0.36719529 0.35415645 0.37799831 0.35406936].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6f6b14ca50cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"min_impurity_decrease=\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_impurity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mresults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexperiment_RF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_leaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_leaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_impurity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaler_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaler_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-368792da7e2b>\u001b[0m in \u001b[0;36mexperiment_RF\u001b[1;34m(repeats, param, est, min_leaf, random, feat, max_leaf, min_weight, min_impurity, train_X, test_X, train_y, test_y, scaler_x, scaler_y)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# invert scaling for forecast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0minv_y_predict_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;31m#        inv_y_predict_test = inv_y_predict_test[:,0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0minv_y_predict_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'scale_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\Tensor_1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    408\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    411\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.33936217 0.33126877 0.31335274 0.33756125 0.32007488 0.33712314\n 0.34623056 0.37401899 0.34239561 0.33068446 0.26586132 0.29168653\n 0.31186799 0.32387878 0.33005449 0.35809981 0.35987033 0.34572868\n 0.34701502 0.40243664 0.35426892 0.37034756 0.32278517 0.33111088\n 0.33488242 0.36719529 0.35415645 0.37799831 0.35406936].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "\n",
    "rs=42\n",
    "repeats = 3\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "results = DataFrame()\n",
    "\n",
    "\n",
    "estimator_options = [100,200,500,1000,5000,10000,20000]\n",
    "min_sample_leaf_options = [1,2,5,20,30]\n",
    "#random_state_options =[10]\n",
    "max_features_options=[10,\"log2\",\"sqrt\",\"auto\"]\n",
    "max_leaf_nodes_options=[2,5,10,100,200,300] \n",
    "min_weight_fraction_leaf_options=[0.00001,0.0001,0.001,0.01,0.1] \n",
    "min_impurity_decrease_options =[0.0000001,0.000001,0.001,0.01,0.05]\n",
    "\n",
    "param='TRUE'\n",
    "est=estimator_options[2]\n",
    "min_leaf=min_sample_leaf_options[0]\n",
    "feat=max_features_options[2]\n",
    "max_leaf=max_leaf_nodes_options[3]\n",
    "min_weight=min_weight_fraction_leaf_options[1]\n",
    "min_impurity=min_impurity_decrease_options[3]\n",
    "\n",
    "\n",
    "est=200\n",
    "min_leaf=2\n",
    "feat=\"log2\"\n",
    "max_leaf=5\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "print(\"parameter usage\", param)\n",
    "print(\"est=\", est)\n",
    "print(\"min_sample_leaf=\", min_leaf)\n",
    "print(\"max_features=\",feat)\n",
    "print(\"max_leaf_nodes=\", max_leaf)\n",
    "print(\"min_weight_fraction_leaf=\", min_weight)\n",
    "print(\"min_impurity_decrease=\", min_impurity)\n",
    "\n",
    "results=experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "print(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "\n",
    "for r in range (0,100):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for min_leaf in min_sample_leaf_options:\n",
    "            results_exp[str(min_leaf)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "\n",
    "\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_sample_leaf_options,rs,feat,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(y.name,MonthSeries,est,min_sample_leaf_options,feat,max_leaf,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"log2\"\n",
    "max_leaf=5\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "for r in range (0,20):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "        \n",
    "        for feat in max_features_options:\n",
    "            results_exp[str(feat)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        \n",
    "        \n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,max_features_options,max_leaf,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=5\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "print(\"est=\", est)\n",
    "print(\"min_sample_leaf=\", min_leaf)\n",
    "print(\"max_features=\",feat)\n",
    "print(\"max_leaf_nodes=\", max_leaf)\n",
    "print(\"min_weight_fraction_leaf=\", min_weight)\n",
    "print(\"min_impurity_decrease=\", min_impurity)\n",
    "\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "\n",
    "for r in range (0,30):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for max_leaf in max_leaf_nodes_options:\n",
    "            results_exp[str(max_leaf)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        \n",
    "        results=pd.concat([results,results_exp])\n",
    "            \n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,feat,max_leaf_nodes_options,min_weight,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weight,{}min_impurity.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,feat,max_leaf_nodes_options,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.01\n",
    "min_impurity=0.000001\n",
    "\n",
    "\n",
    "print(\"est=\", est)\n",
    "print(\"min_sample_leaf=\", min_leaf)\n",
    "print(\"max_features=\",feat)\n",
    "print(\"max_leaf_nodes=\", max_leaf)\n",
    "print(\"min_weight_fraction_leaf=\", min_weight)\n",
    "print(\"min_impurity_decrease=\", min_impurity)\n",
    "\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "        for min_weight in min_weight_fraction_leaf_options:\n",
    "            results_exp[str(min_weight)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        \n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,feat,max_leaf,min_weight_fraction_leaf_options,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for{}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weig,{}min_imp.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,feat,max_leaf,min_weight_fraction_leaf_options,min_impurity))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.000001\n",
    "print(\"est=\", est)\n",
    "print(\"min_sample_leaf=\", min_leaf)\n",
    "print(\"max_features=\",feat)\n",
    "print(\"max_leaf_nodes=\", max_leaf)\n",
    "print(\"min_weight_fraction_leaf=\", min_weight)\n",
    "print(\"min_impurity_decrease=\", min_impurity)\n",
    "\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "\n",
    "        for min_impurity in min_impurity_decrease_options:\n",
    "            results_exp[str(min_impurity)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  est, min_leaf,rs,feat,max_leaf,min_weight,min_impurity_decrease_options))\n",
    "plt.savefig('Data/15 Mayıs/RF-Box Plot for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} min_weig,{}min_impu.png'\n",
    "               .format(y.name,MonthSeries,est,min_leaf,feat,max_leaf,min_weight,min_impurity_decrease_options))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator_options = [100,200,500,1000,5000,10000]\n",
    "\n",
    "est=200\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "\n",
    "        for est in estimator_options:\n",
    "            results_exp[str(est)] = experiment_RF(repeats,param,est,min_leaf,rs,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "\n",
    "\n",
    "plt.title(\"RF-Box Plot for {}-{},{} est,{} min_leaf,{} rs_for split,{} feat, {} max_leaf, {} min_weight,{}min_impurity\"\n",
    "          .format(y.name,MonthSeries,  estimator_options, min_leaf,rs,feat,max_leaf,min_weight,min_impurity))\n",
    "plt.savefig('Data/15 Mayıs/RF-BoxP for {}-{}, {} est,{} min_leaf,{} feat,{} max_leaf, {} minweig,{}minimp.png'\n",
    "               .format(y.name,MonthSeries,estimator_options,min_leaf,feat,max_leaf,min_weight,min_impurity))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM ICIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "\n",
    "repeats = 1\n",
    "\n",
    "# vary training epochs\"\n",
    "epochs = [50, 500, 1000,2000]\n",
    "neurons = [5, 50,100]\n",
    "learning_rates= [0.001, 0.01, 0.05, 0.1]\n",
    "batch_sizes=[5, 12, 24,50,100]\n",
    "\n",
    "\n",
    "e=3000\n",
    "n=200\n",
    "lr=0.02\n",
    "b=50\n",
    "\n",
    "\n",
    "e=500\n",
    "n=100\n",
    "lr=0.05\n",
    "b=50\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "\n",
    "        for e in epochs:\n",
    "            results_exp[str(e)] = experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "\n",
    "results.boxplot()\n",
    "plt.title(\"LSTM-Box Plot for {}-{}, {} epochs,{} neurons,{} learning_rate, {}batch size \"\n",
    "          .format(y.name,MonthSeries,epochs,n,lr,b))\n",
    "plt.savefig('Data/LSTM-Box Plot for {}-{}, {} epochs,{} neurons {}lr,{}b.png'\n",
    "               .format(y.name,MonthSeries,epochs,n,lr,b))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "\n",
    "repeats = 1\n",
    "e=500\n",
    "n=100\n",
    "lr=0.001\n",
    "b=50\n",
    "deney=experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)\n",
    "deney[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#repeats=10\n",
    "e=2000\n",
    "n=100\n",
    "lr=0.05\n",
    "b=50\n",
    "\n",
    "neurons = [5, 50, 100]\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for n in neurons:\n",
    "            results_exp[str(n)] = experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"LSTM-Box Plot for {}-{}, {} epochs,{} neurons,{} learning_rate {}batch size\"\n",
    "          .format(y.name,MonthSeries,e,neurons,lr,b))\n",
    "plt.savefig('Data/LSTM-Box Plot for {}-{}, {} epochs,{} neurons{},lr{}, b.png'\n",
    "               .format(y.name,MonthSeries,e,neurons,lr,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "repeats = 10\n",
    "e=100\n",
    "n=50\n",
    "lr=0.05\n",
    "b=50\n",
    "results_exp = DataFrame()\n",
    "results = DataFrame()\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for b in batch_sizes:\n",
    "            results_exp[str(b)] = experiment_LSTM(repeats,e,n,lr,b,drop_rate,do_batch,do_model,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"LSTM-Box Plot for {}-{}, {} epochs,{} neurons,{} learning_rate {}batch size \"\n",
    "          .format(y.name,MonthSeries,e,n,lr,batch_sizes))\n",
    "plt.savefig('Data/LSTM-Box Plot for {}-{}, {} epochs,{} neurons{}lr,{}bsize.png'\n",
    "               .format(y.name,MonthSeries,e,n,lr,batch_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "LSTM SONU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN BASLANGICI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def experiment_NN(repeats,param,alph,max_iteration,slv,rs,hidden_layer,train_X, test_X, train_y, test_y,scaler_x,scaler_y):\n",
    "\n",
    "#    rs=90\n",
    "    error_rmse = list()\n",
    "    error_r2hat = list()\n",
    "    error_r2 = list()\n",
    "    for r in range(repeats):\n",
    "        \n",
    "        if param== 'TRUE':\n",
    "            MLP = MLPRegressor(\n",
    "                              alpha = alph,\n",
    "                              solver=slv ,\n",
    "                              max_iter=max_iteration,\n",
    "       #                       random_state =rs,\n",
    "                              hidden_layer_sizes=hidden_layer\n",
    "                        )\n",
    "        \n",
    "        elif param== 'FALSE':\n",
    "             MLP = MLPRegressor()\n",
    "            \n",
    "        \n",
    "        MLPRegressor.fit(MLP,train_X,train_y)\n",
    "        \n",
    "        \n",
    "        # make a prediction\n",
    "        y_predict_test = MLP.predict(test_X)\n",
    "        y_predict_train = MLP.predict(train_X)\n",
    "\n",
    "  \n",
    "        \n",
    "        #test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "#        test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "        inv_x_test = scaler_x.inverse_transform(test_X)\n",
    "        inv_x_test = pd.DataFrame(data=inv_x_test[:,:])\n",
    "\n",
    "\n",
    "        # invert scaling for forecast\n",
    "        inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "#        inv_y_predict_test = inv_y_predict_test[:,0]\n",
    "        inv_y_predict_train = scaler_y.inverse_transform(y_predict_train)\n",
    "#        inv_y_predict_train = inv_y_predict_train[:,0]\n",
    "\n",
    "        # invert scaling for actual\n",
    "        y_test = test_y.reshape((len(test_y), 1))\n",
    "        inv_y_test = scaler_y.inverse_transform(test_y)\n",
    "        inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "        y_train = train_y.reshape((len(train_y), 1))\n",
    "        inv_y_train = scaler_y.inverse_transform(train_y)\n",
    "        inv_y_train = inv_y_train[:,0]\n",
    "\n",
    "        # calculate RMSE for DIFFERENCE\n",
    "        rmse_test = sqrt(mean_squared_error(inv_y_test, inv_y_predict_test))\n",
    "#        print('Test RMSE: %.3f' % rmse_test)\n",
    "        R2_test=int(1000*(metrics.r2_score(inv_y_test, inv_y_predict_test)))/1000\n",
    "#        print('R2_test: %.3f' % R2_test)\n",
    "\n",
    "        rmse_train = sqrt(mean_squared_error(inv_y_train, inv_y_predict_train))\n",
    "#        print('Train RMSE: %.3f' % rmse_train)\n",
    "        R2_train=int(1000*(metrics.r2_score(inv_y_train, inv_y_predict_train)))/1000\n",
    "#        print('R2_train: %.3f' % R2_train)\n",
    "\n",
    "        # calculate RMSE for REAL VALUE\n",
    "\n",
    "        real_y_test= inv_x_test.iloc[:,0]+inv_y_test\n",
    "        real_y_predict_test=inv_x_test.iloc[:,0]+inv_y_predict_test\n",
    "        \n",
    "        real_rmse_test = sqrt(mean_squared_error(real_y_test, real_y_predict_test))\n",
    "#        print('Test RMSE: %.3f' % real_rmse_test)\n",
    "        real_R2_test=int(1000*(metrics.r2_score(real_y_test, real_y_predict_test)))/1000\n",
    "#        print('R2_test: %.3f' % real_R2_test)\n",
    "        \n",
    "        error_rmse.append(real_rmse_test)\n",
    "        error_r2hat.append(real_R2_test)\n",
    "        error_r2.append(R2_test)\n",
    "        \n",
    "#        plt.gcf().clear()\n",
    "#        plt.figure(figsize=(5.5, 5.5))\n",
    "#        plt.plot(range(len(inv_y_test)), inv_y_test, linestyle='-', marker='*', color='r')\n",
    "#        plt.plot(range(len(inv_y_predict_test)), inv_y_predict_test, linestyle='-', marker='.', color='b')\n",
    "#        plt.legend(['Actual','Predicted'], loc=2)\n",
    "#        plt.title('Actual vs Predicted for {}'.format(y.name))\n",
    "#        plt.ylabel('Trade Value')\n",
    "#        plt.xlabel('Index')\n",
    "#        plt.savefig('Data/RF-LinePlt{} ,{} est,{} min_leaf,{} rs_for split,{} max_leaf, {} min_weight,{}min_impurity, {} R2.png'.format(y.name,\n",
    "#                                est,min_leaf,random,feat,max_leaf,min_weight,min_impurity,R2_test), format='png', dpi=300)\n",
    "       \n",
    "\n",
    "        \n",
    "        \n",
    "    return error_rmse,error_r2,error_r2hat,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "param='TRUE'\n",
    "random_split='TRUE'\n",
    "alpha_options = [0.0001,0.00000001,0.0000000001, 0.000000000001]\n",
    "solver_options = ['lbfgs', 'adam' ] # sgd solver cok sapıttı\n",
    "max_iteration_options = [50000,60000,100000]\n",
    "#random_state_options =[1,10,50,75,200]\n",
    "#random_state_options =[10,50,90]\n",
    "random_state_options =[90]\n",
    "hidden_layer_sizes_options=[(30,100,10),(30,30),(100,100),(30,30,30)]\n",
    "\n",
    "alph=alpha_options[0]\n",
    "max_iteration=max_iteration_options[0]\n",
    "slv=solver_options[1]\n",
    "rseed=random_state_options[0]\n",
    "hidden_layer=hidden_layer_sizes_options[0]\n",
    "\n",
    "\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        rs=42\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for alph in alpha_options:\n",
    "            rseed=90\n",
    "            results_exp[str(alph)] = experiment_NN(repeats,param,alph,max_iteration,slv,rseed,hidden_layer,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "            \n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer \"\n",
    "          .format(y.name,MonthSeries,alpha_options,max_iteration,slv,hidden_layer))\n",
    "plt.savefig(\"Data/18Mayıs/NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer.png \"\n",
    "          .format(y.name,MonthSeries,alpha_options,max_iteration,slv,hidden_layer), format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "\n",
    "alph=alpha_options[3]\n",
    "max_iteration=max_iteration_options[0]\n",
    "slv=solver_options[1]\n",
    "rseed=random_state_options[0]\n",
    "hidden_layer=hidden_layer_sizes_options[1]\n",
    "\n",
    "\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        rs=42\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for max_iteration in max_iteration_options:\n",
    "            \n",
    "            results_exp[str(max_iteration)] = experiment_NN(repeats,param,alph,max_iteration,slv,rseed,hidden_layer,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "            \n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration_options,slv,hidden_layer))\n",
    "plt.savefig(\"Data/18Mayıs/NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer.png \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration_options,slv,hidden_layer), format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "\n",
    "alph=alpha_options[3]\n",
    "max_iteration=max_iteration_options[0]\n",
    "slv=solver_options[1]\n",
    "rseed=random_state_options[0]\n",
    "hidden_layer=hidden_layer_sizes_options[1]\n",
    "\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        rs=42\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for slv in solver_options:\n",
    "            \n",
    "            results_exp[str(slv)] = experiment_NN(repeats,param,alph,max_iteration,slv,rseed,hidden_layer,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "            \n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration,solver_options,hidden_layer))\n",
    "plt.savefig(\"Data/18Mayıs/NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer.png \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration,solver_options,hidden_layer), format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "\n",
    "alph=alpha_options[3]\n",
    "max_iteration=max_iteration_options[0]\n",
    "slv=solver_options[1]\n",
    "rseed=random_state_options[0]\n",
    "hidden_layer=hidden_layer_sizes_options[1]\n",
    "\n",
    "print('alph=',alph)\n",
    "print('max_iteration=',max_iteration)\n",
    "print('slv=',slv)\n",
    "print('hidden_layer=',hidden_layer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for r in range (0,50):\n",
    "        rs=random.randint(1,100)\n",
    "        rs=42\n",
    "        SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "        train_X=SplitData[0] \n",
    "        test_X=SplitData[1] \n",
    "        train_y=SplitData[2] \n",
    "        test_y=SplitData[3]\n",
    "        scaler_x=SplitData[4]\n",
    "        scaler_y=SplitData[5]\n",
    "        split_succesfull=SplitData[7]\n",
    "\n",
    "        for hidden_layer in hidden_layer_sizes_options:\n",
    "            \n",
    "            results_exp[str(hidden_layer)] = experiment_NN(repeats,param,alph,max_iteration,slv,rseed,hidden_layer,train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "            \n",
    "\n",
    "        results=pd.concat([results,results_exp])\n",
    "\n",
    "## summarize results\n",
    "print('Size:',results.size)\n",
    "print(results.describe())\n",
    "#save boxplot\n",
    "plt.gcf().clear()\n",
    "results.boxplot()\n",
    "plt.title(\"NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration,slv,hidden_layer_sizes_options))\n",
    "plt.savefig(\"Data/18Mayıs/NN-Box Plot for {}-{}, {} alpha,{} max_ite,{} slv {}hiddenlayer.png \"\n",
    "          .format(y.name,MonthSeries,alph,max_iteration,slv,hidden_layer_sizes_options), format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN DENEME VE KONTROL ICIN ESKI VERSIYONDAN GELEN KODLAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn (alph,max_iteration,slv,rseed,hidden_layer,X_train, X_test, y_train, y_test):\n",
    "    MLP = MLPRegressor(\n",
    "                              alpha = alph,\n",
    "                              solver=slv ,\n",
    "                              max_iter=max_iteration,\n",
    "                              random_state =rseed,\n",
    "                              hidden_layer_sizes=hidden_layer\n",
    "    )\n",
    "    MLPRegressor.fit(MLP,X_train,y_train)\n",
    "    \n",
    "    predictions = MLP.predict(X_test)\n",
    "    \n",
    "    MAE=int(metrics.mean_absolute_error(y_test, predictions))\n",
    "    MSE=int(sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "    R2=int(1000*(metrics.r2_score(y_test, predictions)))/1000\n",
    "    print('R2 nn icindeki',R2)\n",
    "    print(alph,max_iteration,slv,rseed,hidden_layer)\n",
    "    return MAE,MSE,R2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calıstır_nn(Product,MonthSeries,Scaler_Type,X_train, X_test, y_train, y_test):\n",
    "    estimation_method='nn'\n",
    "    alpha_options = [0.0001,0.00000001]\n",
    "    solver_options = [ 'adam']#,'lbfgs' ] # sgd solver cok sapıttı\n",
    "    max_iteration_options = [50000]#,60000,100000]\n",
    "    #random_state_options =[1,10,50,75,200]\n",
    "    #random_state_options =[10,50,90]\n",
    "    random_state_options =[90]\n",
    "    hidden_layer_sizes_options=[(30,100,10)]#,(30,30),(100,100),(30,30,30)]\n",
    "\n",
    "    sonuc = pd.DataFrame(columns='EstMethod Product Scaler MonthSeries alpha max_iteration slv hidden_layer random MAE MSE R2'.split())\n",
    "    i=0\n",
    "\n",
    "    for alpha in alpha_options:\n",
    "    \n",
    "        for max_iteration in max_iteration_options:\n",
    "\n",
    "            for slv in solver_options:\n",
    "        \n",
    "                for hidden_layer in hidden_layer_sizes_options:\n",
    "           \n",
    "                    for rseed in random_state_options:\n",
    "                \n",
    "                        estimate_metric=nn(alpha,max_iteration,slv,rseed,hidden_layer,X_train, X_test, y_train, y_test)\n",
    "                    \n",
    "                        MAE=estimate_metric[0]\n",
    "                        MSE=estimate_metric[1]\n",
    "                        R2=estimate_metric[2]\n",
    "                        print(R2)\n",
    "                        print('alpha',alpha,'iter:',max_iteration,'slvr:',slv,'random:',rseed,'layers:',hidden_layer,\n",
    "                          MAE,MSE,R2)\n",
    "                        sonuc.loc[i]=[estimation_method,Product,Scaler_Type,MonthSeries,alpha,max_iteration,slv,hidden_layer,random,MAE,MSE,R2]\n",
    "                        i=i+1\n",
    "    return sonuc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y=y3\n",
    "Z=z3\n",
    "X=X3\n",
    "\n",
    "values = X.values\n",
    "values = values.astype('float32')\n",
    "scaler_x= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaled_value_x = scaler_x.fit_transform(values)\n",
    "scaled_value_x = pd.DataFrame(data=scaled_value_x[:,:])\n",
    "\n",
    "values = y.values\n",
    "values = values.astype('float32')\n",
    "scaler_y= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaled_value_y = scaler_y.fit_transform(values)\n",
    "scaled_value_y = pd.DataFrame(data=scaled_value_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_value_x,scaled_value_y,test_size=0.2,random_state=42,stratify=Z['Month'])\n",
    "\n",
    "\n",
    "random_split='TRUE'\n",
    "rs=42\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "#        print(rs)\n",
    "X_train=SplitData[0] \n",
    "X_test=SplitData[1] \n",
    "y_train=SplitData[2] \n",
    "y_test=SplitData[3]\n",
    "scaler_x=SplitData[4]\n",
    "scaler_y=SplitData[5]\n",
    "split_succesfull=SplitData[7]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sonuc=calıstır_nn(Product,MonthSeries,ScalerType,X_train, X_test, y_train, y_test)\n",
    "filename='Out_NN_Prediction_Results_{one}_Product{two}'.format(one=datetime.now().strftime('Date_%m-%d_Time%H_%M'),two=Product)\n",
    "\n",
    "#sonuc.to_excel('{}.xlsx'.format(filename),index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN SONU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyDOE import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#fig, axs = plt.subplots(2, 3)\n",
    "\n",
    "\n",
    "results.boxplot()\n",
    "plt.title(\"Boxplot of Something\")\n",
    "\n",
    "#set_title('change outlier\\npoint symbols')\n",
    "\n",
    "\n",
    "plt.savefig('boxplot_epochs.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aşağıdaki Orjinal Kod Parçası"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    print(train_X.shape[1])\n",
    "    print(train_X.shape[2])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(300))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.15, clipvalue=0.3)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=800, batch_size=12, validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "#test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "inv_x_test = scaler_x.inverse_transform(test_X_reshaped)\n",
    "inv_x_test = pd.DataFrame(data=inv_x_test[:,:])\n",
    "\n",
    "# make a prediction\n",
    "y_predict_test = model.predict(test_X)\n",
    "y_predict_train = model.predict(train_X)\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "inv_y_predict_test = inv_y_predict_test[:,0]\n",
    "inv_y_predict_train = scaler_y.inverse_transform(y_predict_train)\n",
    "inv_y_predict_train = inv_y_predict_train[:,0]\n",
    "\n",
    "# invert scaling for actual\n",
    "y_test = test_y.reshape((len(test_y), 1))\n",
    "inv_y_test = scaler_y.inverse_transform(test_y)\n",
    "inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "y_train = train_y.reshape((len(train_y), 1))\n",
    "inv_y_train = scaler_y.inverse_transform(train_y)\n",
    "inv_y_train = inv_y_train[:,0]\n",
    "\n",
    "# calculate RMSE for DIFFERENCE\n",
    "rmse_test = sqrt(mean_squared_error(inv_y_test, inv_y_predict_test))\n",
    "print('Test RMSE: %.3f' % rmse_test)\n",
    "R2_test=int(1000*(metrics.r2_score(inv_y_test, inv_y_predict_test)))/1000\n",
    "print('R2_test: %.3f' % R2_test)\n",
    "\n",
    "rmse_train = sqrt(mean_squared_error(inv_y_train, inv_y_predict_train))\n",
    "print('Train RMSE: %.3f' % rmse_train)\n",
    "R2_train=int(1000*(metrics.r2_score(inv_y_train, inv_y_predict_train)))/1000\n",
    "print('R2_train: %.3f' % R2_train)\n",
    "\n",
    "# calculate RMSE for REAL VALUE\n",
    "\n",
    "real_y_test= inv_x_test.iloc[:,0]+inv_y_test\n",
    "real_y_predict_test=inv_x_test.iloc[:,0]+inv_y_predict_test\n",
    "\n",
    "rmse_test = sqrt(mean_squared_error(real_y_test, real_y_predict_test))\n",
    "print('Test RMSE: %.3f' % rmse_test)\n",
    "R2_test=int(1000*(metrics.r2_score(real_y_test, real_y_predict_test)))/1000\n",
    "print('R2_test: %.3f' % R2_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=pd.DataFrame(columns=['inv_y_test'],data=inv_y_test)\n",
    "b=pd.DataFrame(columns=['inv_y_predict_test'],data=inv_y_predict_test)\n",
    "c=pd.concat([a, b], axis=1)\n",
    "\n",
    "sns.pairplot(c[['inv_y_test','inv_y_predict_test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(inv_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=pd.DataFrame(columns=['inv_y_train'],data=inv_y_train)\n",
    "b=pd.DataFrame(columns=['inv_y_predict_train'],data=inv_y_predict_train)\n",
    "\n",
    "c=pd.concat([a, b], axis=1)\n",
    "\n",
    "sns.pairplot(c[['inv_y_train','inv_y_predict_train']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_y_predict_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_y_predict_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
